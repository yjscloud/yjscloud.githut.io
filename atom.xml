<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>戏子登台</title>
  <subtitle>唱一曲词，戏子登台，人生若只初相见，卖弄风骚为谁演。</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yjscloud.com/"/>
  <updated>2017-10-26T07:29:36.000Z</updated>
  <id>http://yjscloud.com/</id>
  
  <author>
    <name>Pan</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>LVS + Keepalived 实现高可用Web集群</title>
    <link href="http://yjscloud.com/2017/10/26/LVS-Keepalived-%E5%AE%9E%E7%8E%B0%E9%AB%98%E5%8F%AF%E7%94%A8Web%E9%9B%86%E7%BE%A4/"/>
    <id>http://yjscloud.com/2017/10/26/LVS-Keepalived-实现高可用Web集群/</id>
    <published>2017-10-26T05:23:40.000Z</published>
    <updated>2017-10-26T07:29:36.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="高可用性技术简介"><a href="#高可用性技术简介" class="headerlink" title="高可用性技术简介"></a>高可用性技术简介</h1><p>高可用性（HighAvailability）通常是用来描述一个系统经过专门的设计，从而减少停工的时间，而保持其服务的高可用性。计算机系统的可用性定义为：MTTF/(MTTF+MTTR) * 100%，因此计算机系统的可用性定义为系统保持正常运行时间的百分比。而负载均衡服务器的高可用性是为了屏蔽负载均衡服务器的失效，需要建立一个备份机。主服务器和备份机上都运行高可用性监控程序，通过传送信息来监控对方的运行状况。当备份机不能在一定的时间里接收到从主服务器那里发送的它存活着（即它从事着主服务器的工作）的时候，备份服务器就会从主服务器那里接管器主服务器的服务IP并继续提供服务。当主服务器又开始接管服务时，它会给备份服务器发送它接管的消息，接着备份服务器就会释放服务IP地址，这样子主服务器又再一次接管了服务IP。这就实现了在主服务器失效的状况下，备份服务器可以接管主服务的工作，以此实现负载集群系统配置信息的同步与备份了。</p>
<a id="more"></a>
<h1 id="LVS-负载均衡技术"><a href="#LVS-负载均衡技术" class="headerlink" title="LVS 负载均衡技术"></a>LVS 负载均衡技术</h1><p>LVS即 Linux Virtual Server，是由中国一个Linux程序员章文嵩博士发起和领导的，基于Linux系统的服务器集群解决方案，其实现目标是创建一个具有良好的扩展性、高可靠性、高性能和高可用性的体系。使用LVS架设的服务器集群系统从体系结构上看是透明的，最终用户只感觉到一个虚拟服务器。物理服务器之间可以通过高速的 LAN或分布在各地的WAN相连。最前端是负载均衡器，它负责将各种服务请求分发给后面的物理服务器，让整个集群表现得像一个服务于同一IP地址的虚拟服务器。负载均衡（Load Balance）建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。</p>
<p>负载均衡可以通过软件实现也可以通过硬件实现，软件负载均衡解决方案是指在一台或多台服务器相应的操作系统上安装一个或多个附加软件来实现负载均衡，它的优点是基于特定环境，配置简单，使用灵活，成本低廉，可以满足一般的负载均衡需求。而硬件负载均衡解决方案是直接在服务器和外部网络间安装负载均衡设备，这种设备我们通常称之为负载均衡器，由于专门的设备完成专门的任务，独立于操作系统，整体性能得到大量提高，加上多样化的负载均衡策略，智能化的流量管理，可达到最佳的负载均衡需求。LVS负载均衡的实现基础是IP交换，将IP层的TCP/IP请求均匀的转移到服务器池中不同的服务器上。而在 Linux平台下 IP的交换具备了一定的可扩展性,可以实现高性能、高可扩展性、易管理性等诸多特点,成为一个以负载均衡为核心的真正意义的集群系统。</p>
<p>LVS服务器集群采用IP负载均衡技术和基于内容请求分发技术。调度器具有很好的吞吐率，将请求均衡地转移到不同的服务器上执行，且调度器自动屏蔽掉服务器的故障，从而将一组服务器构成一个高性能的、高可用的虚拟服务器。整个服务器集群的结构对客户是透明的，而且无需修改客户端和服务器端的程序。负载调度器可以运行在以下三种模式下：</p>
<p>（1）Virtual Server via NAT（VS-NAT）：用地址翻译实现虚拟服务器。地址转换器有能被外界访问到的合法IP地址，它修改来自专有网络的流出包的地址。外界看起来包是来自 地址转换器本身，当外界包送到转换器时，它能判断出应该将包送到内部网的哪个节点。优点是节省IP 地址，能对内部进行伪装；缺点是效率低，因为返回给请求方的流量经过转换器。</p>
<p>（2）Virtual Server via IP Tunneling （VS-TUN）：用IP隧道技术实现虚拟服务器。这种方式是在集群的节点不在同一个网段时可用的转发机制，是将IP包封装在其他网络流量中的方法。为了 安全的考虑，应该使用隧道技术中的VPN，也可使用租用专线。 集群所能提供的服务是基于TCP/IP的Web服务、Mail服务、News服务、DNS服务、Proxy服务器等。</p>
<p>（3）Virtual Server via Direct Routing（VS-DR）：用直接路由技术实现虚拟服务器。当参与集群的计算机和作为控制管理的计算机在同一个网段时可以用此法，控制管理的计算机接 收到请求包时直接送到参与集群的节点。优点是返回给客户的流量不经过控制主机，速度快开销少。<br>LVS本身是基于IP层的负载均衡，可以说是最高效的一种方式。其中VS- DR和VS-TUN两种工作模式可以由后端机器直接对外服务，负载均衡的性能很高，对资源占用很少，通过LVS服务器集群负载均衡技术，能够以很高的性价比解决网络访问量激增带来的服务器瓶颈问题。</p>
<h1 id="KEEPALIVED-技术"><a href="#KEEPALIVED-技术" class="headerlink" title="KEEPALIVED 技术"></a>KEEPALIVED 技术</h1><p>在 keepalived中，一个是master，其他的都是backup</p>
<p>vrrp:实现ip地址的高可用性，将除地址之外其他的功能也转移</p>
<p>通过状态的改变，keepalived检测到，执行相应的状态下定义的脚本，脚本中有服务的 关闭和开启的命令，来实现服务的转移。</p>
<p>keepalived不仅提供地址的转移功能，服务启动和关闭，还有监控功能具有两个核心组件：VRRP stack 和 checkers（用来监控服务）、还有对外围监控脚本调用的实现，节点之间只通过优先级来确定资源在哪个节点上运行，需要起始配置，虚拟地址转移需通过配置脚本来启动服务转移信息状态，有个通知机制，可以发短信或者邮件给管理员（需配置邮件服务器）</p>
<p>适用于用不到共享存储，节点少的且keepalived支持多节点，但是节点中启动服务的只能有一个节点（一主多从）让每个节点都活动起来（运行两组资源）</p>
<p>vrrp认证：1、明文认证、配置好预共享密钥  2、md5 sha1 散列</p>
<p>core：是keepalived的核心，复杂主进程的启动和维护，全局配置文件的加载解析等</p>
<p>check：负责healthchecker(健康检查)，包括了各种健康检查方式，以及对应的配置的解析包括<br>LVS的配置解析</p>
<p>vrrp：VRRPD子进程，VRRPD子进程就是来实现VRRP协议的</p>
<p>libipfwc：iptables(ipchains)库，配置LVS会用到</p>
<p>libipvs*：配置LVS会用到</p>
<p>注意，keepalived和LVS完全是两码事，只不过他们各负其责相互配合而已</p>
<p><img src="http://ow78pfxd9.bkt.clouddn.com/k-1.png" alt="k-1"></p>
<p>keepalived启动后会有三个进程</p>
<p>(1)父进程：内存管理，子进程管理等等</p>
<p>(2)子进程：VRRP子进程</p>
<p>(3)子进程：healthchecker子进程</p>
<h1 id="实验环境物理结构说明"><a href="#实验环境物理结构说明" class="headerlink" title="实验环境物理结构说明"></a>实验环境物理结构说明</h1><p><img src="http://ow78pfxd9.bkt.clouddn.com/k-2.png" alt="k-2"></p>
<h1 id="keepalived测试环境安装"><a href="#keepalived测试环境安装" class="headerlink" title="keepalived测试环境安装"></a>keepalived测试环境安装</h1><p>（1）关闭防火墙和selinux</p>
<pre><code># service iptables stop
# chkconfig iptables off
# vi /etc/selinux/config 
    把enforcing改为disabled
# setenforce 0
</code></pre><p>（2）分别给master和backup节点安装ipvsadm和keepalived</p>
<pre><code># yum –y install ipvsadm
# yum –y install keepalived
# service keepalived start
# chkconfig keepalived on
</code></pre><p>（3）配置 keepalived.conf</p>
<pre><code>#  vi /etc/keeplived/keepalived.conf
</code></pre><pre>
! Configuration File for keepalived

global_defs {
   router_id S208                ## keepalived 服务器标识符，可以随意设定（ 貌似也是全局唯一 ）
}

vrrp_instance NW3007 {            ## 定义一个名为 NW3007 的 VRRP 实例
    state MASTER                ## Keepalived 服务器角色，MASTER 为主、BACKUP 为备
    interface eth0                ## 指定 HA 监测网络接口
    virtual_router_id 51            ## 虚拟路由标识，同一个 VRRP 实例使用唯一的标识，主备必须一样
    priority 200                    ## 节点优先级，同一 VRRP 实例中 MASTER 的优先级必须大于 BACKUP
    advert_int 5                    ## MASTER / BACKUP 之间同步检查间隔时间，单位 秒
    track_interface {                ##指定监听数据的网口
        eth0
    }
    authentication {                ## 节点之间通信验证类型、密码 ，同一 VRRP 实例中，MASTER / BACKUP 必须使用相同的密码才可以通信
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {            ## 虚拟 IP 地址，又称漂移 IP 。可以通过 ip add 在 MASTER 上查看是否绑定
        192.168.2.100
    }
}

virtual_server 192.168.0.110 80 {        ## 定义虚拟服务器
    delay_loop 3                        ## 定义健康检查时间间隔，单位 秒
    lb_algo wlc                         ## 负载均衡调度算法，支持 rr 、wrr 、lc 、wlc 、lblc 、sh 、dh 等
    lb_kind DR                        ## LVS 负载均衡机制，支持 NAT 、TUN 、DR
    protocol TCP                    ## 转发协议类型，支持 TCP 、UDP
    ha_suspend                        

    real_server 192.168.0.30 80 {            ## 定义节点服务器
        weight 3                        ## 节点权重值，数字越大权重越高，分配到的连接越多。主要用于后端节点服务器性能不统一
        TCP_CHECK {                ## 健康检测方式，支持 HTTP_GET 、SSL_GET 、TCP_CHECK 、SMTP_CHECK 、MISC_CHECK
            connect_timeout 3        ## 无响应超时时间，单位 秒
        }
    }

    real_server 192.168.0.31 80 {        ## 第二台节点服务器
        weight 3
        TCP_CHECK {
            connect_timeout 3
        }
    }
}
</pre>

<p>在master节点配置好keepalived文件后将keepalived.conf拷贝到backup节点</p>
<pre><code># scp /etc/keepalived/keepalived.conf  192.168.0.29:/etc/keepalived/
</code></pre><p>然后将priority值改为100即可,最后重启keepalived服务</p>
<pre><code># service keepalived restart
</code></pre><p>（4）为master节点和backup节点添加vip</p>
<p>master节点</p>
<pre><code># ip addr add 192.168.0.110/32 dev eth0
</code></pre><p><img src="http://ow78pfxd9.bkt.clouddn.com/k-3.png" alt="k-3"></p>
<p>backup节点</p>
<pre><code># ip addr add 192.168.0.110/32 dev eth0
</code></pre><p><img src="http://ow78pfxd9.bkt.clouddn.com/k-4.png" alt="k-4"></p>
<p>（5）验证虚拟 IP 地址是否可以正常漂移</p>
<p>停用master节点网卡</p>
<pre><code># ifdown eth0
</code></pre><p>查看backup节点的日志文件</p>
<p><img src="http://ow78pfxd9.bkt.clouddn.com/k-5.png" alt="k-5"></p>
<p>查看backup的网卡</p>
<p><img src="http://ow78pfxd9.bkt.clouddn.com/k-6.png" alt="k-6"></p>
<p>重新激活master网卡,查看backup日志文件<br><img src="http://ow78pfxd9.bkt.clouddn.com/k-7.png" alt="k-7"></p>
<p>虚拟ip会自动移除，虚拟ip设置正常！</p>
<p>注意：停用master的网卡vip会自动消失需要重新为master添加vip</p>
<pre><code># ip addr add 192.168.0.110/32 dev eth0
</code></pre><h1 id="配置RS-1和RS-2"><a href="#配置RS-1和RS-2" class="headerlink" title="配置RS-1和RS-2"></a>配置RS-1和RS-2</h1><p>（1）关闭防火墙和selinux</p>
<pre><code># service iptables stop
# chkconfig iptables off
# vi /etc/selinux/config 
    把enforcing改为disabled
# setenforce 0
</code></pre><p>（2）安装httpd</p>
<p>分别在RS-1和RS-2上进行如下操作</p>
<pre><code># yum –y install httpd
# service httpd start
# chkconfig httpd on
</code></pre><p>在RS-1</p>
<pre><code>echo RS-1-Web11111111 &gt; /var/www/html/index.html
</code></pre><p>在RS-2</p>
<pre><code>echo RS-2-Web2222222 &gt; /var/www/html/index.html
</code></pre><p>（3）RS-1创建一个脚本文件</p>
<pre><code># vi /root/realserver.sh
</code></pre><pre>
#!/bin/bash
vip=192.168.0.110

case $1 in
start)
    echo 1 > /proc/sys/net/ipv4/conf/all/arp_ignore
    echo 1 > /proc/sys/net/ipv4/conf/eth0/arp_ignore
    echo 2 > /proc/sys/net/ipv4/conf/all/arp_announce
    echo 2 > /proc/sys/net/ipv4/conf/eth0/arp_announce

    ifconfig lo:0 $vip netmask 255.255.255.255 broadcast $vip up

    ;;
stop)
    ifconfig lo:0 down
        echo 0 > /proc/sys/net/ipv4/conf/all/arp_ignore
        echo 0 > /proc/sys/net/ipv4/conf/eth0/arp_ignore
        echo 0 > /proc/sys/net/ipv4/conf/all/arp_announce
        echo 0 > /proc/sys/net/ipv4/conf/eth0/arp_announce
    ;;
esac
</pre>

<p>赋予运行权权限</p>
<pre><code># chmod a+x /root/realserver.sh
</code></pre><p>将脚本拷贝到RS-2</p>
<pre><code># scp /root/realserver.sh 192.168.0.31:/root/
</code></pre><p>在RS-1和RS-2执行脚本</p>
<pre><code># ./realserver start
</code></pre><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>服务器之间可以自由调度</p>
<p><img src="http://ow78pfxd9.bkt.clouddn.com/k-9.png" alt="k-9"></p>
<p><img src="http://ow78pfxd9.bkt.clouddn.com/k-8.png" alt="k-8"></p>
<p>停用mater网卡也可以自由调度RS-1和RS-2，实验到此结束</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;高可用性技术简介&quot;&gt;&lt;a href=&quot;#高可用性技术简介&quot; class=&quot;headerlink&quot; title=&quot;高可用性技术简介&quot;&gt;&lt;/a&gt;高可用性技术简介&lt;/h1&gt;&lt;p&gt;高可用性（HighAvailability）通常是用来描述一个系统经过专门的设计，从而减少停工的时间，而保持其服务的高可用性。计算机系统的可用性定义为：MTTF/(MTTF+MTTR) * 100%，因此计算机系统的可用性定义为系统保持正常运行时间的百分比。而负载均衡服务器的高可用性是为了屏蔽负载均衡服务器的失效，需要建立一个备份机。主服务器和备份机上都运行高可用性监控程序，通过传送信息来监控对方的运行状况。当备份机不能在一定的时间里接收到从主服务器那里发送的它存活着（即它从事着主服务器的工作）的时候，备份服务器就会从主服务器那里接管器主服务器的服务IP并继续提供服务。当主服务器又开始接管服务时，它会给备份服务器发送它接管的消息，接着备份服务器就会释放服务IP地址，这样子主服务器又再一次接管了服务IP。这就实现了在主服务器失效的状况下，备份服务器可以接管主服务的工作，以此实现负载集群系统配置信息的同步与备份了。&lt;/p&gt;
    
    </summary>
    
      <category term="技术分享" scheme="http://yjscloud.com/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="Linux学习笔记" scheme="http://yjscloud.com/tags/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="keepalived" scheme="http://yjscloud.com/tags/keepalived/"/>
    
  </entry>
  
  <entry>
    <title>kvm学习笔记（九）-cpu添加虚拟化功能</title>
    <link href="http://yjscloud.com/2017/10/21/kvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B9%9D%EF%BC%89-cpu%E6%B7%BB%E5%8A%A0%E8%99%9A%E6%8B%9F%E5%8C%96%E5%8A%9F%E8%83%BD/"/>
    <id>http://yjscloud.com/2017/10/21/kvm学习笔记（九）-cpu添加虚拟化功能/</id>
    <published>2017-10-21T09:23:10.000Z</published>
    <updated>2017-12-02T09:35:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>因为只有一台物理机，物理机运行着centos7，需要测试虚拟化环境，就要在运行的kvm环境中的虚拟机增加kvm_intel模块！具体方法如下：</p>
<pre><code>[root@kvm~]# vim /etc/modprobe.d/kvm-nested.conf #此文件默认不存在，新建即可
options kvm_intel nested=1 #添加此行
[root@kvm ~]# modprobe -r kvm_intel #卸载模块
[root@kvm ~]# modprobe kvm_intel #重新加载模块
[root@kvm ~]# cat /sys/module/kvm_intel/parameters/nested 
Y
#返还Y即为支持nested KVM
[root@kvm ~]# virsh edit VM host name #修改虚拟机
</code></pre><p>修改如下区块</p>
<p>将如下代码</p>
<pre><code>&lt;cpu mode=’custom’ match=’exact’ &gt;
</code></pre><p>修改为</p>
<pre><code>&lt;cpu mode=&apos;host-passthrough&apos;&gt;
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/2.1.png" alt="2.1"></p>
<p>如果虚拟机的配置文件里没有<cpu mode="’custom’" match="’exact’">这一行代码就在如下位置添加一行代码即可</cpu></p>
<p><img src="http://oxysobnip.bkt.clouddn.com/2.2.png" alt="2.2"></p>
<p>查看一下虚拟机cpu已经支持虚拟化了</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/2.3.png" alt="2.3"></p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;因为只有一台物理机，物理机运行着centos7，需要测试虚拟化环境，就要在运行的kvm环境中的虚拟机增加kvm_intel模块！具体方法如下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[root@kvm~]# vim /etc/modprobe.d/kvm-nested.conf #
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KVM学习笔记" scheme="http://yjscloud.com/tags/KVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kvm学习笔记（八）-kvm虚拟机存储池配置</title>
    <link href="http://yjscloud.com/2017/10/20/kvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89-kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%AD%98%E5%82%A8%E6%B1%A0%E9%85%8D%E7%BD%AE/"/>
    <id>http://yjscloud.com/2017/10/20/kvm学习笔记（八）-kvm虚拟机存储池配置/</id>
    <published>2017-10-20T04:56:21.000Z</published>
    <updated>2017-12-02T09:34:59.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是存储池"><a href="#什么是存储池" class="headerlink" title="什么是存储池"></a>什么是存储池</h1><p>KVM平台以存储池的形式对存储进行统一管理，所谓存储池可以理解为本地目录、通过远端磁盘阵列（iSCSI、NFS）分配过来磁盘或目录，当然也支持各类分布式文件系统。通过virsh中pool命令能够查看、创建、激活、注册、删除存储池。</p>
<p>注1:KVM存储池主要是体现一种管理方式，可以通过挂载存储目录，lvm逻辑卷的方式创建存储池，虚拟机存储卷创建完成后，剩下的操作与无存储卷的方式无任何区别了。</p>
<p>注2:KVM存储池也要用于虚拟机迁移任务。</p>
<h1 id="存储池配置步骤"><a href="#存储池配置步骤" class="headerlink" title="存储池配置步骤"></a>存储池配置步骤</h1><h2 id="创建基于文件夹的存储池（目录）"><a href="#创建基于文件夹的存储池（目录）" class="headerlink" title="创建基于文件夹的存储池（目录）"></a>创建基于文件夹的存储池（目录）</h2><p><img src="http://oxysobnip.bkt.clouddn.com/1.102.png" alt="1.102"></p>
<h2 id="定义存储池与其目录"><a href="#定义存储池与其目录" class="headerlink" title="定义存储池与其目录"></a>定义存储池与其目录</h2><p><img src="http://oxysobnip.bkt.clouddn.com/1.103.png" alt="1.103"></p>
<h2 id="创建已定义的存储池"><a href="#创建已定义的存储池" class="headerlink" title="创建已定义的存储池"></a>创建已定义的存储池</h2><p>(1)创建已定义的存储池</p>
<pre><code># virsh pool-build vmdisk
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.104.png" alt="1.104"></p>
<p>(2)查看已定义的存储池，存储池不激活无法使用。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.105.png" alt="1.105"></p>
<h2 id="激活并自动启动已定义的存储池"><a href="#激活并自动启动已定义的存储池" class="headerlink" title="激活并自动启动已定义的存储池"></a>激活并自动启动已定义的存储池</h2><p><img src="http://oxysobnip.bkt.clouddn.com/1.106.png" alt="1.106"></p>
<p>这里vmdisk存储池就已经创建好了，可以直接在这个存储池中创建虚拟磁盘文件了。</p>
<h2 id="在存储池中创建虚拟机存储卷"><a href="#在存储池中创建虚拟机存储卷" class="headerlink" title="在存储池中创建虚拟机存储卷"></a>在存储池中创建虚拟机存储卷</h2><p>(1)在存储池中创建虚拟机存储卷</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.107.png" alt="1.107"></p>
<p>(2)根据创建的虚拟机存储卷安装虚拟机</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.108.png" alt="1.108"></p>
<p>安装过程略！</p>
<p>说明：KVM存储池主要是体现一种管理方式，可以通过挂载存储目录，lvm逻辑卷的方式创建存储池，虚拟机存储卷创建完成后，剩下的操作与无存储卷的方式无任何区别了。KVM存储池也要用于虚拟机迁移任务。</p>
<h2 id="存储池相关管理命令"><a href="#存储池相关管理命令" class="headerlink" title="存储池相关管理命令"></a>存储池相关管理命令</h2><p>(1)在存储池中删除虚拟机存储卷</p>
<pre><code># virsh vol-delete --pool vmdisk test-01.qcow2
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.109.png" alt="1.109"></p>
<p>(2)取消激活存储池</p>
<pre><code># virsh pool-destroy vmdisk
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.110.png" alt="1.110"></p>
<p>(3)删除存储池定义的目录/mnt/vmfs</p>
<pre><code># virsh pool-delete vmdisk
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.111.png" alt="1.111"></p>
<p>(4)取消定义存储池</p>
<pre><code># virsh pool-undefine vmdisk
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.112.png" alt="1.112"></p>
<p>到此kvm存储池配置与管理操作完毕。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是存储池&quot;&gt;&lt;a href=&quot;#什么是存储池&quot; class=&quot;headerlink&quot; title=&quot;什么是存储池&quot;&gt;&lt;/a&gt;什么是存储池&lt;/h1&gt;&lt;p&gt;KVM平台以存储池的形式对存储进行统一管理，所谓存储池可以理解为本地目录、通过远端磁盘阵列（iSCSI、NF
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KVM学习笔记" scheme="http://yjscloud.com/tags/KVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kvm学习笔记（七）-kvm虚拟机动态迁移</title>
    <link href="http://yjscloud.com/2017/10/20/kvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89-kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8A%A8%E6%80%81%E8%BF%81%E7%A7%BB/"/>
    <id>http://yjscloud.com/2017/10/20/kvm学习笔记（七）-kvm虚拟机动态迁移/</id>
    <published>2017-10-20T01:49:46.000Z</published>
    <updated>2017-12-02T09:34:41.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么叫动态迁移？"><a href="#什么叫动态迁移？" class="headerlink" title="什么叫动态迁移？"></a>什么叫动态迁移？</h1><p>动态迁移（Live Migration）：也叫在线迁移（Online Migration）。就是在保证虚拟机上服务正常运行的同时，将一个虚拟机系统从一个物理主机移动到另一个物理主机的过程。该过程不会对最终用户造成明 显的影响，从而使得管理员能够在不影响用户正常使用的情况下，对物理服务器进行离线维修或者升级。与静态迁移不同的是，为了保证迁移过程中虚拟机服务的可用，迁移过程仅有非常短暂的停机时间。迁移的前面阶段，服务在源主机的虚拟机上运行，当迁移进行到一定阶段，目的主机已经具备了运行虚拟机系统的必须资源，经过一个非常短暂的切换，源主机将控制权转移到目的主机，虚拟机系统在目的主机上继续运行。对于虚拟机服务本身而言，由于切换的时间非常短暂，用户感 觉不到服务的中断，因而迁移过程对用户是透明的。动态迁移适用于对虚拟机服务可用性要求很高的场合。</p>
<a id="more"></a>
<p>动态迁移需要将原有的虚拟机镜像放在采用 SAN（storage area network）或 NAS（network-attached storage）之类的集中式共享外存设备,这样迁移的时候,不是迁移整个硬盘镜象,而是迁移内存的信息.所以迁移起来,速度比较快,停顿时间少。</p>
<p>动态迁移实际上是把虚拟机的配置封装在一个文件中，然后通过高速网络，把虚拟机配置和内存运行状态从一台物理机迅速传送到另外一台物理机上，期间虚拟机一直保持运行状态。现有技术条件下，大多虚拟机软件如 VMware、Hyper-V、Xen 进行动态迁移都需要共享存储的支持。典型的共享存储包括 NFS 和 SMB/CIFS 协议的网络文件系统，或者通过 iSCSI 连接到 SAN 网络。选用哪一种网络文件系统，需要根据具体情况而定，本文使用NFS 共享存储！</p>
<p>虚拟化平台架构</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.83.png" alt="1.83"></p>
<h1 id="虚拟化环境介绍"><a href="#虚拟化环境介绍" class="headerlink" title="虚拟化环境介绍"></a>虚拟化环境介绍</h1><p>（1）kvm虚拟化服务器节点：kvm-1</p>
<p>   操作系统：CentOS7.2</p>
<p>   kvm虚拟化：自带版本</p>
<p>   Ip地址：192.168.0.40    </p>
<p>   nfs挂载目录：/mnt</p>
<hr>
<p>(2）kvm虚拟化服务器节点kvm-2</p>
<p>   操作系统：CentOS7.2</p>
<p>   kvm虚拟化：自带版本</p>
<p>  ip地址：192.168.0.15    </p>
<p>  nfs挂载目录：/mnt</p>
<p>  测试虚拟机：share</p>
<p>  虚拟机磁盘文件：/mnt/kvm/share.qcow2</p>
<hr>
<p>（3）nfs服务器</p>
<p>   操作系统：CentOS7.2</p>
<p>   ip地址：192.168.0.12</p>
<p>   nfs服务目录：/home/image</p>
<h1 id="三台虚拟机都关闭SElinux和防火墙"><a href="#三台虚拟机都关闭SElinux和防火墙" class="headerlink" title="三台虚拟机都关闭SElinux和防火墙"></a>三台虚拟机都关闭SElinux和防火墙</h1><pre><code># systemctl stop firewalld
# systemctl disable firewalld
# vim /etc/selinux/config
    将enforcing改为disabled
</code></pre><h1 id="共享存储的配置"><a href="#共享存储的配置" class="headerlink" title="共享存储的配置"></a>共享存储的配置</h1><p>（1）)NFS共享存储虚拟机安装NFS服务</p>
<pre><code># yum –y install nfs-utils
</code></pre><p>（2）创建并加载挂载目录</p>
<pre><code># mkdir /home/image
# vim /etc/exports
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.84.png" alt="1.84"></p>
<p>（3）查看是否共享目录,并重启nfs服务</p>
<pre>
# exportfs -av
# systemctl enable rpcbind.service
# systemctl enable nfs-server.service
# systemctl start rpcbind.service
# systemctl start nfs-server.service
# showmount –e
</pre>

<p><img src="http://oxysobnip.bkt.clouddn.com/1.85.png" alt="1.85"></p>
<p>（4）先确保两台宿主机的虚拟机全部呈关闭状态，目的是将之前的磁盘镜像目录移动到/mnt 外的其他位置，好将NFS 目录挂载到 /mnt 目录下：</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.86.png" alt="1.86"><br><img src="http://oxysobnip.bkt.clouddn.com/1.87.png" alt="1.87"></p>
<p>(5)将kvm-2和kvm-2的虚拟机磁盘镜像目录移动到 /mnt 目录以外的地方：</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.88.png" alt="1.88"><br><img src="http://oxysobnip.bkt.clouddn.com/1.89.png" alt="1.89"></p>
<h1 id="kvm虚拟主机配置准备"><a href="#kvm虚拟主机配置准备" class="headerlink" title="kvm虚拟主机配置准备"></a>kvm虚拟主机配置准备</h1><p>(1)节点1挂载nfs目录</p>
<pre><code># mount -t nfs 192.168.0.12:/home/image /mnt/
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.90.png" alt="1.90"></p>
<p>(2)节点2挂载nfs目录</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.91.png" alt="1.91"></p>
<p>(3)将kvm-2的虚拟机磁盘镜像目录移回到NFS，因为kvm-1的虚拟机之前是静态迁移过来的，kvm-2上也有一份，所以就不移回了(如果kvm-1上有不同于kvm-2上的虚拟机，则也要移回)</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.92.png" alt="1.92"></p>
<h1 id="kvm虚拟机迁移"><a href="#kvm虚拟机迁移" class="headerlink" title="kvm虚拟机迁移"></a>kvm虚拟机迁移</h1><p>(1)kvm-2虚拟机状态，share虚拟机开机状态</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.93.png" alt="1.93"></p>
<p>(2) kvm-1虚拟机状态，无虚拟机运行</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.94.png" alt="1.94"></p>
<p>(3)kvm-2上执行迁移命令</p>
<pre><code># virsh migrate --live --verbose share  qemu+ssh://192.168.0.40/system tcp://192.168.0.40 --unsafe
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.95.png" alt="1.95"></p>
<p>(4) 为了在验证过程中，虚拟主机不中断，我们开启ping 虚拟主机，没有出现超时状态，迁移成功。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.96.png" alt="1.96"></p>
<p>（5）迁移完成，验证kvm-2上的share呈关闭状态</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.97.png" alt="1.97"></p>
<p>kvm-1上,可以看到虚拟机share已经启动了。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.98.png" alt="1.98"></p>
<p>(6) 虽然share虚拟机已经在kvm-1上启动了，但是虚拟主机上还没有share虚拟机的配置文件。所以需要创建配置文件并定义虚拟机。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.99.png" alt="1.99"></p>
<p>Kvm-1上,通过迁移过来的虚拟机内存状态创建虚拟机配置文件，并通过xml配置文件定义虚拟机。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.100.png" alt="1.100"></p>
<p>在kvm-1上进入虚拟机没有问题。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.101.png" alt="1.101"></p>
<p>到此，kvm虚拟机动态迁移成功。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么叫动态迁移？&quot;&gt;&lt;a href=&quot;#什么叫动态迁移？&quot; class=&quot;headerlink&quot; title=&quot;什么叫动态迁移？&quot;&gt;&lt;/a&gt;什么叫动态迁移？&lt;/h1&gt;&lt;p&gt;动态迁移（Live Migration）：也叫在线迁移（Online Migration）。就是在保证虚拟机上服务正常运行的同时，将一个虚拟机系统从一个物理主机移动到另一个物理主机的过程。该过程不会对最终用户造成明 显的影响，从而使得管理员能够在不影响用户正常使用的情况下，对物理服务器进行离线维修或者升级。与静态迁移不同的是，为了保证迁移过程中虚拟机服务的可用，迁移过程仅有非常短暂的停机时间。迁移的前面阶段，服务在源主机的虚拟机上运行，当迁移进行到一定阶段，目的主机已经具备了运行虚拟机系统的必须资源，经过一个非常短暂的切换，源主机将控制权转移到目的主机，虚拟机系统在目的主机上继续运行。对于虚拟机服务本身而言，由于切换的时间非常短暂，用户感 觉不到服务的中断，因而迁移过程对用户是透明的。动态迁移适用于对虚拟机服务可用性要求很高的场合。&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KVM学习笔记" scheme="http://yjscloud.com/tags/KVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kvm学习笔记（六）-kvm虚拟机静态迁移</title>
    <link href="http://yjscloud.com/2017/10/20/kvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89-kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E9%9D%99%E6%80%81%E8%BF%81%E7%A7%BB/"/>
    <id>http://yjscloud.com/2017/10/20/kvm学习笔记（六）-kvm虚拟机静态迁移/</id>
    <published>2017-10-20T01:28:43.000Z</published>
    <updated>2017-12-02T09:34:18.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="什么是静态迁移？"><a href="#什么是静态迁移？" class="headerlink" title="什么是静态迁移？"></a>什么是静态迁移？</h1><p>静态迁移：也叫做常规迁移、离线迁移（Offline Migration）。就是在虚拟机关机或暂停的情况下从一台物理机迁移到另一台物理机。因为虚拟机的文件系统建立在虚拟机镜像上面，所以在虚拟机关机的 情况下，只需要简单的迁移虚拟机镜像和相应的配置文件到另外一台物理主机上；如果需要保存虚拟机迁移之前的状态，在迁移之前将虚拟机暂停，然后拷贝状态至目的主机，最后在目的主机重建虚拟机状态，恢复执行。这种方式的迁移过程需要显式的停止虚拟机的运行。从用户角度看，有明确的一段停机时间，虚拟机上的服务不可用。这种迁移方式简单易行，适用于对服务可用性要求不严格的场合。</p>
<a id="more"></a>
<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><p>(1)虚拟主机各自使用本地存储存放虚拟机磁盘文件</p>
<p>本文实现基于本地磁盘存储虚拟机磁盘文件的迁移方式</p>
<p>(2)虚拟主机之间使用共享存储存放虚拟机磁盘文件</p>
<p>该方式只是在目标虚拟主机上重新定义虚拟机就可以了</p>
<h1 id="静态迁移过程"><a href="#静态迁移过程" class="headerlink" title="静态迁移过程"></a>静态迁移过程</h1><p>(1)确定虚拟机关闭状态</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.70.png" alt="1.70"></p>
<p>(2)准备迁移clone-3虚拟机，查看该虚拟机配置的磁盘文件</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.71.png" alt="1.71"></p>
<p>(3)导入虚拟机配置文件</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.72.png" alt="1.72"></p>
<p>(4)拷贝配置文件到目标虚拟主机上</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.73.png" alt="1.73"></p>
<p>拷贝虚拟磁盘文件</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.74.png" alt="1.74"></p>
<h1 id="目标虚拟主机"><a href="#目标虚拟主机" class="headerlink" title="目标虚拟主机"></a>目标虚拟主机</h1><p>上面已经将虚拟机磁盘文件与配置文件都已经复制到目标虚拟主机上了。下面开始配置与启动。</p>
<p>(1)    查看目标虚拟主机环境</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.75.png" alt="1.75"></p>
<p>如果上面没有显示虚拟主机，就需要对虚拟主机进行注册</p>
<pre><code># virsh define /etc/libvirt/qemu/clone-3.xml
</code></pre><p>查看虚拟机磁盘文件，目录结构与源虚拟主机一致。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.76.png" alt="1.76"></p>
<p>(2)启动虚拟主机并确认</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.77.png" alt="1.77"></p>
<p>成功连接</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.78.png" alt="1.78"></p>
<p>至此虚拟机静态迁移完成。</p>
<h1 id="kvm的那些坑"><a href="#kvm的那些坑" class="headerlink" title="kvm的那些坑"></a>kvm的那些坑</h1><p>（1）如果您遇到如下报错您可以这样处理</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.79.png" alt="1.79"></p>
<p>查看包版本：</p>
<pre><code># yum info device-mapper-libs         
</code></pre><p>更新软件包：</p>
<pre><code># yum update device-mapper-libs  
</code></pre><p>然后运行如下命令</p>
<pre>
# sed -i 's/#listen_tls = 0/listen_tls = 0/g' /etc/libvirt/libvirtd.conf
# sed -i 's/#listen_tcp = 1/listen_tcp = 1/g' /etc/libvirt/libvirtd.conf
# sed -i 's/#auth_tcp = "sasl"/auth_tcp = "none"/g' /etc/libvirt/libvirtd.conf
# sed -i 's/#LIBVIRTD_ARGS="--listen"/LIBVIRTD_ARGS="--listen"/g' /etc/sysconfig/libvirtd
# systemctl restart libvirtd
</pre>

<p>（2）如果您把您的虚拟机静态迁移到不同平台（不同型号的cpu）的主机上报了如下错误</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.80.png" alt="1.80"></p>
<p>您可以根据提示修改您的虚拟机配置文件</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.81.png" alt="1.81"></p>
<p>Broadwell是原cpu类型，这里根据报错信息将其修改为Broadwell-noTSX</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.82.png" alt="1.82"></p>
<p>修改后即可启动虚拟机了！</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;什么是静态迁移？&quot;&gt;&lt;a href=&quot;#什么是静态迁移？&quot; class=&quot;headerlink&quot; title=&quot;什么是静态迁移？&quot;&gt;&lt;/a&gt;什么是静态迁移？&lt;/h1&gt;&lt;p&gt;静态迁移：也叫做常规迁移、离线迁移（Offline Migration）。就是在虚拟机关机或暂停的情况下从一台物理机迁移到另一台物理机。因为虚拟机的文件系统建立在虚拟机镜像上面，所以在虚拟机关机的 情况下，只需要简单的迁移虚拟机镜像和相应的配置文件到另外一台物理主机上；如果需要保存虚拟机迁移之前的状态，在迁移之前将虚拟机暂停，然后拷贝状态至目的主机，最后在目的主机重建虚拟机状态，恢复执行。这种方式的迁移过程需要显式的停止虚拟机的运行。从用户角度看，有明确的一段停机时间，虚拟机上的服务不可用。这种迁移方式简单易行，适用于对服务可用性要求不严格的场合。&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KVM学习笔记" scheme="http://yjscloud.com/tags/KVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kvm学习笔记（五）-kvm虚拟机在线扩展磁盘</title>
    <link href="http://yjscloud.com/2017/10/20/kvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89-kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%9C%A8%E7%BA%BF%E6%89%A9%E5%B1%95%E7%A3%81%E7%9B%98/"/>
    <id>http://yjscloud.com/2017/10/20/kvm学习笔记（五）-kvm虚拟机在线扩展磁盘/</id>
    <published>2017-10-20T01:08:07.000Z</published>
    <updated>2017-12-02T09:34:00.000Z</updated>
    
    <content type="html"><![CDATA[<p> kvm虚拟机也支持在线扩展磁盘功能,在线扩展有特定的使用环境，主要用于不能随便停用的生产环境中。经过测试KVM在线扩展磁盘功能只适用于RHEL/CentOS/OEL6.x环境,5.x不支持在线的扩展磁盘。</p>
<p>本次次测试使用centos7.3的虚拟机</p>
<p>给clone-2虚拟机在线添加磁盘</p>
<a id="more"></a>
<h1 id="查看现有磁盘"><a href="#查看现有磁盘" class="headerlink" title="查看现有磁盘"></a>查看现有磁盘</h1><pre><code># virsh start clone-2
# virsh list –all 
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.60.png" alt="1.60"></p>
<h1 id="创建一块qcow2虚拟磁盘"><a href="#创建一块qcow2虚拟磁盘" class="headerlink" title="创建一块qcow2虚拟磁盘"></a>创建一块qcow2虚拟磁盘</h1><pre><code># qemu-img create -f qcow2 add01.qcow2 10G
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.61.png" alt="1.61"></p>
<h1 id="在线添加这台qcow2虚拟磁盘"><a href="#在线添加这台qcow2虚拟磁盘" class="headerlink" title="在线添加这台qcow2虚拟磁盘"></a>在线添加这台qcow2虚拟磁盘</h1><pre><code># virsh attach-disk clone-2 /mnt/kvm/add01.qcow2 vdb --cache=none --subdriver=qcow2
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.62.png" alt="1.62"></p>
<h1 id="进入clone-2虚拟机查看添加磁盘情况"><a href="#进入clone-2虚拟机查看添加磁盘情况" class="headerlink" title="进入clone-2虚拟机查看添加磁盘情况"></a>进入clone-2虚拟机查看添加磁盘情况</h1><p>这里我通过vnc远程登录clone-2即可看见刚才添加到虚拟机的磁盘了</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.63.png" alt="1.63"></p>
<p>可以看见有两个scsi存储设备</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.64.png" alt="1.64"></p>
<blockquote>
<p>注：再次说明只有RHEL/CentOS/OEL6.x版本在线添加磁盘，虚拟机直接可以在线识别。</p>
</blockquote>
<h1 id="修改虚拟机配置文件添加新增磁盘配置"><a href="#修改虚拟机配置文件添加新增磁盘配置" class="headerlink" title="修改虚拟机配置文件添加新增磁盘配置"></a>修改虚拟机配置文件添加新增磁盘配置</h1><p>1)查看当前虚拟机配置文件<br>这里查看到的虚拟机配置文件是内存中存放的配置，重启后会消失，需要将新添的磁盘配置保存到配置文件中。</p>
<pre><code># virsh dumpxml clone-2
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.65.png" alt="1.65"></p>
<p>2)保存新增磁盘配置</p>
<pre><code># virsh edit clone-2
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.66.png" alt="1.66"></p>
<h1 id="将新增磁盘并入虚拟机逻辑卷中"><a href="#将新增磁盘并入虚拟机逻辑卷中" class="headerlink" title="将新增磁盘并入虚拟机逻辑卷中"></a>将新增磁盘并入虚拟机逻辑卷中</h1><p>(1) 分区过程如下</p>
<pre><code># fdisk /dev/vdb
# partprobe
</code></pre><p>(2) 创建逻辑卷过程如下</p>
<pre>
# pvcreate  /dev/vdb
# vgextend cl_kvm-1 /dev/vdb
# lvextend –l +100%FREE /dev/cl_kvm-1/root
# xfs_growfs /dev/cl_kvm-1/root
</pre>

<p><img src="http://oxysobnip.bkt.clouddn.com/1.67.png" alt="1.67"><br><img src="http://oxysobnip.bkt.clouddn.com/1.68.png" alt="1.68"><br><img src="http://oxysobnip.bkt.clouddn.com/1.69.png" alt="1.69"></p>
<p>至此clone-2虚拟机在线添加磁盘并在线扩展磁盘成功。</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt; kvm虚拟机也支持在线扩展磁盘功能,在线扩展有特定的使用环境，主要用于不能随便停用的生产环境中。经过测试KVM在线扩展磁盘功能只适用于RHEL/CentOS/OEL6.x环境,5.x不支持在线的扩展磁盘。&lt;/p&gt;
&lt;p&gt;本次次测试使用centos7.3的虚拟机&lt;/p&gt;
&lt;p&gt;给clone-2虚拟机在线添加磁盘&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KVM学习笔记" scheme="http://yjscloud.com/tags/KVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kvm学习笔记（四）-kvm虚拟机快照备份</title>
    <link href="http://yjscloud.com/2017/10/20/kvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89-kvm%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%BF%AB%E7%85%A7%E5%A4%87%E4%BB%BD/"/>
    <id>http://yjscloud.com/2017/10/20/kvm学习笔记（四）-kvm虚拟机快照备份/</id>
    <published>2017-10-19T23:42:15.000Z</published>
    <updated>2017-12-02T09:33:42.000Z</updated>
    
    <content type="html"><![CDATA[<p>kvm虚拟机默认使用raw格式的镜像格式，性能最好，速度最快，它的缺点就是不支持一些新的功能，如支持镜像,zlib磁盘压缩,AES加密等。要使用镜像功能，磁盘格式必须为qcow2。KMV下磁盘模式raw和qcow2的性能比较请参阅<a href="http://www.cnblogs.com/zhangzhang/archive/2012/02/13/2348928.html" target="_blank" rel="external">KMV下磁盘模式raw和qcow2的性能比较</a></p>
<p>下面开始kvm虚拟机快照备份的过程</p>
<a id="more"></a>
<h1 id="查看现有磁盘镜像格式与转换"><a href="#查看现有磁盘镜像格式与转换" class="headerlink" title="查看现有磁盘镜像格式与转换"></a>查看现有磁盘镜像格式与转换</h1><p>(1) 查看磁盘格式</p>
<pre><code># qemu-img info test01.img
</code></pre><p>raw格式需要转换成qcow2</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.45.png" alt="1.45"></p>
<p>（2）关闭虚拟机并装换磁盘</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.46.png" alt="1.46"></p>
<p>(3) 转换磁盘格式</p>
<pre><code># qemu-img convert -f raw -O qcow2 clone-2.img clone-2.qcow2 
</code></pre><p>   -f  源镜像的格式</p>
<p>   -O 目标镜像的格式<br><img src="http://oxysobnip.bkt.clouddn.com/1.47.png" alt="1.47"></p>
<p>查看转换后的格式，已经转换成了qcow2, 这里是拷贝一份，并将格式转成qcow2</p>
<pre><code># qemu-img info clone-2.qcow2
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.48.png" alt="1.48"></p>
<h1 id="修改虚拟机配置文件"><a href="#修改虚拟机配置文件" class="headerlink" title="修改虚拟机配置文件"></a>修改虚拟机配置文件</h1><p>修改磁盘格式，与新qcow2格式的磁盘。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.49.png" alt="1.49"></p>
<h1 id="对虚拟机进行快照管理"><a href="#对虚拟机进行快照管理" class="headerlink" title="对虚拟机进行快照管理"></a>对虚拟机进行快照管理</h1><p>(1) 对clone-2虚拟机创建快照</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.50.png" alt="1.50"></p>
<p>(2) 查看虚拟机镜像快照的版本</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.51.png" alt="1.51"></p>
<p>(3) 查看当前虚拟机镜像快照的版本</p>
<p>   可以看到为当前最新的快照版本。</p>
<pre><code># virsh snapshot-current clone-2
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.52.png" alt="1.52"></p>
<p>(4) 查看当前虚拟机镜像文件</p>
<p>  又创建了一个，快照的版本也记录在镜像文件中了。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.53.png" alt="1.53"></p>
<p>快照配置文件在/var/lib/libvirt/qemu/snapshot/虚拟机名称/下<br><img src="http://oxysobnip.bkt.clouddn.com/1.54.png" alt="1.54"></p>
<h1 id="恢复虚拟机快照"><a href="#恢复虚拟机快照" class="headerlink" title="恢复虚拟机快照"></a>恢复虚拟机快照</h1><p>(1) 恢复虚拟机快照必须关闭虚拟机。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.55.png" alt="1.55"></p>
<p>(2) 确认需要恢复的快照时间，这里恢复到1508285665</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.56.png" alt="1.56"></p>
<p>(3) 执行恢复，并确认恢复版本</p>
<pre><code># virsh snapshot-revert clone-2 1508285665
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.57.png" alt="1.57"></p>
<h1 id="删除虚拟机快照"><a href="#删除虚拟机快照" class="headerlink" title="删除虚拟机快照"></a>删除虚拟机快照</h1><p>(1) 查看虚拟机快照</p>
<pre><code># qemu-img info clone-2.qcow2
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.58.png" alt="1.58"></p>
<p>这里删除第一个快照1378579737</p>
<p>(2) 删除快照</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.59.png" alt="1.59"></p>
<p>到此kvm虚拟机快照测试完毕!</p>
]]></content>
    
    <summary type="html">
    
      &lt;p&gt;kvm虚拟机默认使用raw格式的镜像格式，性能最好，速度最快，它的缺点就是不支持一些新的功能，如支持镜像,zlib磁盘压缩,AES加密等。要使用镜像功能，磁盘格式必须为qcow2。KMV下磁盘模式raw和qcow2的性能比较请参阅&lt;a href=&quot;http://www.cnblogs.com/zhangzhang/archive/2012/02/13/2348928.html&quot;&gt;KMV下磁盘模式raw和qcow2的性能比较&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;下面开始kvm虚拟机快照备份的过程&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KVM学习笔记" scheme="http://yjscloud.com/tags/KVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kvm学习笔记（三）-设置VNC和时间同步</title>
    <link href="http://yjscloud.com/2017/10/20/kvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89-%E8%AE%BE%E7%BD%AEVNC%E5%92%8C%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5/"/>
    <id>http://yjscloud.com/2017/10/20/kvm学习笔记（三）-设置VNC和时间同步/</id>
    <published>2017-10-19T18:54:34.000Z</published>
    <updated>2017-12-02T09:33:25.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="设置VNC"><a href="#设置VNC" class="headerlink" title="设置VNC"></a>设置VNC</h1><p>这里的通过vnc方式访问虚拟机不是在kvm虚拟机安装配置vnc服务器，通过虚拟主机的IP地址与端口进行访问，kvm虚拟化对vnc的支持相对来说比xen要好很多，在虚拟主机上配置VNC访问虚拟机，也是为了多提供一种方式访问虚拟机。</p>
<a id="more"></a>
<h2 id="修改qemu-conf"><a href="#修改qemu-conf" class="headerlink" title="修改qemu.conf"></a>修改qemu.conf</h2><pre><code># vim  /etc/libvirt/qemu.conf
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.38.png" alt="1.38"></p>
<p>去掉第12行的注释，保存退出</p>
<p>注意：vnclisten 默认绑定127.0.0.1 在配置文件里指定VNC 绑定0.0.0.0的IP,就不用在安装kvm虚拟机时指定vnclisten参数了。在虚拟主机上有很多个虚拟机的时候，需要指定每个虚拟机的端口，否则将会很乱。</p>
<h2 id="修改虚拟机配置文件"><a href="#修改虚拟机配置文件" class="headerlink" title="修改虚拟机配置文件"></a>修改虚拟机配置文件</h2><pre><code># virsh edit clone-1
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.39.png" alt="1.39"></p>
<p>配置VNC的配置文件,port是指定端口号,autoport是自动分配端口号。</p>
<h2 id="启动虚拟机并测试VNC"><a href="#启动虚拟机并测试VNC" class="headerlink" title="启动虚拟机并测试VNC"></a>启动虚拟机并测试VNC</h2><p>启动虚拟机</p>
<pre><code># virsh start clone-1
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.40.png" alt="1.40"></p>
<p>使用vnc工具登陆</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.41.png" alt="1.41"></p>
<p>登陆成功</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.42.png" alt="1.42"></p>
<hr>
<h1 id="kvm虚拟机时间配置"><a href="#kvm虚拟机时间配置" class="headerlink" title="kvm虚拟机时间配置"></a>kvm虚拟机时间配置</h1><p>在虚拟化环境中，虚拟机在长时间运行过程中，时间会变慢，通常的作法是配置ntpdate定时与时间服务器进行时间同步的计划任务。KVM虚拟机默认采用utc时间，需要专门修改，以及考虑kvm时间同步问题。</p>
<h2 id="kvm虚拟机修改时间配置文件"><a href="#kvm虚拟机修改时间配置文件" class="headerlink" title="kvm虚拟机修改时间配置文件"></a>kvm虚拟机修改时间配置文件</h2><p>kvm虚拟机采用utc时间，需要先修改配置文件使用KVM虚拟机的时间与虚拟主机同步。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.43.png" alt="1.43"></p>
<p>修改utc为localtime，保存退出，重启虚拟机</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.44.png" alt="1.44"></p>
<h2 id="关于kvm虚拟机时间问题解决思路"><a href="#关于kvm虚拟机时间问题解决思路" class="headerlink" title="关于kvm虚拟机时间问题解决思路"></a>关于kvm虚拟机时间问题解决思路</h2><p>(1)虚拟机时间慢是所有虚拟化平台的一共性问题。</p>
<p>(2)解决时间的最终解决方法就是在生产环境中配置时间服务器，kvm虚拟化服务器与kvm机均都要配置时间同步的计划任务，这才是解决这一个问题最终解决方案。</p>
<p>示例：如果能访问互联网，最简单了，需要kvm虚拟机与主机时间同步，但是运行一段时间会慢，一定要做时间同步，特别是对时间敏感的环境。   </p>
<pre><code># crontab -e    
01 */3 * * * /usr/sbin/ntpdate cn.pool.ntp.org &gt;&gt; /dev/null 2&gt;&amp;1
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;设置VNC&quot;&gt;&lt;a href=&quot;#设置VNC&quot; class=&quot;headerlink&quot; title=&quot;设置VNC&quot;&gt;&lt;/a&gt;设置VNC&lt;/h1&gt;&lt;p&gt;这里的通过vnc方式访问虚拟机不是在kvm虚拟机安装配置vnc服务器，通过虚拟主机的IP地址与端口进行访问，kvm虚拟化对vnc的支持相对来说比xen要好很多，在虚拟主机上配置VNC访问虚拟机，也是为了多提供一种方式访问虚拟机。&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KVM学习笔记" scheme="http://yjscloud.com/tags/KVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kvm学习笔记（二）-KVM基础学习</title>
    <link href="http://yjscloud.com/2017/10/18/kvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89-KVM%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yjscloud.com/2017/10/18/kvm学习笔记（二）-KVM基础学习/</id>
    <published>2017-10-17T20:06:18.000Z</published>
    <updated>2017-12-02T09:33:03.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="kvm简绍"><a href="#kvm简绍" class="headerlink" title="kvm简绍"></a>kvm简绍</h1><p>KVM 全称是 基于内核的虚拟机（Kernel-basedVirtual Machine），它是一个 Linux 的一个内核模块，该内核模块使得 Linux 变成了一个 Hypervisor：</p>
<ul>
<li>它由 Quramnet 开发，该公司于 2008年被 Red Hat 收购。</li>
<li>它支持 x86 (32 and 64 位), s390, Powerpc 等 CPU。</li>
<li>它从 Linux 2.6.20 起就作为一模块被包含在 Linux 内核中。</li>
<li>它需要支持虚拟化扩展的 CPU。</li>
<li>它是完全开源的。</li>
</ul>
<a id="more"></a>
<p>（1）KVM特性</p>
<p>嵌入到Linux正式Kernel（提高兼容性），代码级资源调用（提高性能），虚拟机就是一个进程（内存易于管理）</p>
<p>（2）KVM虚拟化架构</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.20.png" alt="1.20"></p>
<p>（3)KVM CPU性能优化</p>
<ul>
<li>一个 KVM 虚机即一个 Linux qemu-kvm 进程，与其他Linux 进程一样被Linux 进程调度器调度。</li>
<li>KVM 虚机包括虚拟内存、虚拟CPU和虚机 I/O设备，其中，内存和 CPU 的虚拟化由 KVM 内核模块负责实现，I/O 设备的虚拟化由 QEMU 负责实现。</li>
<li>KVM户机系统的内存是 qumu-kvm 进程的地址空间的一部分。</li>
<li><p>KVM 虚机的 vCPU 作为 线程运行在 qemu-kvm 进程的上下文中。</p>
<p>CPU虚拟化<br><img src="http://oxysobnip.bkt.clouddn.com/1.21.png" alt="1.21"></p>
</li>
</ul>
<h1 id="KVM安装"><a href="#KVM安装" class="headerlink" title="KVM安装"></a>KVM安装</h1><h2 id="检查主机是否支持虚拟化"><a href="#检查主机是否支持虚拟化" class="headerlink" title="检查主机是否支持虚拟化"></a>检查主机是否支持虚拟化</h2><p>   打开您的虚拟机的虚拟化引擎</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.22.png" alt="1.22"></p>
<pre>
# egrep -c '(vmx|svm)' /proc/cpuinfo
</pre>

<p>命令结果大于0表示cpu支持虚拟化</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.23.png" alt="1.23"></p>
<p>最好关闭防火墙和关闭selinux</p>
<pre>
# systemctl stop firewalld
# systemctl disable firewalld
# vim /etc/selinux/config
    将enforcing改为disabled
</pre>

<h2 id="配置本地yum源"><a href="#配置本地yum源" class="headerlink" title="配置本地yum源"></a>配置本地yum源</h2><p>替换CentOS默认源，默认生产环境上不了外网，所以你得想办法用自己的内部Yum源，如果没有，需要搭建一个。让系统上网，然后运行下面命令：</p>
<pre>
# cd /etc/yum.repos.d
# rm -rf *
# wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo
# wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo
</pre>

<p>在我的实验环境中我已经搭好了本地yum源，在这里我直接使用本地yum源，下面是我的yum配置文件</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.24.png" alt="1.24"></p>
<h2 id="安装kvm以及相应的依赖包"><a href="#安装kvm以及相应的依赖包" class="headerlink" title="安装kvm以及相应的依赖包"></a>安装kvm以及相应的依赖包</h2><p>安装依赖包</p>
<pre>
# yum -y groupinstall "Virtualization Host"
# yum -y install virt-{install,viewer,manager} 
</pre>

<p>相关组件介绍</p>
<p>【1】libvirt：操作和管理KVM虚机的虚拟化 API，使用 C 语言编写，可以由 Python,Ruby, Perl, PHP, Java 等语言调用。可以操作包括 KVM，vmware，XEN，Hyper-v, LXC 等 Hypervisor。</p>
<p>【2】Virsh：基于 libvirt 的 命令行工具 （CLI）</p>
<p>【3】Virt-Manager：基于 libvirt 的 GUI 工具</p>
<p>kvm内核模块</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.25.png" alt="1.25"></p>
<h2 id="配置网卡为桥接模式"><a href="#配置网卡为桥接模式" class="headerlink" title="配置网卡为桥接模式"></a>配置网卡为桥接模式</h2><pre>
# cd /etc/sysconfig/network-scripts/
# cp ifcfg-eno16777736 ifcfg-br0
</pre>

<p>我的配置文件</p>
<pre>
[root@kvm network-scripts]# cat ifcfg-eno16777736 
TYPE="Ethernet"
DEVICE="eno16777736"
NAME="eno16777736"
BRIDGE=br0
[root@kvm network-scripts]# cat ifcfg-br0 
TYPE=Bridge
NAME=br0
DEVICE=br0
IPADDR=172.31.129.95
NETMASK=255.255.255.0
GATEWAY=172.31.129.254
</pre>

<h2 id="创建虚拟机硬盘"><a href="#创建虚拟机硬盘" class="headerlink" title="创建虚拟机硬盘"></a>创建虚拟机硬盘</h2><pre>
# qemu-img create -f qcow2 /mnt/vm-test/iso/centos-7.2.qcow2 10G
# chown qemu:qemu /mnt/vm-test/iso/centos-7.2.qcow2 -R
</pre>

<h2 id="创建虚拟机"><a href="#创建虚拟机" class="headerlink" title="创建虚拟机"></a>创建虚拟机</h2><pre>
[root@kvm iso]# virt-install --virt-type kvm --name centos-7.2 --ram 512 \    # name 是自己取得
> --vcpus 1 \        #指定cpu核数
> --cdrom=CentOS-7-x86_64-DVD-1511.iso \  #指定镜像
> --disk centos-7.2.qcow2,format=qcow2 \    #disk参数为上面创建的磁盘
> --network network=default \  #网络设置为默认网络（NAT）
> --graphics vnc,listen=0.0.0.0 --noautoconsole \ #运行所有网段远程，远程方式采用vnc
> --os-type=linux --os-variant=rhel7 #指定系统类型
</pre>

<p>桥接网卡位置</p>
<pre>
virt-install --virt-type kvm --name centos-7.2 --ram 512 --vcpus 1 --cdrom=CentOS-7-x86_64-DVD-1511.iso --disk centos7.2.qcow2,format=qcow2 --network bridge=virbr0 --vnc --vncport=5910 --vnclisten=0.0.0.0  --os-type=linux --os-variant=rhel7
</pre>

<h2 id="远程虚拟机"><a href="#远程虚拟机" class="headerlink" title="远程虚拟机"></a>远程虚拟机</h2><p>查看端口：netstat –natp</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.26.png" alt="1.26"></p>
<p>在vnc输入172.31.129.95:5900即可远程虚拟机</p>
<h1 id="KVM命令介绍"><a href="#KVM命令介绍" class="headerlink" title="KVM命令介绍"></a>KVM命令介绍</h1><h2 id="virsh"><a href="#virsh" class="headerlink" title="virsh"></a>virsh</h2><p>virsh:虚拟化交互式终端</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.27.png" alt="1.27"></p>
<ul>
<li>virsh list  # 显示本地活动虚拟机</li>
<li>virsh start kvm_name # 启动非活动虚拟机, kvm_name为你的虚拟机名字</li>
<li>virsh create kvm_name.xml  # 创建虚拟机（创建后，虚拟机立即执行，成为活动主机）</li>
<li>virsh suspend kvm_name # 暂停虚拟机</li>
<li>virsh resume kvm_name # 启动暂停的虚拟机</li>
<li>virsh shutdown kvm_name # 正常关闭虚拟机</li>
<li>virsh destroy kvm_name # 强制关闭虚拟机</li>
<li>virsh dominfo kvm_name # 显示虚拟机的基本信息</li>
<li>virsh dumpxml kvm_name # 显示虚拟机的当前配置文件</li>
<li>virsh setmem kvm_name 51200 # 给不活动虚拟机设置内存大小</li>
<li>virsh setvcpus kvm_name 4  # 给不活动虚拟机设置cpu个数</li>
<li><p>virsh edit kvm_name # 编辑配置文件（一般用在刚定义完VM）</p>
<p>虚拟机配置文件路径：/etc/libvirt/qemu</p>
</li>
</ul>
<h2 id="虚拟化vcpu操作"><a href="#虚拟化vcpu操作" class="headerlink" title="虚拟化vcpu操作"></a>虚拟化vcpu操作</h2><pre>
# yum -y install numactl
</pre>

<ul>
<li>nodeinfo #查看节点配置信息</li>
<li>dominfo    #查看虚拟机节点配置信息</li>
<li>numactl –hardware #查看节点硬件信息</li>
<li>numastat –c qemu-kvm</li>
<li>virsh<ul>
<li>vcpuinfo kvm_name #查看运行在那个逻辑cpu上</li>
<li>emulatorpin kvm_name #查看可以调度逻辑cpu</li>
<li>emulatorpin kvm_name 1-2 –live #限制可以调度逻辑cpu(重启生效)<br><img src="http://oxysobnip.bkt.clouddn.com/1.28.png" alt="1.28"></li>
</ul>
</li>
</ul>
<p>虚拟机cpu优化</p>
<p>vcpu单独强制绑定</p>
<ul>
<li>vcpupin kvm_name 0 1</li>
<li>vcpupin kvm_name 1 2</li>
<li>vcpuinfo</li>
<li>dumpxml kvm_name</li>
</ul>
<p>命令使用参考文章：<br><a href="http://hl914.blog.51cto.com/4128173/1557615/" target="_blank" rel="external">CPU性能监控之二—–Numa架构下进程与CPU绑定</a></p>
<p><a href="http://blog.csdn.net/shaoyunzhe/article/details/53606584" target="_blank" rel="external">numa总结</a></p>
<h2 id="安装acpid"><a href="#安装acpid" class="headerlink" title="安装acpid"></a>安装acpid</h2><p>默认情况下virsh工具不能对linux虚拟机进行关机操作，linux操作系统需要开启与启动acpid服务。在安装KVM linux虚拟机必须配置此服务。 </p>
<pre>
# yum install -y acpid
# systemctl enable acpid
</pre>

<h2 id="克隆虚拟机"><a href="#克隆虚拟机" class="headerlink" title="克隆虚拟机"></a>克隆虚拟机</h2><p>（1）根据模板文件修改</p>
<ul>
<li>进入对应目录拷贝模板文件</li>
</ul>
<pre>
# cd /etc/libvirt/qemu
# cp centos-7.2.xml clone-1.xml
</pre>

<ul>
<li>修改虚拟名称</li>
<li>删除uuid</li>
</ul>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.29.png" alt="1.29"></p>
<ul>
<li>指定disk</li>
</ul>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.30.png" alt="1.30"></p>
<ul>
<li>删除mac</li>
</ul>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.31.png" alt="1.31"></p>
<ul>
<li>修改vnc远程允许端口（可选）</li>
</ul>
<p>如果您上面选择桥接模式创建虚拟机且指定了端口5910，请您把5910改为5911，这样可以避免与centos7.3的端口冲突</p>
<p>（2）复制qcow2文件</p>
<pre>
# cp centos-7.2.qcow2 clone-1.qcow2
</pre>

<p>（3）virsh define 模板文件路径</p>
<pre>
# virsh define /etc/libvirt/qemu/clone-1.xml
</pre>

<p>（4）启动虚拟机</p>
<pre>
# virsh start clone-1
</pre>

<p>（5）删除克隆的虚拟机</p>
<pre>
# virsh shutdown clone-1
# virsh undefine clone-1
# rm –rf /mnt/vm-test/clone-1.qcow2
</pre>

<p>（6）一个小坑</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.32.png" alt="1.32"></p>
<p>这一行位置在第86行，修改配置文件时一定要删除，不知道为什么，它会出现在CentOS7.2版本的系统中，而在CentOS7.3版本的系统中不会出现这一行代码！</p>
<h2 id="虚拟机快照snapshot"><a href="#虚拟机快照snapshot" class="headerlink" title="虚拟机快照snapshot"></a>虚拟机快照snapshot</h2><pre>
virsh # snapshot-create-as centos-7.2 kuaizhao #创建虚拟机centos-7.2的快照，快照名字为kuaizhao
Domain snapshot kuaizhao created
virsh # snapshot-list centos-7.2 #显示虚拟机快照的名称
 Name                 Creation Time             State
------------------------------------------------------------
 kuaizhao             2017-10-17 09:53:49 +0800 shutoff

virsh # snapshot-revert centos-7.2 kuaizhao #恢复快照
</pre>

<h2 id="添加磁盘"><a href="#添加磁盘" class="headerlink" title="添加磁盘"></a>添加磁盘</h2><p>(1)创建磁盘</p>
<pre>
# qemu-img create -f qcow2 /mnt/vm-test/ios/testadd.qcow2 10G
</pre>

<p>(2)修改配置文件</p>
<pre>
# virsh edit centos-7.2
</pre>

<p>添加以下内容并保存配置文件</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">disk</span> <span class="attr">type</span>=<span class="string">'file'</span> <span class="attr">device</span>=<span class="string">'disk'</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">driver</span> <span class="attr">name</span>=<span class="string">'qemu'</span> <span class="attr">type</span>=<span class="string">'qcow2'</span>/&gt;</span></div><div class="line">   	<span class="tag">&lt;<span class="name">source</span> <span class="attr">file</span>=<span class="string">'/mnt/vm-test/ios/testadd.qcow2'</span>/&gt;</span></div><div class="line">   <span class="tag">&lt;<span class="name">target</span> <span class="attr">dev</span>=<span class="string">'vdb'</span> <span class="attr">bus</span>=<span class="string">'virtio'</span>/&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">disk</span>&gt;</span></div></pre></td></tr></table></figure>
<pre>
# virsh create /etc/libvirt/qemu/centos-7.2.xml
# virsh destroy centos-7.2
# virsh start centos-7.2
</pre>

<p>重启后进入虚拟机查看</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.33.png" alt="1.33"></p>
<p>(3)直接扩展qcow2磁盘</p>
<p>qcow2格式的好处就是支持直接扩展，下面我们关闭虚拟机直接对磁盘进行扩容</p>
<pre><code># qemu-img resize clone-3.qcow2 +10G
</code></pre><p><img src="http://oxysobnip.bkt.clouddn.com/1.35-1.png" alt="1.35-1"></p>
<p>经过前后对比，磁盘大小已由20G扩展到30G,已扩展,qcow2磁盘格式必须采用此方式进行扩展!</p>
<h2 id="kvm虚拟机的网络模式"><a href="#kvm虚拟机的网络模式" class="headerlink" title="kvm虚拟机的网络模式"></a>kvm虚拟机的网络模式</h2><p>(1)nat网络模式</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.34.png" alt="1.34"></p>
<p>(2)桥接模式</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.35.png" alt="1.35"></p>
<p>（3）添加NAT网络</p>
<p> 定义一个虚拟网络</p>
<pre>
# virsh net-define /usr/share/libvirt/networks/default.xml
</pre>

<p>添加内容</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">network</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">name</span>&gt;</span>default<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">bridge</span> <span class="attr">name</span>=<span class="string">"virbr0"</span> /&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">forward</span>/&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">ip</span> <span class="attr">address</span>=<span class="string">"192.168.122.1"</span> <span class="attr">netmask</span>=<span class="string">"255.255.255.0"</span>&gt;</span></div><div class="line">	<span class="tag">&lt;<span class="name">dhcp</span>&gt;</span></div><div class="line">		<span class="tag">&lt;<span class="name">range</span> <span class="attr">start</span>=<span class="string">"192.168.122.2"</span> <span class="attr">end</span>=<span class="string">"192.168.122.254"</span> /&gt;</span></div><div class="line">	<span class="tag">&lt;/<span class="name">dhcp</span>&gt;</span></div><div class="line">	<span class="tag">&lt;/<span class="name">ip</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">network</span>&gt;</span></div></pre></td></tr></table></figure>
<p>设置为自动启动</p>
<pre>
# virsh net-autostart default
</pre>

<p>查看网络</p>
<pre>
# brctl show
</pre>

<p>修改/etc/sysctl.conf中参数，允许ip转发</p>
<pre>
# net.ipv4.ip_forward=1
</pre>

<p>修改虚拟机配置文件</p>
<pre>
# virsh edit centos-7.2
</pre>

<p>修改网卡链接模式</p>
<p>桥接模式</p>
<pre><code>&lt;interface type=&apos;bridge&apos;&gt;
    &lt;source bridge=&apos;br0&apos;/&gt;
    &lt;model type=&apos;virtio&apos;/&gt;
    &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x02&apos; function=&apos;0x0&apos;/&gt;
&lt;/interface&gt;
</code></pre><p>nat模式</p>
<pre><code>&lt;interface type=&apos;network&apos;&gt;
    &lt;source network=&apos;default&apos;/&gt;
    &lt;model type=&apos;virtio&apos;/&gt;
    &lt;address type=&apos;pci&apos; domain=&apos;0x0000&apos; bus=&apos;0x00&apos; slot=&apos;0x03&apos; function=&apos;0x0&apos;/&gt;
&lt;/interface&gt; 
</code></pre><p>修改完之后，保存退出。</p>
<pre>
# virsh create /etc/libvirt/qemu/centos-7.2.xml
</pre>

<ol>
<li><p>修改桥接后nat不能上网问题</p>
<p>默认配置文件：（virsh交互界面）</p>
</li>
</ol>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.36.png" alt="1.36"></p>
<p>将默认配置文件修改为：</p>
<pre>
# vim /etc/libvirt/qemu/networks/default.xml
</pre>

<p><img src="http://oxysobnip.bkt.clouddn.com/1.37.png" alt="1.37"></p>
<p>然后再执行如下命令</p>
<pre>
virsh # net-define /etc/libvirt/qemu/networks/default.xml
virsh # net-destroy default
virsh # net-start default
</pre>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;kvm简绍&quot;&gt;&lt;a href=&quot;#kvm简绍&quot; class=&quot;headerlink&quot; title=&quot;kvm简绍&quot;&gt;&lt;/a&gt;kvm简绍&lt;/h1&gt;&lt;p&gt;KVM 全称是 基于内核的虚拟机（Kernel-basedVirtual Machine），它是一个 Linux 的一个内核模块，该内核模块使得 Linux 变成了一个 Hypervisor：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;它由 Quramnet 开发，该公司于 2008年被 Red Hat 收购。&lt;/li&gt;
&lt;li&gt;它支持 x86 (32 and 64 位), s390, Powerpc 等 CPU。&lt;/li&gt;
&lt;li&gt;它从 Linux 2.6.20 起就作为一模块被包含在 Linux 内核中。&lt;/li&gt;
&lt;li&gt;它需要支持虚拟化扩展的 CPU。&lt;/li&gt;
&lt;li&gt;它是完全开源的。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KVM学习笔记" scheme="http://yjscloud.com/tags/KVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>kvm学习笔记（一）——虚拟化介绍</title>
    <link href="http://yjscloud.com/2017/10/18/kvm%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89-%E8%99%9A%E6%8B%9F%E5%8C%96%E4%BB%8B%E7%BB%8D/"/>
    <id>http://yjscloud.com/2017/10/18/kvm学习笔记（一）-虚拟化介绍/</id>
    <published>2017-10-17T19:04:16.000Z</published>
    <updated>2017-12-02T09:32:38.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="什么是系统虚拟化"><a href="#什么是系统虚拟化" class="headerlink" title="什么是系统虚拟化"></a>什么是系统虚拟化</h2><p>系统虚拟化是将底层物理设备与上层操作系统、软件分离的一种去耦合技术，在一台物理机器上逻辑的划分出多台机器。虚拟化的目标是实现IT资源利用效率和灵活性的最大化</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.1.png" alt="1.1"></p>
<p>多个系统融合在一台服务器上——资源利用率高 资源利用率高<br>应用系统不再依赖特定的硬件——系统维护灵活</p>
<a id="more"></a>
<h2 id="虚拟化基础架构"><a href="#虚拟化基础架构" class="headerlink" title="虚拟化基础架构"></a>虚拟化基础架构</h2><p><img src="http://oxysobnip.bkt.clouddn.com/1.2.png" alt="1.2"></p>
<h2 id="虚拟化"><a href="#虚拟化" class="headerlink" title="虚拟化"></a>虚拟化</h2><p>在一台物理主机上虚拟出多个虚拟计算机（虚拟机，Virtual Machine，VM），其上能同时运行多个独立的操作系统，这些客户操作系统（Guest OS）通过虚拟机管理器（Virtual Machine Monitor，VMM，也称作Hypervisor）访问实际的物理资源。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.3.png" alt="1.3"></p>
<h2 id="为什么需要使用虚拟化"><a href="#为什么需要使用虚拟化" class="headerlink" title="为什么需要使用虚拟化"></a>为什么需要使用虚拟化</h2><p>公司服务器越来越多</p>
<p>   – 充分利用是个问题</p>
<p>   – 统一运维管理是个问题</p>
<ul>
<li>浪费时间</li>
<li>操作繁琐</li>
<li>机器闲置时间较多</li>
</ul>
<p>计算系统利用率不高！</p>
<p>  “多数用户承认，计算系统平均利用率只有25%～30%”</p>
<h2 id="为什么客户要选择服务器虚拟化？"><a href="#为什么客户要选择服务器虚拟化？" class="headerlink" title="为什么客户要选择服务器虚拟化？"></a>为什么客户要选择服务器虚拟化？</h2><p><img src="http://oxysobnip.bkt.clouddn.com/1.4.png" alt="1.4"></p>
<ol>
<li>打破“一台服务器对应一套应用”的模式，将物理服务器进行整合，提升利用率</li>
<li>服务器和相关IT硬件更少，节省了机房空间，也减少了散热和电力需求</li>
<li>具备灵活数据备份和应用迁移机制，保障服务永不中断</li>
<li>资源动态调配和模板化部署，应用系统快速上线，及时响应业务变化</li>
</ol>
<h2 id="虚拟化技术分类"><a href="#虚拟化技术分类" class="headerlink" title="虚拟化技术分类"></a>虚拟化技术分类</h2><p><img src="http://oxysobnip.bkt.clouddn.com/1.5.png" alt="1.5"></p>
<h2 id="什么是桌面虚拟化？"><a href="#什么是桌面虚拟化？" class="headerlink" title="什么是桌面虚拟化？"></a>什么是桌面虚拟化？</h2><p>桌面虚拟化（MS：Remote Desktop、Citrix：XenDesktop、Vmware：View）</p>
<p>   − 将原本在本地电脑安装的桌面系统统一在后端数据中心进行部署和管理；</p>
<p>   − 用户可以通过任何设备，在任何地点，任何时间访问属于自己的桌面系统环境。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.6.png" alt="1.6"></p>
<h2 id="服务器虚拟化"><a href="#服务器虚拟化" class="headerlink" title="服务器虚拟化"></a>服务器虚拟化</h2><p><img src="http://oxysobnip.bkt.clouddn.com/1.7.png" alt="1.7"></p>
<h2 id="cpu"><a href="#cpu" class="headerlink" title="cpu"></a>cpu</h2><p>【1】无虚拟化</p>
<p>   – CPU一般设为四个Ring</p>
<p>   – Kernel Mode一般跑在Ring 0上</p>
<p>   – User Mode一般跑在Ring 3上</p>
<p>   – 对于一个普通的传统的Linux系统没有问题</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.8.png" alt="1.8"></p>
<p>【2】虚拟化</p>
<p>   – 在Guest机器和Host机器中间加一层Hypervisor</p>
<p>   – Host机器看它像跑在自己上面的程序</p>
<p>   – Guest机器看它像自己所运行的硬件</p>
<p>   – 如果Host机器和Guest机器都跑相同的Linux，它们的Kernel都想运行在Ring 0，可怎么办？</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.9.png" alt="1.9"></p>
<p>【3】传统cpu工作模式</p>
<p>   – X86 操作系统是设计在直接运行在裸硬件设备上的，因此它们自动认为它们完全占有计算机硬件。x86 架构提供四个特权级别给操作系统和应用程序来访问硬件。 Ring 是指 CPU 的运行级别，Ring 0是最高级别，Ring1次之，Ring2更次之…… 就 Linux+x86 来说，</p>
<p>   – 操作系统（内核）需要直接访问硬件和内存，因此它的代码需要运行在最高运行级别 Ring0上，这样它可以使用特权指令，控制中断、修改页表、访问设备等等。</p>
<p>   – 应用程序的代码运行在最低运行级别上ring3上，不能做受控操作。如果要做，比如要访问磁盘，写文件，那就要通过执行系统调用（函数），执行系统调用的时候，CPU的运行级别会发生从ring3到ring0的切换，并跳转到系统调用对应的内核代码位置执行，这样内核就为你完成了设备访问，完成之后再从ring0返回ring3。这个过程也称作用户态和内核态的切换。</p>
<p>【4】为什么需要 为什么需要 CPU 虚拟化</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.10.png" alt="1.10"></p>
<h2 id="虚拟化分类"><a href="#虚拟化分类" class="headerlink" title="虚拟化分类"></a>虚拟化分类</h2><p>   虚拟化在这里就遇到了一个难题，因为宿主操作系统是工作在 ring0 的，客户操作系统就不能也在 ring0 了，但是它不知道这一点，以前执行什么指令，现在还是执行什么指令，但是没有执行权限是会出错的。所以这时候虚拟机管理程序（VMM）需要避免这件事情发生。 虚机怎么通过 VMM 实现 Guest CPU 对硬件的访问，根据其原理不同有三种实现技术：</p>
<p>【1】基于二进制翻译的全虚拟化（Full Virtualization with Binary Translation）</p>
<p>   客户操作系统运行在 Ring 1，它在执行特权指令时，会触发异常（CPU的机制，没权限的指令会触发异常），然后 VMM捕获这个异常，在异常里面做翻译，模拟，最后返回到客户操作系统内，客户操作系统认为自己的特权指令工作正常，继续运行。但是这个性能损耗，就非常的大， 简单的一条指令，执行完，了事，现在却要通过复杂的异常处理过程</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.11.png" alt="1.11"></p>
<p>异常 “捕获（trap）-翻译（handle）-模拟（emulate）” 过程：</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.12.png" alt="1.12"></p>
<p>【2】 超虚拟化（或者半虚拟化/操作系统辅助虚拟化 Paravirtualization）</p>
<p>   半虚拟化的思想就是，修改操作系统内核，替换掉不能虚拟化的指令，通过超级调用（hypercall）直接和底层的虚拟化层hypervisor来通讯，hypervisor 同时也提供了超级调用接口来满足其他关键内核操作，比如内存管理、中断和时间保持。这种做法省去了全虚拟化中的捕获和模拟，大大提高了效率。所以像XEN这种半虚拟化技术，客户机操作系统都是有一个专门的定制内核版本，和x86、mips、arm这些内核版本等价。这样以来，就不会有捕获异常、翻译、模拟的过程了，性能损耗非常低。这就是XEN这种半虚拟化架构的优势。这也是为什么XEN只支持虚拟化Linux，无法虚拟化windows原因，微软不改代码啊。</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.13.png" alt="1.13"></p>
<p>【3】硬件辅助的全虚拟化</p>
<p>   2005年后，CPU厂商Intel 和 AMD 开始支持虚拟化了。Intel 引入了 Intel-VT （Virtualization Technology）技术。这种 CPU，有 VMX root operation 和 VMX non-root operation两种模式，两种模式都支持Ring 0 ~ Ring 3 共 4个运行级别。这样，VMM 可以运行在 VMX root operation模式下，客户 OS 运行在VMX non-root operation模式下。也就说，硬件这层就做了些区分，这样全虚拟化下，那些靠“捕获异常-翻译-模拟”的实现就不需要了。而且CPU厂商，支持虚拟化的力度越来越大，靠硬件辅助的全虚拟化技术的性能逐渐逼近半虚拟化，再加上全虚拟化不需要修改客户操作系统这一优势，全虚拟化技术应该是未来的发展趋势</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.14.png" alt="1.14"></p>
<h2 id="三种虚拟化技术的比较"><a href="#三种虚拟化技术的比较" class="headerlink" title="三种虚拟化技术的比较"></a>三种虚拟化技术的比较</h2><p><img src="http://oxysobnip.bkt.clouddn.com/1.15.png" alt="1.15"></p>
<h2 id="全虚拟化-vs-半虚拟化"><a href="#全虚拟化-vs-半虚拟化" class="headerlink" title="全虚拟化 vs 半虚拟化"></a>全虚拟化 vs 半虚拟化</h2><p><img src="http://oxysobnip.bkt.clouddn.com/1.16.png" alt="1.16"></p>
<h2 id="服务器虚拟化方法"><a href="#服务器虚拟化方法" class="headerlink" title="服务器虚拟化方法"></a>服务器虚拟化方法</h2><p>【1】全虚拟化(Full-Virtulization)：无需修改操作系统， VM ESXi、Linux KVM</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.17.png" alt="1.17"></p>
<p>【2】半虚拟化(Para-Virtulization)：集成半虚拟化代码，直接运行特权指令，性能接近物理机，需要修改操作系统，MS Hyper-V、 Ctrix Xen、IBM PowerVM</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.18.png" alt="1.18"></p>
<p>【3】操作系统层虚拟化：开发、测试环境，VM Workstation、VM Server、Oracle VitrualBox</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/1.19.png" alt="1.19"></p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;什么是系统虚拟化&quot;&gt;&lt;a href=&quot;#什么是系统虚拟化&quot; class=&quot;headerlink&quot; title=&quot;什么是系统虚拟化&quot;&gt;&lt;/a&gt;什么是系统虚拟化&lt;/h2&gt;&lt;p&gt;系统虚拟化是将底层物理设备与上层操作系统、软件分离的一种去耦合技术，在一台物理机器上逻辑的划分出多台机器。虚拟化的目标是实现IT资源利用效率和灵活性的最大化&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://oxysobnip.bkt.clouddn.com/1.1.png&quot; alt=&quot;1.1&quot;&gt;&lt;/p&gt;
&lt;p&gt;多个系统融合在一台服务器上——资源利用率高 资源利用率高&lt;br&gt;应用系统不再依赖特定的硬件——系统维护灵活&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="KVM学习笔记" scheme="http://yjscloud.com/tags/KVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>CloudStack搭建指南（三）</title>
    <link href="http://yjscloud.com/2017/09/19/CloudStack%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97%EF%BC%88%E4%B8%89%EF%BC%89/"/>
    <id>http://yjscloud.com/2017/09/19/CloudStack搭建指南（三）/</id>
    <published>2017-09-19T06:11:56.000Z</published>
    <updated>2017-10-18T05:30:13.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Open-vSwitch简介"><a href="#Open-vSwitch简介" class="headerlink" title="Open vSwitch简介"></a>Open vSwitch简介</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>Open vSwitch的官方定义：Open vSwitch是一个具有工业级质量的多层虚拟交换机。通过可编程扩展，可以实现大规模网络的自动化（配置、管理、维护）。它支持现有标准管理接口和协议（比如netFlow，sFlow，SPAN，RSPAN，CLI，LACP，802.1ag等，熟悉物理网络维护的管理员可以毫不费力地通过Open vSwitch转向虚拟网络管理）。</p>
<a id="more"></a>
<p><img src="http://owawy15xy.bkt.clouddn.com/%E4%B8%89-1.png" alt="三-1"></p>
<h2 id="模块介绍"><a href="#模块介绍" class="headerlink" title="模块介绍"></a>模块介绍</h2><p><img src="http://owawy15xy.bkt.clouddn.com/%E4%B8%89-2.png" alt="三-2"></p>
<p>最新代码包主要包括以下模块和特性：</p>
<p>ovs-vswitchd ：核心模块，实现交换功能的守护程序（daemon），和Linux内核模块一起，实现基于流的交换；</p>
<p>ovsdb-server ：提供轻量级数据库查询服务。其保存了整个OVS的配置信息，包括接口，流表，VLAN等。ovs-vswitchd从其查询配置信息；</p>
<p>ovsdb-tool: 不通过ovs-server就能直接操控数据库；</p>
<p>ovsdb-client: 直接通过ovs-server数据库操作；</p>
<p>ovs-brcompatd ：让 ovs-vswitch 替换 Linux bridge，包括获取 bridge ioctls 的 Linux 内核模块；</p>
<p>ovs-dpctl ：dapapath control.  用来配置 switch 内核模块，可以控制转发规则；</p>
<p>ovs-vsctl ：获取或者更改ovs-vswitchd的配置信息，此工具操作的时候会更新ovsdb-server数据库；</p>
<p>ovs-appctl ：openvswitch apply control, 发送命令来运行相关 daemon(很少使用)；</p>
<p>ovsdbmonitor GUI 工具，用于显示 OVS 数据库中的相关数据；</p>
<p>此外， OVS 也提供了支持 OpenFlow 的特性实现，包括</p>
<p>ovs-openflowd： 一个简单的 OpenFlow 交换机；</p>
<p>ovs-controller： 一个简单的 OpenFlow 控制器；</p>
<p>ovs-ofctl :openvswitch openflow control,用来控制OVS作为OpenFlow交换机工作时的流表内容；</p>
<p>ovs-pki ： OpenFlow 交换机创建和管理公钥框架；</p>
<p>ovs-tcpundump： 实现类似tcpdump 的抓包分析功能。</p>
<h1 id="CloudStack的高级网络"><a href="#CloudStack的高级网络" class="headerlink" title="CloudStack的高级网络"></a>CloudStack的高级网络</h1><h2 id="高级网络"><a href="#高级网络" class="headerlink" title="高级网络"></a>高级网络</h2><p>每个区域都有基本或高级网络。一个区域的整个生命周期中，不论是基本或高级网络。一旦在CloudStack中选择并配置区域的网络类型，就无法再修改。</p>
<p>下表比较了两种网络类型的功能</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/%E4%B8%89-3.png" alt="三-3"></p>
<p>在一个云中可能会存在二种网络类型。但无论如何，一个给定的区域必须使用基本网络或高级网络。单一的物理网络可以被分割不同类型的网络流量。账户也可以分割来宾流量。你可以通过划分VLAN来隔离流量。如果你在物理网络中划分了VLAN，确保VLAN标签的数值在独立范围。</p>
<h2 id="在CloudStack-中使用-Open-vSwitch"><a href="#在CloudStack-中使用-Open-vSwitch" class="headerlink" title="在CloudStack 中使用 Open vSwitch"></a>在CloudStack 中使用 Open vSwitch</h2><p>Open vSwitch是由 Nicira Networks 主导的，运行在虚拟化平台（例如 KVM，Xen）上的虚拟交换机。在虚拟化平台上，OVS 可以为动态变化的端点提供 2 层交换功能，很好的控制虚拟网络中的访问策略、网络隔离、流OVS主要是用来在虚拟化环境中。虚拟机之间一个虚拟机和外网之间的通信所用，如下是一个典型的结构图：</p>
<p>那么，通常情况下的工作流程如下：</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/%E4%B8%89-4.png" alt="三-4"></p>
<p>（1）VM实例instance产生一个数据包并发送至实例内的虚拟网络接口VNIC，图中就是instance中的eth0.</p>
<p>（2）这个数据包会传送到物理节点上的VNIC接口，如图就是vnet接口。</p>
<p>（3）数据包从vnet NIC出来，到达桥（虚拟交换机）br100上。</p>
<p>（4）数据包经过交换机的处理，从物理节点上的物理接口发出，如图中物理节点上的eth0。</p>
<p>（5）数据包从eth0出去的时候，是按照物理节点上的路由以及默认网关操作的，这个时候该数据包其实已经不受你的控制了。</p>
<h2 id="OVS-的基本操作"><a href="#OVS-的基本操作" class="headerlink" title="OVS 的基本操作"></a>OVS 的基本操作</h2><p>以下操作都需要root权限运行，在所有命令中br0表示网桥名称，eth0为网卡名称。</p>
<p>添加网桥：</p>
<pre><code># ovs-vsctl add-br br0
</code></pre><p>列出open vswitch中的所有网桥：</p>
<pre><code># ovs-vsctl list-br
</code></pre><p>判断网桥是否存在</p>
<pre><code># ovs-vsctl br-exists br0
</code></pre><p>将物理网卡挂接到网桥：</p>
<pre><code># ovs-vsctl add-port br0 eth0
</code></pre><p>列出网桥中的所有端口：</p>
<pre><code># ovs-vsctl list-ports br0
</code></pre><p>列出所有挂接到网卡的网桥：</p>
<pre><code># ovs-vsctl port-to-br eth0
</code></pre><p>查看open vswitch的网络状态：</p>
<pre><code># ovs-vsctl show
</code></pre><p>删除网桥上已经挂接的网口：</p>
<pre><code># vs-vsctl del-port br0 eth0
</code></pre><p>删除网桥：</p>
<pre><code># ovs-vsctl del-br br0量监控等等。
</code></pre><h1 id="虚拟机网络设置"><a href="#虚拟机网络设置" class="headerlink" title="虚拟机网络设置"></a>虚拟机网络设置</h1><h2 id="设置虚拟机的虚拟网络编辑器"><a href="#设置虚拟机的虚拟网络编辑器" class="headerlink" title="设置虚拟机的虚拟网络编辑器"></a>设置虚拟机的虚拟网络编辑器</h2><p>(1)添加两个自定义网络</p>
<p>VMnet2子网设置为：10.5.5.0，起始ip为：10.5.5.128，结束ip为：10.5.5.254。</p>
<p>VMnet3子网设置为：10.5.6.0，起始ip为：10.5.6.128，结束ip为：10.5.6.254。</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs-01.png" alt="ovs-01"></p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs-02.png" alt="ovs-02"></p>
<p>（2)进入为master节点虚拟机添加网卡</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs-03.png" alt="ovs-03"></p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs-04.png" alt="ovs-04"></p>
<p>确保可以ping同新加的网卡</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs-05.png" alt="ovs-05"></p>
<p>在agent1和agent2节点上重复以上操作，要确保新加的网卡都可用！</p>
<h1 id="清理环境"><a href="#清理环境" class="headerlink" title="清理环境"></a>清理环境</h1><p>（1)关闭系统虚拟机s-1-VM和v-2-VM</p>
<p>（2)禁用资源域</p>
<p>（3)进入agent1和agent2删除eth0 网卡配置文件中的桥接网卡cloudbr0，然后删除ifcfg-cloudbr0网卡配置文件。</p>
<p>（4)使用命令：</p>
<pre><code># virsh list --all
</code></pre><p>如果发现系统VM还在运行直接重启两台agent节点。</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs-06.png" alt="ovs-06"></p>
<p>（5)确认网络环境：</p>
<pre><code># brctl show
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/ovs-07.png" alt="ovs-7"></p>
<p>（6)关闭cloudstack-management</p>
<pre><code># /etc/init.d/cloudstack-management stop
</code></pre><p>（7)清除master节点数据库</p>
<p>进入数据库：</p>
<pre><code>#    mysql -uroot -p123456
</code></pre><p>删库：</p>
<pre><code># drop database cloud;
# drop database cloud_usage;
</code></pre><h1 id="安装openvswitch"><a href="#安装openvswitch" class="headerlink" title="安装openvswitch"></a>安装openvswitch</h1><p>（1)把编译好的rpm上传到合适的文件夹，然后安装</p>
<pre><code># rpm -i openvswitch-2.3.2-1.x86_64.rpm kmod-openvswitch-2.3.2-1.el6.x86_64.rpm --force –nodeps
</code></pre><p>这里不采用yum的安装方式，因为用yum安装会报一个很严重的错误，现在暂时无法解决这个报错，所以我们采用强制安装的方法，后期部署时发现并没有什么问题。</p>
<p>（2)为了确保openvswitch安装好了，我们是使用命令检查一下</p>
<pre><code># rpm -qa|grep openvswitch
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/ovs-08.png" alt="ovs-8"></p>
<p>出现以上提示我们就已经安装好了openvswitch。</p>
<p>（3)修改openvswitch配置文件</p>
<pre><code># vim /etc/cloudstack/agent/agent.properties
</code></pre><p>在末尾添加如下内容：</p>
<pre><code>network.bridge.type=openvswitch
libvirt.vif.driver=com.cloud.hypervisor.kvm.resource.OvsVifDriver
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/ovs-09.png" alt="ovs-9"></p>
<p>(4)启动ovs</p>
<pre><code># /etc/init.d/openvswitch start
</code></pre><p>设置开机自动启动</p>
<pre><code># chkconfig openvswitch on
</code></pre><p>验证Open vSwitch是否正确安装</p>
<pre><code># lsmod|grep openvswitch
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/ovs-10.png" alt="ovs-10"></p>
<p>出现以上提示说明您的ovs已经正确安装</p>
<p>(5)在agent1和agent2节点设置glusterfs</p>
<p>在配置文件/etc/glusterfs/glusterd.vol添加如下参数</p>
<pre><code>option rpc-auth-allow-insecure on
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/ovs-11.png" alt="ovs-11"></p>
<p>执行命令（只需要在一台节点执行）：</p>
<pre><code># gluster volume set gv2 server.allow-insecure on
</code></pre><p>重启glusterfs服务</p>
<pre><code># /etc/init.d/glusterd restart
</code></pre><p>(6)手动桥接</p>
<p>进入 /etc/sysconfig/network-scripts/</p>
<p>创建网卡</p>
<pre><code># touch ifcfg-cloudbr2
</code></pre><p>编辑cloudbr2网卡</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs-12.png" alt="ovs-12"></p>
<p>编辑eth2网卡</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs-13.png" alt="ovs-13"></p>
<p>重启agent1网络</p>
<pre><code># /etc/init.d/network restart
</code></pre><p>同步网卡配置文件到agent2</p>
<pre><code># scp ifcfg-cloudbr2 ifcfg-eth2 192.168.0.12:/etc/sysconfig/network-scripts/
</code></pre><p>重启agent2的网络</p>
<pre><code># /etc/init.d/network restart
</code></pre><h1 id="初始化master节点"><a href="#初始化master节点" class="headerlink" title="初始化master节点"></a>初始化master节点</h1><p>（1)初始化：</p>
<pre><code># cloudstack-setup-databases cloud:123456@localhost --deploy-as=root:123456
# cloudstack-setup-management
</code></pre><p>（2)导入模板</p>
<pre><code>#/usr/share/cloudstack-common/scripts/storage/secondary/cloud-install-sys-tmplt -m /export/secondary/ -f /opt/systemvm64template-4.6.0-kvm.qcow2.bz2 -h kvm -F
</code></pre><p>（3)进入web页面进行设置</p>
<p>【1】设置3倍内存超峰（真正生成环境不用设置）</p>
<p>【2】设置开放网段范围</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/allow-1.png" alt="ovs-14"></p>
<p>(4)重启cloudstack-management</p>
<pre><code># /etc/init.d/cloudstack-management restart
</code></pre><p>关闭防火墙</p>
<pre><code># /etc/init.d/iptable stop
# chkconfig iptables off    
</code></pre><h1 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h1><p>配置步骤如图所示：</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs00.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs01.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs02.png" alt=""></p>
<p>点击“管理Edit”添加桥接网卡:cloudbr0</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs03.png" alt=""></p>
<p>点击“来宾Edit”添加桥接网卡：cloudbr2</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs04.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs05.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs06.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs07.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs08.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs09.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs10.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs11.png" alt=""></p>
<p>添加主存失败，我们直接在“基础架构”那里重新剩余未添加完成的部分</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs12.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs13.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/ovs14.png" alt=""></p>
<p>添加完成后启动“资源域”</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs15.png" alt=""></p>
<p>我们可以查看一下ovs为我们自动创建的网卡：</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/ovs16.png" alt=""></p>
<p>如果系统VM正常启动那么至此cloudstack的ovs网络部署完成，现在我们就可以自由的进行添加网络、主机等操作了！</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;Open-vSwitch简介&quot;&gt;&lt;a href=&quot;#Open-vSwitch简介&quot; class=&quot;headerlink&quot; title=&quot;Open vSwitch简介&quot;&gt;&lt;/a&gt;Open vSwitch简介&lt;/h1&gt;&lt;h2 id=&quot;概述&quot;&gt;&lt;a href=&quot;#概述&quot; class=&quot;headerlink&quot; title=&quot;概述&quot;&gt;&lt;/a&gt;概述&lt;/h2&gt;&lt;p&gt;Open vSwitch的官方定义：Open vSwitch是一个具有工业级质量的多层虚拟交换机。通过可编程扩展，可以实现大规模网络的自动化（配置、管理、维护）。它支持现有标准管理接口和协议（比如netFlow，sFlow，SPAN，RSPAN，CLI，LACP，802.1ag等，熟悉物理网络维护的管理员可以毫不费力地通过Open vSwitch转向虚拟网络管理）。&lt;/p&gt;
    
    </summary>
    
      <category term="技术分享" scheme="http://yjscloud.com/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="Linux技术" scheme="http://yjscloud.com/tags/Linux%E6%8A%80%E6%9C%AF/"/>
    
      <category term="CloudStack" scheme="http://yjscloud.com/tags/CloudStack/"/>
    
  </entry>
  
  <entry>
    <title>CloudStack搭建指南（二）</title>
    <link href="http://yjscloud.com/2017/09/17/CloudStack%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97%EF%BC%88%E4%BA%8C%EF%BC%89/"/>
    <id>http://yjscloud.com/2017/09/17/CloudStack搭建指南（二）/</id>
    <published>2017-09-17T12:14:12.000Z</published>
    <updated>2017-10-18T05:30:28.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="GlusterFS介绍"><a href="#GlusterFS介绍" class="headerlink" title="GlusterFS介绍"></a>GlusterFS介绍</h1><h2 id="什么是GlusterFS？"><a href="#什么是GlusterFS？" class="headerlink" title="什么是GlusterFS？"></a>什么是GlusterFS？</h2><p>GlusterFS是定义在用户空间中使用的分布式文件系统，在用户空间即文件系统（FUSE）。 它是一个基于软件的文件系统，它考虑到自己的灵活性功能。</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/gfs-1.1.png" alt="gfs-1.1"></p>
<a id="more"></a>
<p>看看下图，它示意性地表示了分层模型中GlusterFS的位置。 默认情况下，GlusterFS将使用TCP协议。</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/gfs-1.2.png" alt="gfs-1.2"></p>
<h2 id="GlusterFS的优点"><a href="#GlusterFS的优点" class="headerlink" title="GlusterFS的优点"></a>GlusterFS的优点</h2><p>(1)创新 -它消除了元数据，并能dramtically提高性能，这将有助于我们统一的数据和对象。</p>
<p>(2)    弹性 -适应于经济增长和减少数据的大小。</p>
<p>(3)    线性扩展 -它具有可用性高数量和超越。</p>
<p>(4)    简单 -在用户空间运行时，它易于管理和独立于内核。</p>
<h2 id="什么使Gluster在其他分布式文件系统中脱颖而出？"><a href="#什么使Gluster在其他分布式文件系统中脱颖而出？" class="headerlink" title="什么使Gluster在其他分布式文件系统中脱颖而出？"></a>什么使Gluster在其他分布式文件系统中脱颖而出？</h2><p>(1)    出售 -缺乏一个元数据服务器提供了一个更快的文件系统。</p>
<p>(2)    实惠的 -它可以部署在商品硬件。</p>
<p>(3)    灵活的 -正如我刚才所说，GlusterFS是一个纯软件的文件系统。 这里的数据存储在本地文件系统，如ext4，xfs等。</p>
<p>(4)    开源 -目前GlusterFS是由红帽公司是一家十亿美元的开源公司，作为维护红帽存储的一部分。</p>
<h2 id="GlusterFS中的存储概念"><a href="#GlusterFS中的存储概念" class="headerlink" title="GlusterFS中的存储概念"></a>GlusterFS中的存储概念</h2><p>(1)砖 -砖基本上是指的是值得信赖的存储池之间共享任何目录。</p>
<p>(2)    值得信赖的存储池 -为这些共享文件/目录，这是基于对设计方案的集合。</p>
<p>(3)    块存储 -它们是通过该数据跨系统中的块的形式被移动设备。</p>
<p>(4)    集群 -在红帽存储，两个群集和值得信赖的存储池传达的基础上定义的协议存储服务器协作的含义相同。</p>
<p>(5)    分布式文件系统 -的文件系统，其中数据被分布在，用户可以在不知道该文件的实际位置访问该文件不同的节点。 用户没有体验到远程访问的感觉。</p>
<p>(6)    FUSE -这是一个可加载的内核模块，它允许用户在不涉及任何内核代码创建上面的内核文件系统。</p>
<p>（7)glusterd – glusterd是GlusterFS管理守护这是将在整个时间每当服务器处于活动状态运行文件系统的骨干。</p>
<p>(8)POSIX -便携式操作系统接口（POSIX）是由IEEE作为在应用程序可编程接口（API）的形式的解决方案，以Unix的变体之间的相容性定义的标准的家庭。</p>
<p>(9)    RAID -独立磁盘（RAID）冗余阵列是给通过冗余提高存储可靠性的技术。</p>
<p>(10)亚体 -在同一译者由至少处理后砖。</p>
<p>(11)译者 -译者是一段代码，它执行从安装点的用户启动的基本动作。 它连接一个或多个子卷。</p>
<p>（12)音量 -一个体积是砖的逻辑集合。 所有操作都基于用户创建的不同类型的卷。</p>
<h1 id="gluster的三种基本卷"><a href="#gluster的三种基本卷" class="headerlink" title="gluster的三种基本卷"></a>gluster的三种基本卷</h1><h2 id="分布式卷"><a href="#分布式卷" class="headerlink" title="分布式卷"></a>分布式卷</h2><p>分布式Glusterfs卷 - 这是默认的glusterfs卷，即，如果不指定卷的类型，则在创建卷时，默认选项是创建分布式卷。这里，文件分布在卷中的各种砖块上。所以file1可能仅存储在brick1或brick2中，而不能存储在两者中。因此，没有数据冗余。这样的存储容量的目的是容易且便宜地缩放卷大小。然而，这也意味着砖块故障将导致完全丢失数据，并且必须依靠底层硬件进行数据丢失保护<br><img src="http://owawy15xy.bkt.clouddn.com/gfs-1.3.png" alt="gfs1.3"></p>
<h2 id="复制卷-raid1"><a href="#复制卷-raid1" class="headerlink" title="复制卷(raid1)"></a>复制卷(raid1)</h2><p>复制Glusterfs卷 - 在本卷中，我们克服了分布式卷中面临的数据丢失问题。这些数据的完整副本保留在所有砖上。卷中的副本数可以由客户端在创建卷时决定。所以我们需要至少有两个砖块来创建一个2个副本或至少三个砖块来创建一个3个副本的卷。这样一个卷的一个主要优点是，即使一个砖失败，仍然可以从其复制的砖块访问数据。这样的卷被用于更好的可靠性和数据冗余。<br><img src="http://owawy15xy.bkt.clouddn.com/gfs-1.4.png" alt="gfs-1.4"></p>
<h2 id="条带卷（raid0）"><a href="#条带卷（raid0）" class="headerlink" title="条带卷（raid0）"></a>条带卷（raid0）</h2><p>条纹Glusterfs卷 - 考虑一个大型文件存储在一个砖块，许多客户端同时经常访问。这将对单个砖造成太多负载，并降低性能。在条带卷中，将数据分割成不同的条纹后，将数据存储在砖块中。因此，大文件将被分成更小的块（等于块中的块数），每个块都存储在一个砖块中。现在分配了负载，并且可以更快地获取文件，但没有提供数据冗余。<br><img src="http://owawy15xy.bkt.clouddn.com/gfs-1.5.png" alt="gfs-1.5"></p>
<h1 id="GlusterFS搭建与使用"><a href="#GlusterFS搭建与使用" class="headerlink" title="GlusterFS搭建与使用"></a>GlusterFS搭建与使用</h1><h2 id="Glusterfs搭建"><a href="#Glusterfs搭建" class="headerlink" title="Glusterfs搭建"></a>Glusterfs搭建</h2><p>(1)先安装epel源</p>
<pre><code># yum -y install epel-release
</code></pre><p>(2)如果用yum直接安装会很慢，建议去glusterfs官网把rpm包下载下来然后把这些rpm包上传到linux服务器中。<br>然后执行如下命令：</p>
<pre><code># yum -y install glusterfs-*
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/gfs-1.6.png" alt="gfs-1.6"></p>
<p>(3)启动gluster :</p>
<pre><code># service glusterd start
</code></pre><p>(4)关闭防火墙以及selinux</p>
<pre><code># service iptables stop
# chkconfig iptables off
# sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/&apos; /etc/selinux/config
</code></pre><h2 id="GlusterFS的使用"><a href="#GlusterFS的使用" class="headerlink" title="GlusterFS的使用"></a>GlusterFS的使用</h2><p>(1)建立信任关系: </p>
<pre><code># gluster peer probe 10.0.0.5
</code></pre><p>(2)    查看信任状态：</p>
<pre><code># gluster peer status
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/gfs01.png" alt="gfs01"></p>
<p>(3)创建分布式卷：</p>
<p>gfs1: </p>
<pre><code># mkdir -p /data/exp1
</code></pre><p>gfs2: </p>
<pre><code># mkdir -p /data/exp2
</code></pre><p>gfs1: </p>
<pre><code># gluster volume create test-volume 10.0.0.4:/data/exp1 10.0.0.5:/data/exp2 force
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/gfs02.png" alt="gfs02"></p>
<p>查看卷的详情：</p>
<pre><code># gluster volume info
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/gfs03.png" alt="gfs03"></p>
<p>(4)创建复制卷：</p>
<p>gfs1 :</p>
<pre><code># mkdir /data/exp3
</code></pre><p>gfs2 :</p>
<pre><code># mkdir /data/exp4
</code></pre><p>gfs1 :</p>
<pre><code># gluster volume create repo-volume replica 2 transport tcp 10.0.0.4:/data/exp3 10.0.0.5:/data/exp4 force
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/gfs04.png" alt="gfs04"></p>
<p>查看卷的详情：</p>
<pre><code># gluster volume info repo-volume
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/gfs05.png" alt="gfs05"></p>
<p>(5)创建条带卷： </p>
<p>gfs1: </p>
<pre><code># mkdir /data/exp5
</code></pre><p>gfs2: </p>
<pre><code># mkdir /data/exp6
</code></pre><p>gfs1 :</p>
<pre><code># gluster volume create raid0-volume stripe 2 transport tcp 10.0.0.4:/data/exp5 10.0.0.5:/data/exp6 force  
</code></pre><p>(6)启动卷：</p>
<p>默认情况下创建的卷是没有启动的我们用命令gluster volume start volume-name 启动即可<br>(7)挂载卷：</p>
<p>创建挂载点</p>
<p>gfs1:  </p>
<pre><code># mkdir /mnt/g1 /mnt/g2 /mnt/g3
</code></pre><p>挂载卷</p>
<p>gfs1:  </p>
<pre><code># mount.glusterfs 10.0.0.4:/test-volume /mnt/g1
# mount.glusterfs 10.0.0.4:/repo-volume /mnt/g2
# mount.glusterfs 10.0.0.4:/raid0-volume /mnt/g3
</code></pre><p>查看挂载的卷：df -h</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/gfs06.png" alt="gfs06"></p>
<p>(8)创建分布式复制卷：</p>
<p>gfs1: </p>
<pre><code># mkdir /exp1 /exp2
</code></pre><p>gfs2: </p>
<pre><code># mkdir /exp1 /exp2
</code></pre><p>gfs1:</p>
<pre><code>#gluster volume create xwq-volume replica 2 transport tcp 10.0.0.4:/exp1 10.0.0.4:/exp2 10.0.0.5:/exp1 10.0.0.5:/exp2 force
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/gfs07.png" alt="gfs07"></p>
<p>启动卷：</p>
<pre><code># gluster volume start xwq-volume
</code></pre><p>创建挂载点：</p>
<pre><code># mkdir /mnt/g5
</code></pre><p>挂载：</p>
<pre><code># mount.glusterfs 10.0.0.4:/xwq-volume /mnt/g5
</code></pre><p>数据写入测试：</p>
<pre><code># man tcp &gt; /mnt/g5/tcp1.txt
# man tcp &gt; /mnt/g5/tcp2.txt
# man tcp &gt; /mnt/g5/tcp3.txt
# man tcp &gt; /mnt/g5/tcp4.txt
</code></pre><p>查看数据情况：</p>
<pre><code># tree /exp* 
</code></pre><p>数据分布和我们想象中的有点不一样，这与你添加卷的顺序有关</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/tree02.png" alt="gfs"><br><img src="http://owawy15xy.bkt.clouddn.com/tree03.png" alt="gfs"></p>
<p>(9)扩展卷 为分布式添加扩展卷 </p>
<p>gfs1:</p>
<pre><code># mkdir /data/exp9
</code></pre><p>gfs1:</p>
<pre><code># gluster volume add-brick test-volume 10.0.0.4:/data/exp9 force
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/gfs-add01.png" alt=""></p>
<p>均衡卷中的数据：</p>
<pre><code># gluster volume rebalance test-volume start
</code></pre><p>(10)删除卷：                    </p>
<p>gfs1：</p>
<pre><code># gluster volume remove-brick test-volume 10.0.0.4:/data/exp9 force
</code></pre><p>数据可能会丢失，数据并不会删除!</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/remove-gfs.png" alt=""></p>
<p>更多详细内容请参阅<a href="http://docs.gluster.org" target="_blank" rel="external">官方文档</a></p>
<h1 id="GlusterFS在cloudstack中的应用"><a href="#GlusterFS在cloudstack中的应用" class="headerlink" title="GlusterFS在cloudstack中的应用"></a>GlusterFS在cloudstack中的应用</h1><h2 id="在master端删库重新配置cloudstack-management"><a href="#在master端删库重新配置cloudstack-management" class="headerlink" title="在master端删库重新配置cloudstack-management"></a>在master端删库重新配置cloudstack-management</h2><p>（1）先停止管理服务器：</p>
<pre><code># /etc/init.d/cloudstack-management stop
</code></pre><p>（2）删库：<br>进入数据库：</p>
<pre><code># mysql -uroot -p123456
</code></pre><p>删库：</p>
<pre><code># drop database cloud;
# drop database cloud_usage;
</code></pre><h2 id="在agent端配置"><a href="#在agent端配置" class="headerlink" title="在agent端配置"></a>在agent端配置</h2><p>(1)在之前安装agent的时候会自动安装glusterfs但是某些依赖库并没有安装完全，要卸载重装；</p>
<p>卸载命令：</p>
<pre><code># yum remove glusterfs*
</code></pre><p>上传rpm到合适的目录执行</p>
<pre><code># yum -y install glusterfs-*
</code></pre><p>或：安装</p>
<pre><code># yum install -y centos-release-gluster37.noarch
</code></pre><p>然后再执行如下命令：</p>
<pre><code># yum --enablerepo=centos-gluster*-test install glusterfs-server glusterfs-cli glusterfs-geo-replication
</code></pre><p>(2) 删除agent1节点 /export/primary目录下的镜像：</p>
<pre><code># rm -rf *
</code></pre><p>启动glusterfs服务：</p>
<pre><code># service glusterd start 
# chkconfig glusterd on 
</code></pre><p>(3)然后以agent1为模板克隆一台虚拟机，改名为agent2并对网卡和主机名进行更改</p>
<p>(4)    添加信任池</p>
<p>[1]先关闭agent1和agent2的防火墙：</p>
<pre><code># /etc/init.d/iptables stop
</code></pre><p>[2]在agent1节点添加信任：</p>
<pre><code># gluster peer probe 192.168.0.32
</code></pre><p>可用gluster peer status查看链接状态</p>
<p>（5）添加磁盘、格式化、挂载~此处略</p>
<p>（6）因为刚才安装glusterfs的时候把agent给卸载，现在重新安装回去</p>
<pre><code># yum -y install cloudstack-common-4.8.0-1.el6.x86_64.rpm cloudstack-agent-4.8.0-1.el6.x86_64.rpm
</code></pre><p>（7）创建分布式复制卷 </p>
<p>创建：</p>
<pre><code># gluster volume create gv2 replica 2 agnet1:/export/primary agent2:/export/primary force
</code></pre><p>启动卷：</p>
<pre><code># gluster volume start gv2    
</code></pre><p>查看卷：</p>
<pre><code># gluster volume info
</code></pre><p><img src="http://owawy15xy.bkt.clouddn.com/gfs-ag01.png" alt="gsf-ag01"></p>
<h2 id="在master端进行库的初始化"><a href="#在master端进行库的初始化" class="headerlink" title="在master端进行库的初始化"></a>在master端进行库的初始化</h2><p>（1）初始化：</p>
<pre><code># cloudstack-setup-databases cloud:123456@localhost --deploy-as=root:123456
</code></pre><p>（2）启动cloudstack：</p>
<pre><code># cloudstack-setup-management
</code></pre><p>（3）上传模板：</p>
<pre><code># /usr/share/cloudstack-common/scripts/storage/secondary/cloud-install-sys-tmplt -m /export/secondary/ -f /opt/systemvm64template-4.6.0-kvm.qcow2.bz2 -h kvm –F
</code></pre><h1 id="系统管理"><a href="#系统管理" class="headerlink" title="系统管理"></a>系统管理</h1><p>登陆cloudstack后天web界面创建资源域，步骤和之前创建资源域大致相同；<br>配置步骤如下：</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/cs01.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/cs02.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/cs3.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/cs04.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/cs05.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/cs06.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/cs07.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/cs08.png" alt=""><br><img src="http://owawy15xy.bkt.clouddn.com/lose01.png" alt=""></p>
<p>启动资源域后报错，可以通过查看日志来排错，这里我们直接进入“基础架构”进行添加主机</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/lost02.png" alt=""></p>
<p>添加主存储</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/lost03.png" alt=""></p>
<p>添加二级存储<br><img src="http://owawy15xy.bkt.clouddn.com/lost04.png" alt=""></p>
<p>添加好后我们到“全局设置”修改一下配置，设置内存超峰</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/men3.png" alt=""></p>
<p>然后启用资源域，如果系统vm顺利启动则说明你的cloudstack平台搭建成功！<br><img src="http://owawy15xy.bkt.clouddn.com/lost05.png" alt=""></p>
<p>完成效果图：</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/lost~~~.png" alt=""></p>
<h1 id="在线迁移主机"><a href="#在线迁移主机" class="headerlink" title="在线迁移主机"></a>在线迁移主机</h1><p>当运行着虚拟机的主机资源报警或者发生故障时，如何确保运行在该主机上的虚拟机可以正常提供服务呢？这个时候glusterfs分布式文件系统就发挥了它的用处，由于glusterfs是共享式存储，可以实现在网络不中断的情况下对主机进行迁移。</p>
<p>（1）用命令virsh list 查看运行在主机上的虚拟机</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/%E4%BA%8C-1.png" alt="二-1"></p>
<p>虚拟机运行在agent1节点上<br><img src="http://owawy15xy.bkt.clouddn.com/%E4%BA%8C-2.png" alt="二-2"></p>
<p>（2）迁移s-1-VM为例</p>
<p>查看其公网ip,s-1-VM在agent1上，我们在agent2上ping s-1-VM,要确保可以ping通才能进行迁移。</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/%E4%BA%8C-3.png" alt="二-3"></p>
<p>进行系统迁移：</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/%E4%BA%8C-4.png" alt="二-4"></p>
<p><img src="http://owawy15xy.bkt.clouddn.com/%E4%BA%8C-5.png" alt="二-5"></p>
<p>在agent2上查看，迁移成功！</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/%E4%BA%8C-6.png" alt="二-6"></p>
<p>在迁移过程中不会对用户的使用产生任何影响，用户是无法察觉迁移过程的。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;GlusterFS介绍&quot;&gt;&lt;a href=&quot;#GlusterFS介绍&quot; class=&quot;headerlink&quot; title=&quot;GlusterFS介绍&quot;&gt;&lt;/a&gt;GlusterFS介绍&lt;/h1&gt;&lt;h2 id=&quot;什么是GlusterFS？&quot;&gt;&lt;a href=&quot;#什么是GlusterFS？&quot; class=&quot;headerlink&quot; title=&quot;什么是GlusterFS？&quot;&gt;&lt;/a&gt;什么是GlusterFS？&lt;/h2&gt;&lt;p&gt;GlusterFS是定义在用户空间中使用的分布式文件系统，在用户空间即文件系统（FUSE）。 它是一个基于软件的文件系统，它考虑到自己的灵活性功能。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://owawy15xy.bkt.clouddn.com/gfs-1.1.png&quot; alt=&quot;gfs-1.1&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="技术分享" scheme="http://yjscloud.com/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="Linux技术" scheme="http://yjscloud.com/tags/Linux%E6%8A%80%E6%9C%AF/"/>
    
      <category term="CloudStack" scheme="http://yjscloud.com/tags/CloudStack/"/>
    
  </entry>
  
  <entry>
    <title>CloudStack搭建指南（一）</title>
    <link href="http://yjscloud.com/2017/09/15/CloudStack%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97%EF%BC%88%E4%B8%80%EF%BC%89/"/>
    <id>http://yjscloud.com/2017/09/15/CloudStack搭建指南（一）/</id>
    <published>2017-09-15T02:49:46.000Z</published>
    <updated>2017-10-18T05:29:56.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h1><h2 id="云计算的出现"><a href="#云计算的出现" class="headerlink" title="云计算的出现"></a>云计算的出现</h2><p>基本上，云计算只是一种把 IT 资源当作服务来提供的手段。几乎所有 IT 资源都可以作为云服务来提供：应用程序、计算能力、存储容量、联网、编程工具，以至于通信服务和协作工具。<br>云计算最早为 Google、Amazon 等其他扩建基础设施的大型互联网服务提供商所采用。于是产生一种架构：大规模扩展、水平分布的系统资源，抽象为虚拟 IT 服务，并作为持续配置、合用的资源进行管理。<br><a id="more"></a><br>就最终用户而言，云计算意味着没有硬件购置成本、没有需要管理的软件许可证或升级、不需要雇佣新的员工或咨询人员、不需要租赁设施、没有任何种类的基建投资，而且还没有隐性成本。只是一种用仪表测量出来的、根据使用情况支付的订购费或固定的订购费。只是用您所需的量，而且只按使用量付费。</p>
<p>云计算体系结构图如下：</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/cs-1.1.png" alt="1.1"></p>
<h2 id="把基础设施当做服务（IaaS）"><a href="#把基础设施当做服务（IaaS）" class="headerlink" title="把基础设施当做服务（IaaS）"></a>把基础设施当做服务（IaaS）</h2><p>把基础设施当作服务 (IaaS) 处于最低层级，而且是一种作为标准化服务在网上提供基本存储和计算能力的手段。服务器、存储系统、交换机、路由器和其他系统协作 (例如，通过虚拟化技术) 处理特定类型的工作负载 — 从批处理到峰值负载期间的服务器/存储扩大。<br>最著名的商业示例是 Amazon Web 服务 (AWS)，其 EC2 和 S3 服务分别提供基本计算和存储服务。国内代表阿里云、腾讯云、百度云、金山云等。</p>
<h2 id="IaaS平台的虚拟化技术的好处"><a href="#IaaS平台的虚拟化技术的好处" class="headerlink" title="IaaS平台的虚拟化技术的好处"></a>IaaS平台的虚拟化技术的好处</h2><p>利用率更高 — 在虚拟化之前，企业数据中心的服务器和存储利用率一般平均不到 50% (事实上，通常利用率为 10% 到 15%)。通过虚拟化，可以把工作负载封装一并转移到空闲或使用不足的系统，这就意味着可以整合现有系统，因而可以延迟或避免购买更多服务器容量。</p>
<p>资源整合 — 虚拟化使得整合多个 IT 资源成为可能。除服务器和存储整合之外，虚拟化提供一个整合系统架构、应用程序基础设施、数据和数据库、接口、网络、桌面系统甚至业务流程，因而可以节约成本和提高效率。</p>
<p>节省电能/成本 — 运行企业级数据中心所需的电能不再无限制地使用，而成本呈螺旋式上升趋势。在服务器硬件上每花一美元，就会在电费上增加一美元 (包括服务器运行和散热方面的成本)。利用虚拟化进行整合使得降低总能耗和节约大量资金成为可能。</p>
<p>节约空间 — 服务器膨胀仍然是多数企业数据中心面临的一个严重问题，可扩大数据中心并不总是一个良好的选择，因为每增大一平方米空间，就会平均增加很多成本。虚拟化通过把多个虚拟系统整合到较少物理系统上，可以缓解空间压力。</p>
<p>灾难恢复 (Disaster recovery) /业务连续 (Business Continuity) — 虚拟化可提高总体服务级利用率，并提供灾难恢复解决方案新选项。</p>
<h2 id="Cloudstack-介绍"><a href="#Cloudstack-介绍" class="headerlink" title="Cloudstack 介绍"></a>Cloudstack 介绍</h2><p>CloudStack是一个开源的具有高可用性及扩展性的云计算平台CloudStack 是一个开源的云操作系统，它可以帮助用户利用自己的硬件提供类似于Amazon EC2那样的公共云服务。CloudStack可以通过组织和协调用户的虚拟化资源，构建一个和谐的环境。<br>Cloudstack支持管理大部分主流的hypervisors，如KVM，XenServer，VMware，Oracle VM，Xen等。<br><img src="http://owawy15xy.bkt.clouddn.com/1.4.png" alt="1.4"></p>
<p>Cloudstack 部署图如下：</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/1.4.1.png" alt="1.4.1"><br>Zone：Zone 对应于现实中的一个数据中心，它是 CloudStack 中最大的一个单元。<br>即从包含关系上来说，一个 zone 包含多个 pod，一个 pod 包含多个 cluster，一个 cluster 包含多个 host。</p>
<p>提供点（Pods）：<br>一个提供点通常代表一个机架，机柜里面的主机在同一个子网，每个区域中必须包含一个或多个提供点，提供点中包含主机和主存储服务器， CloudStack 的内部管理通信配置一个预留 IP 地址范围。预留的 IP 范围对云中的每个区域来说必须唯一。</p>
<p>集群（Clusters）：<br>Cluster 是多个主机组成的一个集群。<br>同一个cluster中的主机有相同的硬件，相同的 Hypervisor，和共用同样的存储。同一个 cluster 中的虚拟机，可以实现无中断服务地从一个主机迁移到另外一个上。<br>集群由一个或多个宿主机和一个或多个主要存储服务器构成。集群的大小取决于下层虚拟机软件。大多数情况下基本无建议。当使用VMware时，每个VMware集群都被vCenter 服务器管理。管理员必须在本产品中登记vCenter。每个zone下可以有多个vCenter服务器。每个vCenter服务器可能管理多个VMware集群</p>
<p>主机（Hosts）：<br>Host 就是运行的虚拟机（VM）主机。<br>宿主机就是个独立的计算机。宿主机运行来宾虚拟机并提供其相应的计算资源。每个宿主机都装有虚拟机软件来运行来宾虚拟机。比如一个开启了kvm支持的服务器，一个思杰XenServer服务器，或者一个ESXi服务器都可以作为宿主机。<br>宿主机在CloudStack部署中属于最小的组织单元。宿主机包含于集群中，集群又属于提供点，而区域中包含提供点（就是在逻辑概念上zone&gt;pod&gt;cluster&gt;host），新增的宿主机可以随时添加以提供更多资源给来宾虚拟机，CloudStack自动探测宿主机的cpu数量和内存资源。宿主机对终端用户不可见。终端用户不能决定他们的虚拟机被分配到哪台宿主机。</p>
<p>CloudStack 中存在两种存储：<br>Primary storage：一级存储与 cluster 关联，它为该 cluster 中的主机的全部虚拟机提供磁盘卷。一个 cluster 至少有一个一级存储，且在部署时位置要临近主机以提供高性能。<br>Secondary storage：二级存储与 zone 关联，它存储模板文件，ISO 镜像和磁盘卷快照。</p>
<h1 id="部署安装"><a href="#部署安装" class="headerlink" title="部署安装"></a>部署安装</h1><p>cloudstack 安装前的准备</p>
<p>VMWARE Workstation虚拟机为实验平台，我的个节点硬件资源分配情况</p>
<pre><code>master1 : 2G内存+40G硬盘+双核6600k
agent1 :  6G内存+40G硬盘+双核6600k
agent2 : 6G内存+40G硬盘+双核6600k
agent3 : 6G内存+40G硬盘+双核6600k
NFS : 1G内存+40G硬盘+双核6600k+500G硬盘+500G硬盘
系统：CentOS-6-x86_64（6.8）
网络选择：桥接
</code></pre><h2 id="配置nfs服务器"><a href="#配置nfs服务器" class="headerlink" title="配置nfs服务器"></a>配置nfs服务器</h2><h3 id="安装ntp服务"><a href="#安装ntp服务" class="headerlink" title="安装ntp服务"></a>安装ntp服务</h3><p>为了同步云平台中主机的时间，需要配置NTP，但NTP默认没有安装。因此需要先安装NTP，然后进行配置。通过以下命令进行安装：</p>
<pre><code># yum -y install ntp
</code></pre><p>实际上默认配置项即可满足的需求，仅需启用NTP并设置为开机启动，如下所示：</p>
<pre><code># chkconfig ntpd on
# service ntpd start
</code></pre><h3 id="NFS服务安装"><a href="#NFS服务安装" class="headerlink" title="NFS服务安装"></a>NFS服务安装</h3><p>本文档将配置的环境使用NFS做为主存储和辅助存储，需配置两个NFS共享目录，在此之前需先安装nfs-utils：</p>
<pre><code># yum -y install nfs-utils
</code></pre><p>接下来需配置NFS提供两个不同的挂载点。通过编辑/etc/exports文件即可简单实现。确保这个文件中包含下面内容：</p>
<pre><code>/export/secondary *(rw,async,no_root_squash,no_subtree_check)
/export/primary *(rw,async,no_root_squash,no_subtree_check)
</code></pre><p>注意配置文件中指定了系统中两个并不存在的目录，下面需要创建这些目录并设置合适的权限，对应的命令如下所示：</p>
<pre><code># mkdir -p /export/primary
# mkdir –p /export/secondary
</code></pre><h3 id="格式化硬盘"><a href="#格式化硬盘" class="headerlink" title="格式化硬盘"></a>格式化硬盘</h3><p>查看磁盘：</p>
<pre><code># fdisk  -l
</code></pre><p>格式化磁盘：</p>
<pre><code># mkfs.ext4  /dev/sdb 
# mkfs.ext4  /dev/sdc
</code></pre><p>为格式化好的磁盘添加开机自动挂载:</p>
<pre><code># echo &quot;/dev/sdb  /export/secondary  ext4 defaults 0 0&quot;  &gt;&gt; /etc/fstab
# echo &quot;/dev/sdc  /export/primary  ext4 defaults 0 0&quot;  &gt;&gt; /etc/fstab
</code></pre><h3 id="配置防火墙"><a href="#配置防火墙" class="headerlink" title="配置防火墙"></a>配置防火墙</h3><p>CentOS 6.x 版本默认使用NFSv4设置为以下内容：<br>在/etc/sysconfig/nfs文件中取消如下选项的注释：</p>
<pre><code>LOCKD_TCPPORT=32803
LOCKD_UDPPORT=32769
MOUNTD_PORT=892
RQUOTAD_PORT=875
STATD_PORT=662
STATD_OUTGOING_PORT=2020
</code></pre><p>接下来还需配置防火墙策略，允许NFS客户端访问。编辑文件/etc/sysconfig/iptables</p>
<pre><code>-A INPUT -m state --state NEW -p udp --dport 111 -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport 111 -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport 2049 -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport 32803 -j ACCEPT
-A INPUT -m state --state NEW -p udp --dport 32769 -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport 892 -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport 892 -j ACCEPT
-A INPUT -m state --state NEW -p udp --dport 892 -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport 875 -j ACCEPT
-A INPUT -m state --state NEW -p udp --dport 875 -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport 662 -j ACCEPT
-A INPUT -m state --state NEW -p udp --dport 662 -j ACCEPT
-A INPUT -m state --state NEW -p tcp --dport 80 -j ACCEPT
</code></pre><p>通过以下命令重新启动iptables服务：</p>
<pre><code># service iptables restart
</code></pre><p>您也可以直接关闭防火墙：</p>
<pre><code># service iptables stop (关闭防火墙)
# chkconfig iptables off（禁止防火墙开机自起）
# service iptables status（查看防火墙状态）
</code></pre><p>然后需要配置NFS服务为开机自启动，执行如下命令：</p>
<pre><code># service rpcbind start
# service nfs start
# chkconfig rpcbind on
# chkconfig nfs on
</code></pre><p>最后可以在agent1上安装nfs-utils软件，测试您的nfs服务是否搭建成功showmount -e  192.168.0.20测试master1的nfs服务是否配置成功！</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/nfs-2.1.png" alt="nfs-2.1"></p>
<h2 id="管理服务器安装"><a href="#管理服务器安装" class="headerlink" title="管理服务器安装"></a>管理服务器安装</h2><h3 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h3><p>安装好自己的虚拟机为自己的虚拟机设置网络，以下是我的所有虚拟机ip设置如下：</p>
<pre><code>master1: 192.168.0.20
agent1:192.168.0.21
agent2:192.168.0.22
agent3:192.168.0.23
NFS: 192.168.0.24
</code></pre><p>默认情况下新安装的机器并未启用网络，在root权限下使用命令ifup eth0激活你的网卡，并用命令setup开启图形化界面固定你的ip，或这用vim /etc/sysconfig/network-scripts/ifcfg-eth0修改网卡配置文件， </p>
<p>根据您需求修改配置文件，指定IP地址，网络掩码等信息，例：</p>
<pre><code>DEVICE=eth0
HWADDR=52:54:00:B9:A6:C0
NM_CONTROLLED=no
ONBOOT=yes
BOOTPROTO=none
IPADDR=192.168.0.20
NETMASK=255.255.255.0
GATEWAY=192.168.0.1
DNS1=192.168.0.1
</code></pre><h3 id="修改主机名"><a href="#修改主机名" class="headerlink" title="修改主机名"></a>修改主机名</h3><p>需要修改两处：一处是/etc/sysconfig/network，另一处是/etc/hosts，只修改任一处会导致系统启动异常。<br>（1）修改：/etc/sysconfig/network</p>
<p>用vimi编辑器，里面有一行 HOSTNAME=localhost.localdomain (如果是默认的话），修改 localhost.localdomain 为你的主机名。例：<br><img src="http://owawy15xy.bkt.clouddn.com/2.2.1.png" alt="2.2.1"></p>
<p>（2）修改：/etc/hosts</p>
<p>打开该文件，会有一行 127.0.0.1 localhost.localdomain localhost 。其中 127.0.0.1 是本地环路地址， localhost.localdomain 是主机名(hostname)，也就是你待修改的。localhost 是主机名的别名（alias）。将第二项修改为你的主机名，第三项可选。例：</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.2.1-1.png" alt="2.2.1-1"></p>
<p>将上面两个文件修改完后，并不能立刻生效。如果要立刻生效的话，可以用 hostname your-hostname 作临时修改，它只是临时地修改主机名，系统重启后会恢复原样的。但修改上面两个文件是永久的，重启系统会得到新的主机名。</p>
<p>最后，重启后查看主机名 hostname –fqdn</p>
<p>通过hostname –fqdn命令重新检查主机名 。</p>
<h3 id="关闭selinux"><a href="#关闭selinux" class="headerlink" title="关闭selinux"></a>关闭selinux</h3><p>关闭selinux</p>
<pre><code># sed -i &apos;s/SELINUX=enforcing/SELINUX=disabled/&apos; /etc/selinux/config
</code></pre><p>也可以用vi 直接编辑修改</p>
<h3 id="安装epel-源"><a href="#安装epel-源" class="headerlink" title="安装epel 源"></a>安装epel 源</h3><p>cloudstack  yum源有部分包依赖 epel 源</p>
<pre><code># yum -y install epel-release 
</code></pre><h3 id="安装-cloudstack-源"><a href="#安装-cloudstack-源" class="headerlink" title="安装 cloudstack 源"></a>安装 cloudstack 源</h3><p>添加CloudStack软件仓库，创建/etc/yum.repos.d/cloudstack.repo文件，并添加如下信息。</p>
<pre><code>[cloudstack]
name=cloudstack
baseurl=http://cloudstack.apt-get.eu/centos/6/4.8/
enabled=1
gpgcheck=0
</code></pre><p>或者把安装包下载到本地，然后上传到合适的文件夹，我上传到了opt/目录下，这样编译安装会快很多。</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.2.5.png" alt="2.2.5"></p>
<h3 id="安装NTP"><a href="#安装NTP" class="headerlink" title="安装NTP"></a>安装NTP</h3><p>为了同步云平台中主机的时间，需要配置NTP，但NTP默认没有安装。因此需要先安装NTP，然后进行配置。通过以下命令进行安装：</p>
<pre><code># yum -y install ntp
</code></pre><p>实际上默认配置项即可满足的需求，仅需启用NTP并设置为开机启动，如下所示：</p>
<pre><code># chkconfig ntpd on
# service ntpd start
</code></pre><p>接下来进行CloudStack管理节点和相关工具的安装。</p>
<h3 id="安装管理端"><a href="#安装管理端" class="headerlink" title="安装管理端"></a>安装管理端</h3><p>现在进入您放cloudstack软件包的文件件，使用如下命令安装管理服务器。</p>
<pre><code># yum -y install cloudstack-management-4.8.0-1.el6.x86_64.rpm cloudstack-common-4.8.0-1.el6.x86_64.rpm
</code></pre><h3 id="数据库安装和配置"><a href="#数据库安装和配置" class="headerlink" title="数据库安装和配置"></a>数据库安装和配置</h3><p>首先安装MySQL，并对它进行配置，以确保CloudStack运行正常。<br>运行如下命令安装：</p>
<pre><code># yum -y install mysql-server
</code></pre><p>MySQL安装完成后，需更改其配置文件/etc/my.cnf。在[mysqld]下添加下列参数：</p>
<pre><code>innodb_rollback_on_timeout=1
innodb_lock_wait_timeout=600
max_connections=350
log-bin=mysql-bin
binlog-format = &apos;ROW&apos;
</code></pre><p>正确配置MySQL后，启动它并配置为开机自启动：</p>
<pre><code># service mysqld start
# chkconfig mysqld on
</code></pre><p>设置mysql 密码及范围权限 </p>
<pre><code># mysqladmin -uroot password 123456
# mysql -uroot  -p123456 -e &quot;GRANT ALL PRIVILEGES ON *.* TO root@&apos;%&apos;     IDENTIFIED BY &apos;123456&apos;&quot;;
</code></pre><h3 id="系统初始化"><a href="#系统初始化" class="headerlink" title="系统初始化"></a>系统初始化</h3><p>在程序执行完毕后，需初始化数据库，通过如下命令和选项完成：</p>
<pre><code># cloudstack-setup-databases cloud:123456@localhost --deploy-as=root:123456
</code></pre><p>当该过程结束后，您应该可以看到类似信息：”CloudStack has successfully initialized the database.”。<br>数据库创建后，最后一步是配置管理服务器，执行如下命令：</p>
<pre><code># cloudstack-setup-management
</code></pre><h3 id="上传系统模板"><a href="#上传系统模板" class="headerlink" title="上传系统模板"></a>上传系统模板</h3><p>CloudStack通过一系列系统虚拟机提供功能，如访问虚拟机控制台，如提供各类网络服务，以及管理辅助存储的中的各类资源。该步骤会获取系统虚拟机模板，用于云平台引导后系统虚拟机的部署。<br>然后需要下载系统虚拟机模板，并把这些模板部署于刚才创建的辅助存储中；管理服务器包含一个脚本可以正确的操作这些系统虚拟机模板：</p>
<pre><code># /usr/share/cloudstack-common/scripts/storage/secondary/cloud-install-sys-tmplt -m /export/secondary/ -f /opt/systemvm64template-4.6.0-kvm.qcow2.bz2 -h kvm -F
</code></pre><h3 id="访问用户界面"><a href="#访问用户界面" class="headerlink" title="访问用户界面"></a>访问用户界面</h3><p>要访问CloudStack的WEB界面，仅需在浏览器访问 <a href="http://XXX.XXX.XXX:8080/client" target="_blank" rel="external">http://XXX.XXX.XXX:8080/client</a> ，使用默认用户’admin’和密码’password’来登录。第一次登录可以看到欢迎界面。<br><img src="http://owawy15xy.bkt.clouddn.com/2.2.11.png" alt="2.2.11"></p>
<h2 id="安装agent节点及配置"><a href="#安装agent节点及配置" class="headerlink" title="安装agent节点及配置"></a>安装agent节点及配置</h2><h3 id="先决条件"><a href="#先决条件" class="headerlink" title="先决条件"></a>先决条件</h3><p>本文档描述的环境使用管理服务器同时作为计算节点，这意味着很多先决步骤已经在搭建管理服务器时完成；但为了清晰起见，仍然列出相关步骤：</p>
<p>(1)网络配置</p>
<p>(2)主机名</p>
<p>(3)SELinux</p>
<p>(4)NTP</p>
<p>(5)配置ClouStack软件库</p>
<p>你不需要在管理节点上执行这些操作，当然，如果您需要添加额外的主机以上步骤仍然需要执行。</p>
<h3 id="Agent-安装"><a href="#Agent-安装" class="headerlink" title="Agent 安装"></a>Agent 安装</h3><p>安装KVM代理仅仅需要一条简单的命令，但之后我们需要进行一些配置。</p>
<pre><code># yum -y install cloudstack-common-4.8.0-1.el6.x86_64.rpm cloudstack-agent-4.8.0-1.el6.x86_64.rpm
</code></pre><h3 id="虚拟化配置"><a href="#虚拟化配置" class="headerlink" title="虚拟化配置"></a>虚拟化配置</h3><p>配置KVM</p>
<p>KVM中我们有两部分需要进行配置, libvirt和QEMU.</p>
<p>配置QEMU</p>
<p>KVM的配置项相对简单，仅需配置一项。编辑QEMU VNC配置文件/etc/libvirt/qemu.conf并取消如下行的注释。同时注释 security_driver=”none”</p>
<pre><code>vnc_listen=0.0.0.0
# security_driver=&quot;none&quot;
</code></pre><p>配置Libvirt<br>CloudStack使用libvirt管理虚拟机。因此正确的配置libvirt至关重要。Libvirt属于cloudstack-agent的依赖组件，应提前安装好。</p>
<p>为了实现动态迁移，libvirt需要监听使用非加密的TCP连接。还需要关闭libvirts尝试使用组播DNS进行广播。这些都是在 /etc/libvirt/libvirtd.conf文件中进行配置。</p>
<p>设置下列参数：</p>
<pre><code>listen_tls = 0
listen_tcp = 1
tcp_port = &quot;16059&quot;
auth_tcp = &quot;none&quot;
mdns_adv = 0
</code></pre><p>仅仅在libvirtd.conf中启用”listen_tcp”还不够，我们还必须修改/etc/sysconfig/libvirtd中的参数:</p>
<p>更改</p>
<pre><code>LIBVIRTD_ARGS=&quot;-1&quot;
</code></pre><p>重启libvirt服务</p>
<pre><code># service libvirtd restart
</code></pre><p>KVM配置完成</p>
<p>For the sake of completeness you should check if KVM is running OK on your machine:</p>
<pre><code># lsmod | grep kvm
</code></pre><p>输入lsmod | grep kvm命令后输出的信息</p>
<pre><code>kvm_intel              55496  0
kvm                   337772  1 kvm_intel
</code></pre><h2 id="系统配置"><a href="#系统配置" class="headerlink" title="系统配置"></a>系统配置</h2><h3 id="登陆到用户界面"><a href="#登陆到用户界面" class="headerlink" title="登陆到用户界面"></a>登陆到用户界面</h3><p>CloudStack提供一个基于web的UI，管理员和终端用户能够使用这个界面。</p>
<pre><code>http://&lt;management-server-ip-address&gt;:8080/client（后台管理网站）
</code></pre><p>如果管理服务器是全新的安装,。那么会出现一个安装向导。在稍后的访问中,你将看到一个登录界面,你需要通过用户名和密码登入来查看你的仪表盘.</p>
<pre><code>用户名 -&gt; 你账号的用户ID。默认用户名是admin。
密码 -&gt; 用户ID对应的密码。默认用户名的密码是password。
域 -&gt; 如果你是root用户，此处留空即可。
</code></pre><h3 id="根管理员界面的概述"><a href="#根管理员界面的概述" class="headerlink" title="根管理员界面的概述"></a>根管理员界面的概述</h3><p>在管理服务器软件安装并且运行后, 你就可以运行CloudStack的用户界面.了。在这里通过UI，可以供给、查看并管理你的云基础架构。</p>
<p>打开你自己喜欢的浏览器并访问这个URL。请把IP地址替换成你自己的管理服务器的IP。</p>
<p>http://<management-server-ip-address>:8080/client</management-server-ip-address></p>
<p>初次登录管理服务器时，会出现一个向导启动画面。后续访问时，您会直接进入控制面板。<br>如果你看到第一次的向导屏幕, 可以选择下面步骤之一进行。<br><strong>继续执行基本安装。</strong>如果你仅仅是想体验CloudStack，请选择这个，并且这样你可以马上开始跟着向导进行简单的配置。我们将帮助你建立一个有以下功能的云：一个运行CloudStack软件的机器和使用NFS协议的存储；一个运行VMs的XenServer或KVM hypervisor的服务器；一个共享的公有网络。安装向导的提示会给你需要的所有信息。但如果你需要更多的详细信息，你可以按照试用安装向导进行.</p>
<p>我之前用过CloudStack。 如果您已经完成设计阶段，计划部署一个复杂CloudStack云，或是准备对用基础安装向导搭建的试验云进行扩展，请选择此项。在管理员UI中，您可以使用CloudStack中更强大的功能，例如高级VLAN网络、高可用、负载均衡器和防火墙等额外网络设备，以及支持Citrix XenServer、KVM、VMware vSphere等多种虚拟化平台。</p>
<p>根管理员的仪表盘显示出来:<br>在云的安装及后续管理过程中，您需要用根管理员登录UI。根管理员账号管理着CloudStack的部署以及物理设施。根管理员可以修改系统配置，改变基本功能，创建和删除用户账号，以及其他仅限于已授权人员执行的操作。在初始安CloudStack时，请务必修改默认密码为新的较独特的密码。<br>打开你自己喜欢的浏览器并访问这个URL。请把IP地址替换成你自己的管理服务器的IP。</p>
<pre><code>http://&lt;management-server-ip-address&gt;:8080/client
使用当前root用户的ID和口令登录UI。缺省为admin，pawword。
点击帐户。
点击管理员帐号名。
点击查看用户。
点击管理员用户名。
点击更改密码按钮。 
输入新密码，然后点击确认。
</code></pre><h3 id="初始化配置"><a href="#初始化配置" class="headerlink" title="初始化配置"></a>初始化配置</h3><p>选择“基础架构 –&gt; 添加区域”按照截图进行配置.</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.1.png" alt="2.4.1"></p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.2.png" alt="2.4.2"><br>名称：zone        dns1：172.16.2.1        dns2：192.168.0.1（这些内容包括下面的填写仅为参考值。可根据实际情况进行修改）</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.3.png" alt="2.4.3"></p>
<p>物理网卡名称可以保持默认，改一下名也可以我改名为eth0</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.4.png" alt="2.4.4"></p>
<p>提供名称：pod        预留网关：192.168.0.1     预留掩码：255.255.255.0<br>起始IP：192.168.0.31    结束IP：192.168.0.50</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.5.png" alt="2.4.5"></p>
<p>来宾网关：192.168.0.1     掩码：255.255.255.0     起始IP:192.168.0.51  结束IP：192.168.0.80</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.6.png" alt="2.4.6"></p>
<p>集群名称我取名为cluster</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.7.png" alt="2.4.7"></p>
<p>主机名称：192.168.0.21        用户名：root    密码：<strong><em>*</em></strong>（这里用户名和密码，填写被添加主机的root用户和密码）</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.8.png" alt="2.4.8"><br>名称：primary   协议：选择nfs        服务器：192.168.0.24   路径：/export/primary</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.9.png" alt="2.4.9"></p>
<p>NFS服务器：192.168.0.24        路径：/export/secondary</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.10.png" alt="2.4.10"></p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.11.png" alt="2.4.11"></p>
<p>单击“是”启动区域！</p>
<p>查看系统VM。大约5-10分钟启动成功，如果启动失败，查看日志文件进行改进！</p>
<p>如果配置错误在可以在这里启动区域或禁用区域</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.12.png" alt="2.4.12"><br><img src="http://owawy15xy.bkt.clouddn.com/2.4.13.png" alt="2.4.13"></p>
<p>这里我的资源域已经启动了。</p>
<p>如果以上步骤均没有问题，则会显示如上图所示的界面，除了虚拟路由器数目仍旧为0，系统VM数目为2之外，其他所有组件的数目均为1。</p>
<p>系统VM是否启动成功可以查看其状态是否为Running：</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.14.png" alt="2.4.14"></p>
<p>系统VM是不同于主机上创建的普通虚拟机的，他们是CloudStack云平台自带的用于完成自身的一些任务的虚拟机。</p>
<p>Secondary Storage VM：简称为SSVM，用于管理二级存储的相关操作，如模板跟镜像文件的上传与下载，快照，volumes的存放，第一次创建虚拟机时从二级存储拷贝模板到一级存储并且自动创建快照，每一个资源域可以有多个SSVM，当SSVM被删除或停止，它会自动被重建并启动。</p>
<p>Console Proxy VM：用于在web 界面上展示控制台。</p>
<p>虚拟路由器将会在第一个实例启动后自动创建。</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.4.15.png" alt="2.4.15"></p>
<h2 id="启动虚拟机实例"><a href="#启动虚拟机实例" class="headerlink" title="启动虚拟机实例"></a>启动虚拟机实例</h2><h3 id="搭建一个http-服务器"><a href="#搭建一个http-服务器" class="headerlink" title="搭建一个http 服务器"></a>搭建一个http 服务器</h3><p>搭建http 服务主要用来管理ISO系统和镜像模板</p>
<p>在master 节点安装 nginx </p>
<pre><code># yum  -y install nginx
</code></pre><p>防火墙中加入允许80 端口访问</p>
<p>也可以直接关闭防火墙！在master管理节点不建议关闭防火墙！</p>
<pre><code>-A INPUT -p tcp -m state --state NEW -m tcp --dport 80 -j ACCEPT
</code></pre><p>编辑 /etc/nginx/nginx.conf  配置文件，能够使访问目录</p>
<pre><code>autoindex on;# 显示目录
autoindex_exact_size on;# 显示文件大小
autoindex_localtime on;# 显示文件时间
</code></pre><p>到 /usr/share/nginx/html  目录 删除所有文件 ，启动nginx</p>
<pre><code># /etc/init.d/nginx restart
</code></pre><p>上传ISO 到 /usr/share/nginx/html</p>
<p>看到如下界面</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.1.png" alt="2.5.1"><br>修改全局设置  secstorage.allowed 设置 ，二级存储ISO镜像和模板可以下载，IP网段改为0.0.0.0/0</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.2.png" alt="2.5.2"></p>
<h3 id="制作模板"><a href="#制作模板" class="headerlink" title="制作模板"></a>制作模板</h3><p>Cloudstack模版支持两种模式：</p>
<pre><code>一种是通过KVM 制作的qcow2或raw文件    
另外就是直接上传ISO文件作为模版文件
</code></pre><p>先在Cloudstack的模板注册中，添加ISO镜像文件，然后启动实例，选择从ISO启动，然后安装系统。</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.3.png" alt="2.5.3"><br>URL 输入下载ISO的地址</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.4.png" alt="2.5.4"></p>
<p>完成后，已就绪状态是 “YES”</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.5-1.png" alt="2.5.5-1"></p>
<p>用ISO 安装虚拟机实例<br><img src="http://owawy15xy.bkt.clouddn.com/2.5.5.png" alt="2.5.5"></p>
<p>选择ISO </p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.6.png" alt="2.5.6"></p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.7.png" alt="2.5.7"></p>
<p>选择磁盘方案</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.8.png" alt="2.5.8"></p>
<p>完成后选择 启动实例</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.9.png" alt="2.5.9"></p>
<p>安装centos 后 ，发现没有IP， 网卡处选择自动启动</p>
<p>对于CentOS，必须要修改网络接口的配置文件，在这里我们编辑/etc/sysconfig/network-scripts/ifcfg-eth0文件，更改下面的内容。</p>
<pre><code>DEVICE=eth0
TYPE=Ethernet
BOOTPROTO=dhcp
ONBOOT=yes
</code></pre><p>移除udev持久设备规则</p>
<pre><code># rm -f /etc/udev/rules.d/70*
# rm -f /var/lib/dhclient/*
</code></pre><p>移除SSH Keys</p>
<p>这步是为了确认所有要作为模板的VMs的SSH Keys都不相同，否则这样会降低虚拟机的安全性。</p>
<pre><code># rm -f /etc/ssh/*key*
</code></pre><p>清除日志文件</p>
<p>从主模板移除旧的日志文件是一个好习惯。</p>
<pre><code># cat /dev/null &gt; /var/log/audit/audit.log 2&gt;/dev/null
# cat /dev/null &gt; /var/log/wtmp 2&gt;/dev/null
# logrotate -f /etc/logrotate.conf 2&gt;/dev/null
# rm -f /var/log/*-* /var/log/*.gz 2&gt;/dev/null
</code></pre><p>清除用户历史</p>
<p>下一步来清除你曾经运行过的bash命令。</p>
<pre><code># history -c
# unset HISTFILE
</code></pre><p>关闭VM</p>
<p>现在你可以关闭你的主模板并且创建模板了！</p>
<pre><code># halt -p
</code></pre><p>创建模板！</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.10.png" alt="2.5.10"></p>
<p>成功后从模板列表中，可以看出</p>
<p><img src="http://owawy15xy.bkt.clouddn.com/2.5.11.png" alt="2.5.11"></p>
<p>接下来就可以用模板创建VM了！</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;理论基础&quot;&gt;&lt;a href=&quot;#理论基础&quot; class=&quot;headerlink&quot; title=&quot;理论基础&quot;&gt;&lt;/a&gt;理论基础&lt;/h1&gt;&lt;h2 id=&quot;云计算的出现&quot;&gt;&lt;a href=&quot;#云计算的出现&quot; class=&quot;headerlink&quot; title=&quot;云计算的出现&quot;&gt;&lt;/a&gt;云计算的出现&lt;/h2&gt;&lt;p&gt;基本上，云计算只是一种把 IT 资源当作服务来提供的手段。几乎所有 IT 资源都可以作为云服务来提供：应用程序、计算能力、存储容量、联网、编程工具，以至于通信服务和协作工具。&lt;br&gt;云计算最早为 Google、Amazon 等其他扩建基础设施的大型互联网服务提供商所采用。于是产生一种架构：大规模扩展、水平分布的系统资源，抽象为虚拟 IT 服务，并作为持续配置、合用的资源进行管理。&lt;br&gt;
    
    </summary>
    
      <category term="技术分享" scheme="http://yjscloud.com/categories/%E6%8A%80%E6%9C%AF%E5%88%86%E4%BA%AB/"/>
    
    
      <category term="Linux技术" scheme="http://yjscloud.com/tags/Linux%E6%8A%80%E6%9C%AF/"/>
    
      <category term="CloudStack" scheme="http://yjscloud.com/tags/CloudStack/"/>
    
  </entry>
  
  <entry>
    <title>LVS学习笔记</title>
    <link href="http://yjscloud.com/2017/09/13/LVS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>http://yjscloud.com/2017/09/13/LVS学习笔记/</id>
    <published>2017-09-13T02:47:43.000Z</published>
    <updated>2017-10-26T07:29:29.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="LVS简介"><a href="#LVS简介" class="headerlink" title="LVS简介"></a>LVS简介</h2><p>   负载均衡技术有很多实现方案，有基于DNS域名轮流解析的方法、有基于客户端调度访问的方法、有基于应用层系统负载的调度方法，还有基于IP地址的调度方法。本文介绍LVS目前有三种IP负载均衡技术（VS/NAT、VS/TUN和VS/DR）。</p>
 <a id="more"></a>
<p> LVS是Linux Virtual Server的简称，也就是Linux虚拟服务器, 用现在的观点来看就是个4层（传输层tcp/udp）的负责均衡器。 它是一个由章文嵩博士发起的自由软件项目，它的官方站点是www.linuxvirtualserver.org。现在LVS已经是 Linux标准内核的一部分，在Linux2.4内核以前，使用LVS时必须要重新编译内核以支持LVS功能模块，但是从Linux2.4内核以后，已经完全内置了LVS的各个功能模块，无需给内核打任何补丁，可以直接使用LVS提供的各种功能。</p>
<p>LVS技术要达到的目标是：通过LVS提供的负载均衡技术和Linux操作系统实现一个高性能、高可用的服务器群集，它具有良好可靠性、可扩展性和可操作性。从而以低廉的成本实现最优的服务性能。<br>LVS自从1998年开始，发展到现在已经是一个比较成熟的技术项目了。可以利用LVS技术实现高可伸缩的、高可用的网络服务，例如WWW服务、Cache服务、DNS服务、FTP服务、MAIL服务、视频/音频点播服务等等，有许多比较著名网站和组织都在使用LVS架设的集群系统，例如：Linux的门户网站（www.linux.com）、向RealPlayer提供音频视频服务而闻名的Real公司（www.real.com）、全球最大的开源网站（sourceforge.net）等。  </p>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><h4 id="功能特性"><a href="#功能特性" class="headerlink" title="功能特性"></a>功能特性</h4><p>1、抗负载能力强、是工作在网络4层之上仅作分发之用，没有流量的产生；<br>2、配置性比较低，这是一个缺点也是一个优点，因为没有可太多配置的东西，所以并不需要太多接触，大大减少了人为出错的几率；<br>3、工作稳定，自身有完整的双机热备方案；<br>4、无流量，保证了均衡器IO的性能不会收到大流量的影响；<br>5、应用范围比较广，可以对所有应用做负载均衡； </p>
<h4 id="高可用性"><a href="#高可用性" class="headerlink" title="高可用性"></a>高可用性</h4><p>LVS是一个基于内核级别的应用软件，因此具有很高的处理性能，用LVS构架的负载均衡集群系统具有优秀的处理能力，每个服务节点的故障不会影响整个系统的正常使用，同时又实现负载的合理均衡，使应用具有超高负荷的服务能力，可支持上百万个并发连接请求。如配置百兆网卡，采用VS/TUN或VS/DR调度技术，整个集群系统的吞吐量可高达1Gbits/s；如配置千兆网卡，则系统的最大吞吐量可接近10Gbits/s。</p>
<h4 id="高可靠性"><a href="#高可靠性" class="headerlink" title="高可靠性"></a>高可靠性</h4><p>LVS负载均衡集群软件已经在企业、学校等行业得到了很好的普及应用，国内外很多大型的、关键性的web站点也都采用了LVS集群软件，所以它的可靠性在实践中得到了很好的证实。有很多以LVS做的负载均衡系统，运行很长时间，从未做过重新启动。这些都说明了LVS的高稳定性和高可靠性。</p>
<h4 id="适用环境"><a href="#适用环境" class="headerlink" title="适用环境"></a>适用环境</h4><p>LVS对前端Director Server目前仅支持Linux和FreeBSD系统，但是支持大多数的TCP和UDP协议，支持TCP协议的应用有：HTTP，HTTPS ，FTP，SMTP，，POP3，IMAP4，PROXY，LDAP，SSMTP等等。支持UDP协议的应用有：DNS，NTP，ICP，视频、音频流播放协议等。<br>LVS对Real Server的操作系统没有任何限制，Real Server可运行在任何支持TCP/IP的操作系统上，包括Linux，各种Unix（如FreeBSD、Sun Solaris、HP Unix等），Mac/OS和Windows等。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>（1）需要网络环境的支持<br>（2）不能针对上层协议分析<br>（3）如果做成硬件会更完美</p>
<h2 id="LVS原理"><a href="#LVS原理" class="headerlink" title="LVS原理"></a>LVS原理</h2><h3 id="工作模式"><a href="#工作模式" class="headerlink" title="工作模式"></a>工作模式</h3><p>LVS的IP负载均衡技术是通过IPVS模块来实现的，IPVS是LVS集群系统的核心软件，它的主要作用是：安装在Director Server上，同时在Director Server上虚拟出一个IP地址，用户必须通过这个虚拟的IP地址访问服务。这个虚拟IP一般称为LVS的VIP，即Virtual IP。访问的请求首先经过VIP到达负载调度器，然后由负载调度器从Real Server列表中选取一个服务节点响应用户的请求。<br>当用户的请求到达负载调度器后，调度器如何将请求发送到提供服务的Real Server节点，而Real Server节点如何返回数据给用户，是IPVS实现的重点技术，IPVS实现负载均衡机制有三种，分别是NAT、TUN和DR。</p>
<p>注意：<br>director server 、ld 、lvs负责均衡器、调度器都是同一个概念<br>real server 、后端服务器也代表一个意思。</p>
<h3 id="三种转发机制介绍"><a href="#三种转发机制介绍" class="headerlink" title="三种转发机制介绍"></a>三种转发机制介绍</h3><h4 id="VS-NAT"><a href="#VS-NAT" class="headerlink" title="VS/NAT"></a>VS/NAT</h4><p>VS/NAT： 即（Virtual Server via Network Address Translation）<br>也就是网络地址翻译技术实现虚拟服务器，当用户请求到达调度器时，调度器将请求报文的目标地址（即虚拟IP地址）改写成选定的Real Server地址，同时报文的目标端口也改成选定的Real Server的相应端口，最后将报文请求发送到选定的Real Server。在服务器端得到数据后，Real Server返回数据给用户时，需要再次经过负载调度器将报文的源地址和源端口改成虚拟IP地址和相应端口，然后把数据发送给用户，完成整个负载调度过程。<br>可以看出，在NAT方式下，用户请求和响应报文都必须经过DS地址重写，当用户请求越来越多时，调度器的处理能力将称为瓶颈.<br><img src="http://ow78pfxd9.bkt.clouddn.com/VS:NAT.png" alt="VS/NAT"></p>
<h5 id="VS-NAT转发过程"><a href="#VS-NAT转发过程" class="headerlink" title="VS/NAT转发过程"></a>VS/NAT转发过程</h5><p>（1） 客户端发起请求到load balancer的虚拟ip<br>（2） load banlancer（Director）把客户请的目标地址改写为其中一个Real Server的，源地址改成不变。<br>（3）Real Server接受请求，并返回给load banlancer(Director)响应<br>（4） load banlancer(Director)接受到响应，修改目标地址为不变，源地址改成自己的。<br>（5） 客户端接受loader banlancer(Director)的响应</p>
<h5 id="VS-NAT特点"><a href="#VS-NAT特点" class="headerlink" title="VS/NAT特点"></a>VS/NAT特点</h5><p>请求和响应报文都经过Director<br>多目标的DNAT（iptables）:通过修改请求报文的目标ip地址（可能会修改目标端口）,至挑选出某RS的RIP地址实现转发</p>
<p>（1）Real Server应该和DIP应该使用私网地址，且Real Server的网关要指向DIP,</p>
<p>（2）请求和响应报文都要经由Director转发,</p>
<p>（3）支持端口映射,</p>
<p>（4）Real Server可以使用任意os,</p>
<p>（5）Real Server的RIP和Director的必须在同一网络</p>
<h4 id="文中简写字母备注-同下"><a href="#文中简写字母备注-同下" class="headerlink" title="文中简写字母备注(同下)"></a>文中简写字母备注(同下)</h4><p>调度器 ：Director ，Dispatcher,Dalancer </p>
<p>Client IP : CIP(用户IP)</p>
<p>Director Virutal ip : VIP(调度器虚拟网卡IP【外网IP】)</p>
<p>Director IP : DIP（调度器IP【对内IP】）</p>
<p>Real Serverip : RIP（真实服务器IP）</p>
<h4 id="VS-TUN"><a href="#VS-TUN" class="headerlink" title="VS/TUN"></a>VS/TUN</h4><p>即（Virtual Server via IP Tunneling）<br>也就是IP隧道技术实现虚拟服务器。它的连接调度和管理与VS/NAT方式一样，只是它的报文转发方法不同，VS/TUN方式中，调度器采用IP隧道技术将用户请求转发到某个Real Server，而这个Real Server将直接响应用户的请求，不再经过前端调度器，此外，对Real Server的地域位置没有要求，可以和Director Server位于同一个网段，也可以是独立的一个网络。因此，在TUN方式中，调度器将只处理用户的报文请求，集群系统的吞吐量大大提高。<br><img src="http://ow78pfxd9.bkt.clouddn.com/TUNNEL.png" alt="TUNNEL"></p>
<h5 id="VS-TUN转发过程"><a href="#VS-TUN转发过程" class="headerlink" title="VS/TUN转发过程"></a>VS/TUN转发过程</h5><p>（1）客户端发起请求到load balancer的虚拟ip</p>
<p>（2） load banlancer把客户的请求包包裹，然后转发给其中的一个real server</p>
<p>（3） real server接受请求、解包，得到客户端发来的原始包</p>
<p>（4） real server处理，把结果通过vip直接返回给客户端</p>
<p>（5） 客户端接受real server的响应。</p>
<p>注意：<br>（a） load balancer和real server 直接通过ip tunnel技术重新封装、解包</p>
<p>（b） load balancer和 real server 使用相同的vip</p>
<p>（c） load balnacer和real server可以不再同一个网络</p>
<h5 id="VS-TUN特点"><a href="#VS-TUN特点" class="headerlink" title="VS/TUN特点"></a>VS/TUN特点</h5><p>不修改请求报文的IP首部，而是通过在原有的IP首部（CIP&lt;–&gt;VIP）之外，再封装一个IP首部（DIP&lt;–&gt;RIP）<br>    （1）RIP,DIP,VIP全得是公网地址<br>    （2）Real Server的网关不能指向DIP<br>    （3）请求报文必须经由Director调度，但响应报文不必须不能经由Director<br>    （4）不支持端口映射<br>    （5）Real Server的os必须支持隧道功能</p>
<h4 id="VS-DR"><a href="#VS-DR" class="headerlink" title="VS/DR"></a>VS/DR</h4><p>即（Virtual Server via Direct Routing）<br>也就是用直接路由技术实现虚拟服务器。它的连接调度和管理与VS/NAT和VS/TUN中的一样，但它的报文转发方法又有不同，VS/DR通过改写请求报文的MAC地址，将请求发送到Real Server，而Real Server将响应直接返回给客户，免去了VS/TUN中的IP隧道开销。这种方式是三种负载调度机制中性能最高最好的，但是必须要求Director Server与Real Server都有一块网卡连在同一物理网段上。</p>
<p><img src="http://ow78pfxd9.bkt.clouddn.com/VS:DR.png" alt="VS/DR"></p>
<h5 id="VS-DR转发过程"><a href="#VS-DR转发过程" class="headerlink" title="VS/DR转发过程"></a>VS/DR转发过程</h5><p>（1）客户端发起请求到load balancer的虚拟ip<br>（2）load banlancer把客户发送的包，修改源mac地址为vip的，目的mac地址为real server的，然后发送给real server<br>（3）real server接受请求,并处理，然后把结果通过vip直接返回给客户端。<br>（4）客户端接受real server的响应。<br>注意<br>（a）load balancer和 real server 使用相同的vip<br>（b）load balancer和real server必须在同一个网络，因为load balancer需要知道real server的mac地址。    </p>
<h5 id="VS-DR特点"><a href="#VS-DR特点" class="headerlink" title="VS/DR特点"></a>VS/DR特点</h5><p>DR仅请求报文经由director，响应报文时由RS直接响应client,它通过修改请求报文的目标mac地址进行转发.</p>
<p>(1）保证前端路由器将目标IP为VIP的请求报文发给Director</p>
<pre><code>解决方案：
   静态绑定
   arptables
   修改RS主机内核的参数
</code></pre><p>（2）RS的RIP可以使用私有地址；但也可以使用公网地址</p>
<p>（3）RS跟Director必须在同一物理网络中</p>
<p> (4）请求报文经由Director调度，但响应报文一定不能经由Director</p>
<p>（5）不支持端口映射</p>
<p>（6）RS可以大多数OS</p>
<p>（7）RS的网关不能指向DIP</p>
<h4 id="三种转发机制的优缺点"><a href="#三种转发机制的优缺点" class="headerlink" title="三种转发机制的优缺点"></a>三种转发机制的优缺点</h4><p>◆Virtual Server via NAT</p>
<p>VS/NAT 的优点是服务器可以运行任何支持TCP/IP的操作系统，它只需要一个IP地址配置在LVS主机上，服务器组可以用私有的IP地址。缺点是它的扩充能力有限，当服务器结点数目升到20时，LVS主机本身有可能成为系统的新瓶颈，因为在VS/NAT中请求和响应封包都需要通过负载平衡LVS主机。在 Pentium 166主机上测得重写封包的平均延时为60us，假设TCP封包的平均长度为536 Bytes，则LVS主机的最大吞吐量为8.93 MBytes/s。再假设每台服务器的吞吐量为600KBytes/s，这样一个LVS主机可以带动16台服务器。</p>
<p>◆Virtual Server via IP Tunneling</p>
<p>在VS/TUN 的集群系统中，负载平衡LVS主机只将请求分配到不同的实际服务器，实际服务器将应答的资料直接返回给用户。这样，负载平衡LVS主机就可以处理巨量的请求，而不会成为系统的瓶颈。即使负载平衡LVS主机只有100Mbps的全双工网卡，虚拟服务器的最大吞吐量可以达到几Gbps。所以，VS/TUN可以极大地增加负载平衡LVS主机分配的服务器数量，它可以用来构建高性能超级服务器。VS/TUN技术对服务器的要求是所有的服务器必须支持”IP Tunneling”或者”IP Encapsulation”协议。目前，VS/TUN 的后端服务器主要运行Linux操作系统。因为”IP Tunneling”正成为各个操作系统的标准协议，所以VS/TUN也会适用运行其它操作系统的后端服务器。</p>
<p>◆Virtual Server via Direct Routing</p>
<p>同VS/TUN 一样，VS/DRLVS主机只处理客户到服务器端的连接，响应资料可以直接从独立的网络路由返回给客户。这可以极大地提高LVS集群系统的伸缩性。同 VS/TUN相比，这种方法没有IP隧道的开销，但是要求负载平衡LVS主机与实际服务器都有一块网卡连在同一物理网段上，服务器网络设备或者设备别名不作ARP响应。</p>
<p>对比结果<br><img src="http://ow78pfxd9.bkt.clouddn.com/find.png" alt="find"></p>
<h2 id="LVS的调度算法"><a href="#LVS的调度算法" class="headerlink" title="LVS的调度算法"></a>LVS的调度算法</h2><p>Director在接收到来自于Client的请求时，会基于”schedule”从RealServer中选择一个响应给Client。ipvs支持以下调度算法：（1、2为静态调度算法，3、4、5、6、7、8为动态调度算法）</p>
<p>1、 轮询（round robin, rr)</p>
<p>2．  加权轮询(Weighted round robin, wrr)：<br>新的连接请求被轮流分配至各RealServer；算法的优点是其简洁性，它无需记录当前所有连接的状态，所以它是一种无状态调度。轮叫调度算法假设所有服务器处理性能均相同，不管服务器的当前连接数和响应速度。该算法相对简单，不适用于服务器组中处理性能不一的情况，而且当请求服务时间变化比较大时，轮叫调度算法容易导致服务器间的负载不平衡。</p>
<p>2、目标地址散列调度（Destination Hashing，dh）：<br>算法也是针对目标IP地址的负载均衡，但它是一种静态映射算法，通过一个散列（Hash）函数将一个目标IP地址映射到一台服务器。目标地址散列调度算法先 根据请求的目标IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。</p>
<p>3、源地址散列调度（Source Hashing，sh）：<br>算法正好与目标地址散列调度算法相反，它根据请求的源IP地址，作为散列键（Hash Key）从静态分配的散列表找出对应的服务器，若该服务器是可用的且未超载，将请求发送到该服务器，否则返回空。它采用的散列函数与目标地址散列调度算法 的相同。除了将请求的目标IP地址换成请求的源IP地址外，它的算法流程与目标地址散列调度算法的基本相似。在实际应用中，源地址散列调度和目标地址散列 调度可以结合使用在防火墙集群中，它们可以保证整个系统的唯一出入口。</p>
<p>4、最少连接(least connected, lc)， 加权最少连接(weighted least connection, wlc)：<br>新的连接请求将被分配至当前连接数最少的RealServer；最小连接调度是一种动态调度算法，它通过服务器当前所活跃的连接数来估计服务器的负载情况。调度器需要记录各个服务器已建立连接的数目，当一个请求被调度到某台服务器，其连接数加1；当连接中止或超时，其连接数减一。<br>lc：256<em>A+I=当前连接数  wlc：（256</em>A+I）/W=当前连接数   【A：活动连接数  I:非活动连接数 W：权重值】</p>
<p>5、基于局部性的最少链接调度（Locality-Based Least Connections Scheduling，lblc）：<br>针对请求报文的目标IP地址的负载均衡调度，目前主要用于Cache集群系统，因为在Cache集群中客户请求报文的目标IP地址是变化的。这里假设任何后端服务器都可以处理任一请求，算法的设计目标是在服务器的负载基本平衡情况下，将相同目标IP地址的请求调度到同一台服务器，来提高各台服务器的访问局部性和主存Cache命中率，从而整个集群系统的处理能力。LBLC调度算法先根据请求的目标IP地址找出该目标IP地址最近使用的服务器，若该服务器是可用的且没有超载，将请求发送到该服务器；若服务器不存在，或者该服务器超载且有服务器处于其一半的工作负载，则用“最少链接”的原则选出一个可用的服务器，将请求发送到该服务器。</p>
<p>6、带复制的基于局部性最少链接调度（Locality-Based Least Connections with Replication Scheduling，lblcr）：<br>也是针对目标IP地址的负载均衡，目前主要用于Cache集群系统。它与LBLC算法的不同之处是它要维护从一个目标IP地址到一组服务器的映射，而 LBLC算法维护从一个目标IP地址到一台服务器的映射。对于一个“热门”站点的服务请求，一台Cache 服务器可能会忙不过来处理这些请求。这时，LBLC调度算法会从所有的Cache服务器中按“最小连接”原则选出一台Cache服务器，映射该“热门”站点到这台Cache服务器，很快这台Cache服务器也会超载，就会重复上述过程选出新的Cache服务器。这样，可能会导致该“热门”站点的映像会出现在所有的Cache服务器上，降低了Cache服务器的使用效率。LBLCR调度算法将“热门”站点映射到一组Cache服务器（服务器集合），当该“热门”站点的请求负载增加时，会增加集合里的Cache服务器，来处理不断增长的负载；当该“热门”站点的请求负载降低时，会减少集合里的Cache服务器数目。这样，该“热门”站点的映像不太可能出现在所有的Cache服务器上，从而提供Cache集群系统的使用效率。LBLCR算法先根据请求的目标IP地址找出该目标IP地址对应的服务器组；按“最小连接”原则从该服务器组中选出一台服务器，若服务器没有超载，将请求发送到该服务器；若服务器超载；则按“最小连接”原则从整个集群中选出一台服务器，将该服务器加入到服务器组中，将请求发送到该服务器。同时，当该服务器组有一段时间没有被修改，将最忙的服务器从服务器组中删除，以降低复制的程度。</p>
<p>7、 最短的期望的延迟（Shortest Expected Delay Scheduling ,sed）<br>sed: (A+1)/w=当前连接数</p>
<p>8、最少队列调度（Never Queue Scheduling ,nq）：<br>无需队列。如果有台realserver的连接数＝0就直接分配过去，不需要在进行sed运算</p>
<h2 id="ipvsadm命令的使用"><a href="#ipvsadm命令的使用" class="headerlink" title="ipvsadm命令的使用"></a>ipvsadm命令的使用</h2><p>管理service</p>
<figure class="highlight haml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"></div><div class="line">-<span class="ruby">A (--add-service)  添加service </span></div><div class="line"># ipvsadm -A -t 192.168.0.10:80 -s rr</div><div class="line"> </div><div class="line">-<span class="ruby">E (--edit-service)  编辑/修改service </span></div><div class="line"># ipvsadm -E -t 192.168.0.10:80 -s wlc -p 600</div><div class="line"> </div><div class="line">-<span class="ruby">D (--delete-service)  删除service </span></div><div class="line"># ipvsadm -D -t 192.168.0.10:80</div><div class="line"> </div><div class="line">-<span class="ruby">s (--scheduler)  调度算法</span></div><div class="line">-<span class="ruby">t (--tcp-service)  tcp端口</span></div><div class="line">-<span class="ruby">u (--udp-service)  udp端口</span></div><div class="line">-<span class="ruby"><span class="number">6</span> (--ipv6)  ipv6地址</span></div><div class="line">-<span class="ruby">p (--persistent)  客户端连接超时时间，默认<span class="number">360</span>秒</span></div><div class="line">-<span class="ruby">M (--netmask)  子网掩码</span></div></pre></td></tr></table></figure>
<p>补充 ：-s 参数后面接的调度算法，常见有下面8种</p>
<figure class="highlight vim"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">rr    轮询</div><div class="line">wrr   加权轮询</div><div class="line"><span class="keyword">sh</span>    源地址哈希</div><div class="line">dh    目标地址哈希</div><div class="line"><span class="keyword">lc</span>    最少连接</div><div class="line">wlc   加权最少连接</div><div class="line">sed   最少期望延迟</div><div class="line">nq    永不排队</div></pre></td></tr></table></figure>
<p>管理realserver/后端服务器</p>
<figure class="highlight haml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">-<span class="ruby">a (--add-server)  添加realserver</span></div><div class="line"># ipvsadm -A -t 192.168.0.10:80 -r 192.168.1.2:80 -&#123;m|g|i&#125;</div><div class="line"> </div><div class="line">-<span class="ruby">e (--add-server)  编辑/修改realserver</span></div><div class="line"># ipvsadm -A -t 192.168.0.10:80 -r 192.168.1.3:80 -m -w 2</div><div class="line"> </div><div class="line">-<span class="ruby">d (--add-server)  删除realserver</span></div><div class="line"># ipvsadm -A -t 192.168.0.10:80 -r 192.168.1.3:80</div><div class="line"> </div><div class="line">-<span class="ruby">r (--real-server)  接realserver ip地址</span></div><div class="line">-<span class="ruby">m (--gatewaying)  NAT模式</span></div><div class="line">-<span class="ruby">g (--gatewaying)  DR直接路由模式</span></div><div class="line">-<span class="ruby">i (--ipip)  IP-TUN隧道模式</span></div><div class="line">-<span class="ruby">w (--weight)  权重</span></div><div class="line">-<span class="ruby">-set [tcp tcpfin udp] 设置连接超时时间</span></div></pre></td></tr></table></figure>
<p>状态查看</p>
<figure class="highlight haml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">#ipvsadm -ln 是最常用的</div><div class="line">-<span class="ruby">L<span class="params">|l (--list)  查看调度器状态</span></span></div><div class="line">-<span class="ruby"><span class="params">L --timeout  显示连接超时时间[tcp tcpfin udp]</span></span></div><div class="line">-<span class="ruby"><span class="params">L --daemon   显示守护进程状态</span></span></div><div class="line">-<span class="ruby"><span class="params">L --stats    显示统计信息，收发包数量</span></span></div><div class="line">-<span class="ruby"><span class="params">L --rate     显示收发包速率</span></span></div><div class="line">-<span class="ruby"><span class="params">L --sort     排序输出</span></span></div><div class="line"> </div><div class="line">-<span class="ruby"><span class="params">n (--numeric)  不反解IP到主机名</span></span></div><div class="line">-<span class="ruby"><span class="params">c (--connection)  连接数</span></span></div></pre></td></tr></table></figure>
<p>规则/配置管理</p>
<figure class="highlight haml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">-<span class="ruby">C (--clear)  清空当前ipvsadm配置</span></div><div class="line">-<span class="ruby">Z (--zero)  清空计数器</span></div><div class="line"> </div><div class="line">-<span class="ruby">R (--restore)  还原（导入）规则</span></div><div class="line"># ipvsadm -R &lt; /root/ipvs.config</div><div class="line"> </div><div class="line">-<span class="ruby">S (--save)  保存（导出）当前规则</span></div><div class="line"># ipvsadm -S &gt; /root/ipvs.config</div></pre></td></tr></table></figure>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;LVS简介&quot;&gt;&lt;a href=&quot;#LVS简介&quot; class=&quot;headerlink&quot; title=&quot;LVS简介&quot;&gt;&lt;/a&gt;LVS简介&lt;/h2&gt;&lt;p&gt;   负载均衡技术有很多实现方案，有基于DNS域名轮流解析的方法、有基于客户端调度访问的方法、有基于应用层系统负载的调度方法，还有基于IP地址的调度方法。本文介绍LVS目前有三种IP负载均衡技术（VS/NAT、VS/TUN和VS/DR）。&lt;/p&gt;
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Linux学习笔记" scheme="http://yjscloud.com/tags/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="keepalived" scheme="http://yjscloud.com/tags/keepalived/"/>
    
  </entry>
  
  <entry>
    <title>Web安全防御之初探WAF</title>
    <link href="http://yjscloud.com/2017/05/12/Web%E5%AE%89%E5%85%A8%E9%98%B2%E5%BE%A1%E4%B9%8B%E5%88%9D%E6%8E%A2WAF/"/>
    <id>http://yjscloud.com/2017/05/12/Web安全防御之初探WAF/</id>
    <published>2017-05-11T23:44:59.000Z</published>
    <updated>2017-05-12T01:10:22.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="了解waf"><a href="#了解waf" class="headerlink" title="了解waf"></a>了解waf</h1><h2 id="什么是WAF"><a href="#什么是WAF" class="headerlink" title="什么是WAF"></a>什么是WAF</h2><p>Web应用防护系统（也称：网站应用级入侵防御系统 。<br>英文：Web Application Firewall，简称： WAF）。<br>利用国际上公认的一种说法：Web应用 防火墙 是通过执行一系列针对HTTP/HTTPS的 安全策略 来专门为Web应用提供保护的一款产品。</p>
<h2 id="常见的web入侵行为"><a href="#常见的web入侵行为" class="headerlink" title="常见的web入侵行为"></a>常见的web入侵行为</h2><h3 id="SQL注入"><a href="#SQL注入" class="headerlink" title="SQL注入"></a>SQL注入</h3><p>SQL注入恐怕是黑客们最为常见的入侵web站点的手段，黑客通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。</p>
<h3 id="xss"><a href="#xss" class="headerlink" title="xss"></a>xss</h3><p>只要是人做出了东西都会存在或多或少的缺陷，我们的web站点也不例外，xss攻击通常指的是通过利用网页开发时留下的漏洞，通过巧妙的方法注入恶意指令代码到网页，使用户加载并执行攻击者恶意制造的网页程序。</p>
<h3 id="不安全下载"><a href="#不安全下载" class="headerlink" title="不安全下载"></a>不安全下载</h3><p>这是运维工程师在网站部署时经常犯的错误，由于在部署网站是为了方便配置网站，运维工程师可能会把配置文件放在网站的根目录下，如果有人访问网站的根目录里的配置文件（类似这些：code_backup.tar.gz  .sql）那我们的整个网站将会暴露管理员的账号也可能被盗走。</p>
<h3 id="隐私文件访问"><a href="#隐私文件访问" class="headerlink" title="隐私文件访问"></a>隐私文件访问</h3><p>这个原因同样是因为管理员的配置不当使网站的重要信息暴露在外（类似这些文件：.svn .git）</p>
<h3 id="弱口令"><a href="#弱口令" class="headerlink" title="弱口令"></a>弱口令</h3><p>在当今很多地方以用户名(帐号)和口令作为鉴权的世界，口令的重要性就可想而知了。口令就相当于进入家门的钥匙，当他人有一把可以进入你家的钥匙，想想你的安全、你的财物、你的隐私……害怕了吧。因为弱口令很容易被他人猜到或破解，所以如果你使用弱口令，就像把家门钥匙放在家门口的垫子下面，是非常危险的，同理如果管理员把网站的后台密码设置的很简单那无疑是把网站拱手让给黑客</p>
<h3 id="非授权范文"><a href="#非授权范文" class="headerlink" title="非授权范文"></a>非授权范文</h3><p>当管理员要把网站的数据库信息交给客户查看时，有时管理员可能忘记给数据库加密码这就造成了这个数据库暴露在公网，这就造成了数据泄露。</p>
<h3 id="cc攻击"><a href="#cc攻击" class="headerlink" title="cc攻击"></a>cc攻击</h3><p>cc攻击无法避免，只能缓解,如果设置强有力的过滤规则则可能把正常的用户请求拒绝在外。其中性能cc攻击对网站可使网站直接经济服务</p>
<h3 id="DDOS攻击"><a href="#DDOS攻击" class="headerlink" title="DDOS攻击"></a>DDOS攻击</h3><p>DDOS攻击对于那些带宽大的网站他们能做的一是扛，二是挡，带宽小的网站就比较悲剧了只能等攻击者停止攻击才能恢复网站的正常使用。网站也可以接入云清洗分散攻击流量，道高一尺魔高一丈，如果攻击者调用更多的攻击流量来打网站，网站也只能跪，我们无法杜绝DDOS攻击，为保证网站可以正常的使用我们所能做的是“扛”、“挡”、“分”。</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>Nginx网站可以通过配置规则来抵御cc攻击（频率限制）、不安全下载（判断后缀）、非授权访问（后缀，认证）、测试防护（根据UA）、设置ip黑名单。但是其所实现的功能及其有限，为了保证网站的正常功能我们就需要借助更为强大的工具来应对各种威胁，waf由此应运而生。</p>
<h2 id="waf功能"><a href="#waf功能" class="headerlink" title="waf功能"></a>waf功能</h2><p>1.支持IP白名单和黑名单功能，直接将黑名单的IP访问拒绝。</p>
<p>2.支持URL白名单，将不需要过滤的URL进行定义。</p>
<p>3.支持User-Agent的过滤，匹配自定义规则中的条目，然后进行处理（返回403）。</p>
<p>4.支持CC攻击防护，单个URL指定时间的访问次数，超过设定值，直接返回403。</p>
<p>5.支持Cookie过滤，匹配自定义规则中的条目，然后进行处理（返回403）。</p>
<p>6.支持URL过滤，匹配自定义规则中的条目，如果用户请求的URL包含这些，返回403。</p>
<p>7.支持URL参数过滤，原理同上。</p>
<p>8.支持日志记录，将所有拒绝的操作，记录到日志中去</p>
<h2 id="WAF的特点"><a href="#WAF的特点" class="headerlink" title="WAF的特点"></a>WAF的特点</h2><h3 id="异常检测协议"><a href="#异常检测协议" class="headerlink" title="异常检测协议"></a>异常检测协议</h3><p>Web应用防火墙会对HTTP的请求进行异常检测，拒绝不符合HTTP标准的请求。并且，它也可以只允许HTTP协议的部分选项通过，从而减少攻击的影响范围。甚至，一些Web应用防火墙还可以严格限定HTTP协议中那些过于松散或未被完全制定的选项。</p>
<h3 id="增强的输入验证"><a href="#增强的输入验证" class="headerlink" title="增强的输入验证"></a>增强的输入验证</h3><p>增强输入验证，可以有效防止网页篡改、信息泄露、木马植入等恶意网络入侵行为。从而减小Web服务器被攻击的可能性。</p>
<h3 id="及时补丁"><a href="#及时补丁" class="headerlink" title="及时补丁"></a>及时补丁</h3><p>修补Web安全漏洞，是Web应用开发者最头痛的问题，没人会知道下一秒有什么样的漏洞出现，会为Web应用带来什么样的危害。WAF可以为我们做这项工作了——只要有全面的漏洞信息WAF能在不到一个小时的时间内屏蔽掉这个漏洞。当然，这种屏蔽掉漏洞的方式不是非常完美的，并且没有安装对应的补丁本身就是一种安全威胁，但我们在没有选择的情况下，任何保护措施都比没有保护措施更好。</p>
<h3 id="基于规则的保护和基于异常的保护"><a href="#基于规则的保护和基于异常的保护" class="headerlink" title="基于规则的保护和基于异常的保护"></a>基于规则的保护和基于异常的保护</h3><p>基于规则的保护可以提供各种Web应用的安全规则，WAF生产商会维护这个规则库，并时时为其更新。<br>用户可以按照这些规则对应用进行全方面检测。还有的产品可以基于合法应用数据建立模型，并以此为依据判断应用数据的异常。但这需要对用户企业的应用具有十分透彻的了解才可能做到，可现实中这是十分困难的一件事情。</p>
<h3 id="状态管理"><a href="#状态管理" class="headerlink" title="状态管理"></a>状态管理</h3><p>WAF能够判断用户是否是第一次访问并且将请求重定向到默认登录页面并且记录事件。通过检测用户的整个操作行为我们可以更容易识别攻击。状态管理模式还能检测出异常事件（比如登陆失败），并且在达到极限值时进行处理。这对暴力攻击的识别和响应是十分有利的。</p>
<h3 id="其他防护技术"><a href="#其他防护技术" class="headerlink" title="其他防护技术"></a>其他防护技术</h3><p>WAF还有一些安全增强的功能，可以用来解决WEB程序员过分信任输入数据带来的问题。比如：隐藏表单域保护、抗入侵规避技术、响应监视和信息泄露保护。</p>
<h2 id="WAF与网络防火墙的区别"><a href="#WAF与网络防火墙的区别" class="headerlink" title="WAF与网络防火墙的区别"></a>WAF与网络防火墙的区别</h2><p>网络防火墙作为访问控制设备，主要工作在OSI模型三、四层，基于IP报文进行检测。只是对端口做限制，对TCP协议做封堵。其产品设计无需理解HTTP会话，也就决定了无法理解Web应用程序语言如HTML、SQL语言。因此，它不可能对HTTP通讯进行输入验证或攻击规则分析。针对Web网站的恶意攻击绝大部分都将封装为HTTP请求，从80或443端口顺利通过防火墙检测。一些定位比较综合、提供丰富功能的防火墙，也具备一定程度的应用层防御能力，如能根据TCP会话异常性及攻击特征阻止网络层的攻击，通过IP分拆和组合也能判断是否有攻击隐藏在多个数据包中，但从根本上说他仍然无法理解HTTP会话，难以应对如SQL注入、跨站脚本、cookie窃取、网页篡改等应用层攻击。web应用防火墙能在应用层理解分析HTTP会话，因此能有效的防止各类应用层攻击，同时他向下兼容，具备网络防火墙的功能。    </p>
<h1 id="初探实现WAF"><a href="#初探实现WAF" class="headerlink" title="初探实现WAF"></a>初探实现WAF</h1><h2 id="WAF实现规划"><a href="#WAF实现规划" class="headerlink" title="WAF实现规划"></a>WAF实现规划</h2><p>分析步骤如下：解析HTTP请求==》匹配规则==》防御动作==》记录日志<br>具体实现如下：</p>
<p>解析http请求：协议解析模块<br>匹配规则：规则检测模块，匹配规则库<br>防御动作：return 403 或者跳转到自定义界面<br>日志记录：记录到elk中</p>
<h2 id="OpenResty部署"><a href="#OpenResty部署" class="headerlink" title="OpenResty部署"></a>OpenResty部署</h2><p>安装依赖包</p>
<pre><code>[root@nginx ~]# yum install -y readline-devel pcre-devel openssl-devel
</code></pre><p>下载并编译安装openresty</p>
<pre><code>[root@nginx ~]# wget https://openresty.org/download/ngx_openresty-1.9.3.2.tar.gz
[root@nginx ~]# tar zxf ngx_openresty-1.9.3.2.tar.gz
[root@nginx ~]# cd ngx_openresty-1.9.3.2
[root@nginx ngx_openresty-1.9.3.2]# ./configure --prefix=/usr/local/openresty-1.9.3.2 \
--with-luajit --with-http_stub_status_module \
--with-pcre --with-pcre-jit
[root@nginx ngx_openresty-1.9.3.2]# gmake &amp;&amp; gmake install
[root@nginx ngx_openresty-1.9.3.2]#ln -s /usr/local/openresty-1.9.3.2/ /usr/local/openresty
</code></pre><p>测试openresty安装</p>
<pre><code>[root@nginx ngx_openresty-1.9.3.2]# vim /usr/local/openresty/nginx/conf/nginx.conf
server {
location /hello {
        default_type text/html;
        content_by_lua_block {
            ngx.say(&quot;HelloWorld&quot;)
        }
    }
}
[root@nginx ~]# /usr/local/openresty/nginx/sbin/nginx -t
nginx: the configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf syntax is ok
nginx: configuration file /usr/local/openresty-1.9.3.2/nginx/conf/nginx.conf test is successful
[root@nginx ~]# /usr/local/openresty/nginx/sbin/nginx
</code></pre><p>关闭防火墙</p>
<pre><code>[root@nginx ~]# systemctl stop firewalld.service
</code></pre><p><img src="http://oovxjr0mr.bkt.clouddn.com/hello.png" alt="hello"></p>
<h2 id="WAF部署"><a href="#WAF部署" class="headerlink" title="WAF部署"></a>WAF部署</h2><p>安装git</p>
<pre><code>[root@nginx ~]# yum -y install git
</code></pre><p>克隆WAF项目</p>
<pre><code>[root@nginx ~]#git clone https://github.com/unixhot/waf.git
</code></pre><p>把waf目录拷贝到Nginx配置目录下</p>
<pre><code>[root@nginx ~]#cp -a ./waf/waf /usr/local/openresty/nginx/conf/
</code></pre><p>修改Nginx的配置文件，加入以下配置。注意路径，同时WAF日志默认存放在/tmp/日期_waf.log</p>
<pre><code>[root@nginx ~]# vim /usr/local/openresty/nginx/conf/nginx.conf
#WAF
lua_shared_dict limit 50m;
lua_package_path &quot;/usr/local/openresty/nginx/conf/waf/?.lua&quot;;
init_by_lua_file &quot;/usr/local/openresty/nginx/conf/waf/init.lua&quot;;
access_by_lua_file &quot;/usr/local/openresty/nginx/conf/waf/access.lua&quot;;
[root@nginx ~]# /usr/local/openresty/nginx/sbin/nginx –t
[root@nginx ~]# /usr/local/openresty/nginx/sbin/nginx
</code></pre><p>根据日志记录位置，创建日志目录</p>
<pre><code>[root@nginx ~]# mkdir /tmp/waf_logs
[root@nginx ~]# chmod 777 /tmp/waf_logs(为了测试权限直接设置为777，大家千万不要学)
</code></pre><h2 id="学习配置模块"><a href="#学习配置模块" class="headerlink" title="学习配置模块"></a>学习配置模块</h2><p>WAF上生产之前，建议不要直接上生产，而是先记录日志，不做任何动作。确定WAF不产生误杀<br>config.lua即WAF功能详解</p>
<figure class="highlight gauss"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">root<span class="comment">@nginx waf]# pwd</span></div><div class="line">/usr/local/openresty/nginx/conf/waf</div><div class="line">[root@nginx waf]<span class="meta"># cat config.lua</span></div><div class="line"> --WAF config file,<span class="keyword">enable</span> = <span class="string">"on"</span>,<span class="keyword">disable</span> = <span class="string">"off"</span> </div><div class="line"> --waf status    </div><div class="line"> config_waf_enable = <span class="string">"on"</span>   <span class="meta">#是否开启配置</span></div><div class="line"> --<span class="built_in">log</span> dir </div><div class="line"> config_log_dir = <span class="string">"/tmp/waf_logs"</span>    <span class="meta">#日志记录地址</span></div><div class="line"> --rule setting </div><div class="line"> config_rule_dir = <span class="string">"/usr/local/nginx/conf/waf/rule-config"</span>        </div><div class="line">                          <span class="meta">#匹配规则缩放地址</span></div><div class="line"> --<span class="keyword">enable</span>/<span class="keyword">disable</span> white url </div><div class="line"> config_white_url_check = <span class="string">"on"</span>  <span class="meta">#是否开启url检测</span></div><div class="line"> --<span class="keyword">enable</span>/<span class="keyword">disable</span> white ip </div><div class="line"> config_white_ip_check = <span class="string">"on"</span>   <span class="meta">#是否开启IP白名单检测</span></div><div class="line"> --<span class="keyword">enable</span>/<span class="keyword">disable</span> block ip </div><div class="line"> config_black_ip_check = <span class="string">"on"</span>   <span class="meta">#是否开启ip黑名单检测</span></div><div class="line"> --<span class="keyword">enable</span>/<span class="keyword">disable</span> url filtering </div><div class="line"> config_url_check = <span class="string">"on"</span>      <span class="meta">#是否开启url过滤</span></div><div class="line"> --enalbe/<span class="keyword">disable</span> url args filtering </div><div class="line"> config_url_args_check = <span class="string">"on"</span>   <span class="meta">#是否开启参数检测</span></div><div class="line"> --<span class="keyword">enable</span>/<span class="keyword">disable</span> user agent filtering </div><div class="line"> config_user_agent_check = <span class="string">"on"</span>  <span class="meta">#是否开启ua检测</span></div><div class="line"> --<span class="keyword">enable</span>/<span class="keyword">disable</span> cookie deny filtering </div><div class="line"> config_cookie_check = <span class="string">"on"</span>    <span class="meta">#是否开启cookie检测</span></div><div class="line"> --<span class="keyword">enable</span>/<span class="keyword">disable</span> cc filtering </div><div class="line"> config_cc_check = <span class="string">"on"</span>   <span class="meta">#是否开启防cc攻击</span></div><div class="line"> --cc rate the xxx of xxx seconds </div><div class="line"> config_cc_rate = <span class="string">"10/60"</span>   <span class="meta">#允许一个ip60秒内只能访问10此</span></div><div class="line"> --<span class="keyword">enable</span>/<span class="keyword">disable</span> post filtering </div><div class="line"> config_post_check = <span class="string">"on"</span>   <span class="meta">#是否开启post检测</span></div><div class="line"> --config waf <span class="keyword">output</span> redirect/html </div><div class="line"> config_waf_output = <span class="string">"html"</span>  <span class="meta">#action一个html页面，也可以选择跳转</span></div><div class="line"> --<span class="keyword">if</span> config_waf_output ,setting url </div><div class="line"> config_waf_redirect_url = <span class="string">"http://www.baidu.com"</span> </div><div class="line"> config_output_html=[[  <span class="meta">#下面是html的内容</span></div><div class="line"> &lt;html&gt; </div><div class="line"> &lt;head&gt; </div><div class="line"> &lt;meta http-equiv=<span class="string">"Content-Type"</span> content=<span class="string">"text/html; charset=utf-8"</span> /&gt; </div><div class="line"> &lt;meta http-equiv=<span class="string">"Content-Language"</span> content=<span class="string">"zh-cn"</span> /&gt; </div><div class="line"> &lt;<span class="built_in">title</span>&gt;网站防火墙&lt;/<span class="built_in">title</span>&gt; </div><div class="line"> &lt;/head&gt; </div><div class="line"> &lt;body&gt; </div><div class="line"> &lt;h1 align=<span class="string">"center"</span>&gt; <span class="meta"># 您的行为已违反本网站相关规定，注意操作规范. </span></div><div class="line"> &lt;/body&gt; </div><div class="line"> &lt;/html&gt; </div><div class="line"> ]]</div></pre></td></tr></table></figure>
<h2 id="学习access-lua的配置"><a href="#学习access-lua的配置" class="headerlink" title="学习access.lua的配置"></a>学习access.lua的配置</h2><figure class="highlight lua"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line">root@nginx waf]# pwd</div><div class="line">/usr/<span class="keyword">local</span>/openresty/nginx/conf/waf</div><div class="line">[root@nginx waf]# cat access.lua</div><div class="line"><span class="built_in">require</span> <span class="string">'init'</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">function</span> <span class="title">waf_main</span><span class="params">()</span></span></div><div class="line">    <span class="keyword">if</span> white_ip_check() <span class="keyword">then</span></div><div class="line">    <span class="keyword">elseif</span> black_ip_check() <span class="keyword">then</span></div><div class="line">    <span class="keyword">elseif</span> user_agent_attack_check() <span class="keyword">then</span></div><div class="line">    <span class="keyword">elseif</span> cc_attack_check() <span class="keyword">then</span></div><div class="line">    <span class="keyword">elseif</span> cookie_attack_check() <span class="keyword">then</span></div><div class="line">    <span class="keyword">elseif</span> white_url_check() <span class="keyword">then</span></div><div class="line">    <span class="keyword">elseif</span> url_attack_check() <span class="keyword">then</span></div><div class="line">    <span class="keyword">elseif</span> url_args_attack_check() <span class="keyword">then</span></div><div class="line">    <span class="comment">--elseif post_attack_check() then</span></div><div class="line">    <span class="keyword">else</span></div><div class="line">        <span class="keyword">return</span></div><div class="line">    <span class="keyword">end</span></div><div class="line"><span class="keyword">end</span></div><div class="line"></div><div class="line">waf_main()</div></pre></td></tr></table></figure>
<p>书写书序：先检查白名单，通过即不检测；<br>再检查黑名单，不通过即拒绝，检查UA，UA不通过即拒绝；<br>检查cookie；URL检查;URL参数检查，post检查.</p>
<h1 id="启动WAF并测试"><a href="#启动WAF并测试" class="headerlink" title="启动WAF并测试"></a>启动WAF并测试</h1><h2 id="模拟sql注入"><a href="#模拟sql注入" class="headerlink" title="模拟sql注入"></a>模拟sql注入</h2><p>显示效果如下：<br><img src="http://oovxjr0mr.bkt.clouddn.com/ab01_%E5%89%AF%E6%9C%AC.jpg" alt="ab_01"></p>
<p>##使用ab压测工具模拟防cc攻击<br>yum安装Apache</p>
<pre><code>[root@nginx ~]# yum -y install httpd
</code></pre><p><img src="http://oovxjr0mr.bkt.clouddn.com/ab04_%E5%89%AF%E6%9C%AC.jpg" alt="ab-04"><br><img src="http://oovxjr0mr.bkt.clouddn.com/ab02_%E5%89%AF%E6%9C%AC.jpg" alt="ab02"></p>
<h2 id="模拟ip黑名单"><a href="#模拟ip黑名单" class="headerlink" title="模拟ip黑名单"></a>模拟ip黑名单</h2><p>将请求ip放入ip黑名单中</p>
<pre><code>[root@nginx rule-config]# echo &quot;192.168.0.16&quot;  &gt;&gt;/usr/local/openresty/nginx/conf/waf/rule-config/blackip.rule
</code></pre><p>显示结果如下：<br><img src="http://oovxjr0mr.bkt.clouddn.com/ab_05_%E5%89%AF%E6%9C%AC.jpg" alt="ab05"></p>
<h2 id="模拟ip白名单"><a href="#模拟ip白名单" class="headerlink" title="模拟ip白名单"></a>模拟ip白名单</h2><p> 将请求ip放入ip白名单中，此时将不对此ip进行任何防护措施</p>
<pre><code>[root@nginx rule-config]# echo &quot;192.168.0.16&quot;  &gt;&gt;/usr/local/openresty/nginx/conf/waf/rule-config/whiteip.rule
</code></pre><p> 显示结果如下：<br><img src="http://oovxjr0mr.bkt.clouddn.com/ab06_%E5%89%AF%E6%9C%AC.jpg" alt="ab06"></p>
<h2 id="模拟URL参数检测"><a href="#模拟URL参数检测" class="headerlink" title="模拟URL参数检测"></a>模拟URL参数检测</h2><p>在浏览器输入：<a href="http://192.168.0.14/?a=select" target="_blank" rel="external">http://192.168.0.14/?a=select</a> * from table<br>显示结果如下：<br><img src="http://oovxjr0mr.bkt.clouddn.com/ab07_%E5%89%AF%E6%9C%AC.jpg" alt="ab07"><br>详细规定在arg.rule中有规定,对请求进行了规范</p>
<h1 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h1><p>WAF它的定位就决定了只能是一款辅助性安全防御产品，无法从根本上解决产品自身存在的安全缺陷。考虑到安全与效率，WAF也不可能去拦截所有的入侵尝试，毕竟绕过WAF的奇技淫巧还是非常之多的。<br>根本性的防御措施还是需要放在安全开发流程、安全规范的落地和推行上面。<br>在众多的安全防御产品中，有的产品和方案需要花很多钱，但是收益却并不怎么明显。而WAF，在综合考量下它性价比超高，虽然治标不治本，但对于提高攻击成本、降低入侵概率还是很有帮助的。</p>
]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;了解waf&quot;&gt;&lt;a href=&quot;#了解waf&quot; class=&quot;headerlink&quot; title=&quot;了解waf&quot;&gt;&lt;/a&gt;了解waf&lt;/h1&gt;&lt;h2 id=&quot;什么是WAF&quot;&gt;&lt;a href=&quot;#什么是WAF&quot; class=&quot;headerlink&quot; title=&quot;什
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Linux技术" scheme="http://yjscloud.com/tags/Linux%E6%8A%80%E6%9C%AF/"/>
    
  </entry>
  
  <entry>
    <title>Linux学习笔记（八）-防火墙</title>
    <link href="http://yjscloud.com/2017/05/08/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89-%E9%98%B2%E7%81%AB%E5%A2%99/"/>
    <id>http://yjscloud.com/2017/05/08/Linux学习笔记（八）-防火墙/</id>
    <published>2017-05-08T08:42:08.000Z</published>
    <updated>2017-12-02T09:49:26.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="防火墙原理"><a href="#防火墙原理" class="headerlink" title="防火墙原理"></a>防火墙原理</h1><p><img src="http://oxysobnip.bkt.clouddn.com/2.8.png" alt="2.8"></p>
<p>防火墙的主要作用：用来控制那些主机可以访问本地的那些服务</p>
<p>特别注意：</p>
<p>firewall-cmd和iptables是冲突的。</p>
<p>所以，如果使用firewall-cmd，应该把iptables和其他防火墙服务屏蔽。</p>
<pre><code># systemctl  mask   {iptables, ip6tables, ebtables}
</code></pre><h1 id="firewall-cmd的原理"><a href="#firewall-cmd的原理" class="headerlink" title="firewall-cmd的原理"></a>firewall-cmd的原理</h1><p><img src="http://oxysobnip.bkt.clouddn.com/2.9.png" alt="2.9"></p>
<p>预先定义了很多“区域”</p>
<p>每个区域，相当于一个“大门”。</p>
<p>每个网卡，都被绑定到某个区域（如果不绑定，就走默认区域）</p>
<p>区域内又定义了很多规则</p>
<p>数据包到达某个区域后，就匹配该区域的规则，以决定是否通过。</p>
<p>功能演示：主机A安装Apache服务，主机B来访问主机A的网站。默认是拒绝访问的（因为主机A的防火墙没有允许http服务）</p>
<p>预定义服务:系统把一些常用的网络访问，进行了定义。比如web访问，定义为http， 就是指在80端口使用http协议,比如ssh访问， 就是在22端口使用ssh协议,所以，可以直接对这些“服务”设置规则。</p>
<p>端口:对于不是预定义服务的访问，就可以使用端口设置规则。注意，设置端口时，必须同时设置所使用的协议（tcp或udp）,比如： # firewall-cmd  –add-port=8000/tcp     </p>
<h1 id="firewall-cmd的常用命令"><a href="#firewall-cmd的常用命令" class="headerlink" title="firewall-cmd的常用命令"></a>firewall-cmd的常用命令</h1><pre><code># firewall-cmd   --help
# firewall-cmd   --help  |  grep  zone
# firewall-cmd   --get-zones
# firewall-cmd  --get-default-zone
# firewall-cmd  --set-default-zone=home
</code></pre><p>查看指定区域（大门）的所有规则</p>
<pre><code># firewall-cmd   --list-all  --zone=区域名
</code></pre><p>查看默认区域（大门）的所有规则</p>
<pre><code># firewall-cmd   --list-all   
</code></pre><h2 id="防火墙-预定义服务"><a href="#防火墙-预定义服务" class="headerlink" title="防火墙-预定义服务"></a>防火墙-预定义服务</h2><p>在默认区域中，添加一个规则：允许http服务通过防火墙,没有指定区域，就表示是默认区域</p>
<pre><code># firewall-cmd  --add-service=http    
</code></pre><p>在指定的home区域添加一个规则：允许http服务通过防火墙</p>
<pre><code># firewall-cmd  --add-service=http  --zone=home
</code></pre><p>移除服务</p>
<pre><code># firewall-cmd  --remove-service=http
</code></pre><p>查询默认区域中是否允许http服务</p>
<pre><code># firewall-cmd  --query-service=http  
</code></pre><p>查询默认区域中是否允许http服务</p>
<pre><code># firewall-cmd  --query-service=http    --zone=home
</code></pre><h2 id="防火墙-端口"><a href="#防火墙-端口" class="headerlink" title="防火墙-端口"></a>防火墙-端口</h2><pre><code># firewall-cmd  --add-port=80/tcp   
# firewall-cmd  --remove-port=80/tcp
</code></pre><h2 id="防火墙-网络接口"><a href="#防火墙-网络接口" class="headerlink" title="防火墙-网络接口"></a>防火墙-网络接口</h2><p>查看指定的网络接口（网卡），所绑定到的区域</p>
<pre><code># firewall-cmd   --get-zone-of-interface=eno16777736
</code></pre><p>一个网络接口，只能绑定到一个区域。</p>
<p>多个网络接口，可以绑定到同一个区域。</p>
<pre><code># firewall-cmd  --change-interface=eno16777736  --zone=home
</code></pre><p>把网络接口eno16777736所绑定的区域，修改为home区域，该命令，用于已经被绑定到某区域的网路接口。</p>
<pre><code># firewall-cmd  --remove-interface=eno16777736  --zone=home
</code></pre><p>把网络接口eno16777736,从home区域解绑。解绑后，该网路接口，就没有绑定到任何区域（该接口的数据包就传输到默认接口）</p>
<pre><code># firewall-cmd  --add-interface=eno16777736  --zone=public
</code></pre><p>把网络接口eno16777736，绑定到public区域，该命令，用于还没有绑定到任何区域的接口。</p>
<p>注意：一个网卡，只能绑定到一个区域</p>
<p>   多个网卡，可以绑定到同一个区域。</p>
<h1 id="来源source"><a href="#来源source" class="headerlink" title="来源source"></a>来源source</h1><p>需求： server0安装了web服务器，除了desktop0以外，其他任意主机，都不能访问server0的web网站</p>
<p>实现：<br>在server0上实现：</p>
<pre><code>firewall-cmd  --remove-service=http
firewall-cmd  --add-service=http   --zone=home
firewall-cmd  --add-source=192.168.0.11   --zone=home
</code></pre><p>如果某个网络接口，被绑定到某区域,那么，来自该网络接口的所有数据包（无论什么主机），都会“流入”到该区域。如果该区域禁止某个服务（比如http）,但是，来自该接口的某个数据包，和其他区域的某个“source规则”匹配，那么该数据包就会流入该区域。</p>
<p>如果某个网络接口，没有被绑定到任何区域。那么，来自该网络接口的所有数据包（无论什么主机），都会“流入”到“默认区域”。但是，如果来自该接口的某个数据包，和某个区域的“source规则”匹配，那么该数据包就会流入该区域。</p>
<p>实例：</p>
<pre><code># firewall-cmd   --remove-source=192.168.168.1/24 
</code></pre><p>场景：</p>
<p>主机A：</p>
<p>1）安装了Apache服务（http服务）。</p>
<p>2）主机A的网卡被绑定到了public区域。</p>
<p>3) 主机A的public区域又禁止 http服务。</p>
<p>此时导致：</p>
<p>主机B，就不能访问主机A的网站。</p>
<p>但是，主机A的home区域添加一个source规则，以允许主机B(192.168.168.1)访问。同时home区域又允许http服务</p>
<pre><code># firewall-cmd   -add-source=192.168.168.1/24  
</code></pre><p>就会导致：</p>
<p>主机B，可以访问主机A的网站。（是“进入”了主机A的home区域）</p>
<p>其他命令:</p>
<pre><code># firewall-cmd    --remove-source=192.168.168.1/24    删除源
# firewall-cmd    --add-source=192.168.168.0/24    指定一个网络内的所有主机 
</code></pre><h1 id="ICMP规则"><a href="#ICMP规则" class="headerlink" title="ICMP规则"></a>ICMP规则</h1><p>ICMP是一种协议。ping命令发送的数据包，就是使用ICMP协议的。</p>
<p>测试ping的效果</p>
<p>主机A , ping 主机B(192.168.168.1)</p>
<p>在主机A中：    # ping   192.168.168.1</p>
<p>在主机B中抓包：# tcpdump  -i  eno1677728    not  port  22</p>
<p>  捕获指定网卡的包，除了22端口的数据包以外。</p>
<p>  wireshark</p>
<p>就会发现有很多  ICMP  echo  request包 (ping的请求包)</p>
<p>  ICMP  echo  reply包   (ping的响应包）</p>
<p>主机B禁止ping</p>
<pre><code># firewall-cmd   --add-icmp-block=echo-request  
# firewall-cmd   --add-icmp-block=echo-reply
</code></pre><p>主机B禁止icmp请求包或响应包。其他主机都ping不通主机A</p>
<h1 id="伪装"><a href="#伪装" class="headerlink" title="伪装"></a>伪装</h1><p>问题：</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/2.10.png" alt="2.10"></p>
<p>A -&gt; C</p>
<p>[ source ip    destination ip  …. ]</p>
<p>改为：</p>
<p>[ public  network ip    destination ip  …. ]</p>
<p>主机A能ping通主机B,主机A不能ping通主机Ｃ</p>
<p>导致：A不能访问“外网”中的主机。C也不能访问“内网”的主机。</p>
<p>解决方案</p>
<p>方案1:在主机B中开启“转发”功能：</p>
<pre><code># echo 1 &gt;  /proc/sys/net/ipv4/ip_forword
</code></pre><p>如果把主机c的网关设置为路由器的外网端口，就可以使主机C也能ping通主机A</p>
<p>该方案的弊端：该方案在内网中有效。因为私网的数据包，是不能转发到公网的。即公网中的路由器收到私网数据包时，直接丢弃。</p>
<p>补充：</p>
<p>IP: A类，B类，C类</p>
<p>每类IP地址，都划分了一部分私有IP，</p>
<p>A类IP的私有地址：10.0.0.0/8</p>
<p>B类IP的私有地址：172.16.0.0/16</p>
<p>C类IP的私有地址：192.168.0.0/24</p>
<p>方案2：</p>
<p>在主机B（路由器）中，开启“伪装功能”。</p>
<pre><code># firewall-cmd   --add-masquerade
</code></pre><p>效果：外网的主机C 收到的ping请求包中，源地址是内网路由器的公网IP, 而不是真正的内网主机IP。</p>
<h1 id="端口转发"><a href="#端口转发" class="headerlink" title="端口转发"></a>端口转发</h1><h2 id="本地转发"><a href="#本地转发" class="headerlink" title="本地转发"></a>本地转发</h2><p>实例：</p>
<p>主机A：安装http服务，使用80端口。192.168.168.2</p>
<p>主机B：用22来访问主机A的网站。  192.168.168.2:22</p>
<p>实现：</p>
<p>在主机A中做“端口转发”</p>
<pre><code># firewall-cmd  --add-forward-port=port=22:proto=tcp:toport=80:toaddr=
</code></pre><p>把来自22端口的tcp数据包，转发给本地的80端口。</p>
<h2 id="远程转发"><a href="#远程转发" class="headerlink" title="远程转发"></a>远程转发</h2><p>实例：</p>
<p>有主机A(192.168.168.2), 主机B(192.168.168.1), 主机C(192.168.30.30)</p>
<p>任意主机，使用ssh登录到B, 实际却登录主机C</p>
<pre><code>root@A#  ssh  192.168.16 
root@C#
</code></pre><p>实现：</p>
<pre><code>root@B# firewall-cmd  --add-forward-port=port=22:proto=tcp:toport=22:toaddr=192.168.30.30
</code></pre><p>注意：</p>
<p>使用远程端口转发时，需要开启防火墙的伪装功能，否则无效！</p>
<h1 id="富规则"><a href="#富规则" class="headerlink" title="富规则"></a>富规则</h1><h2 id="服务富规则"><a href="#服务富规则" class="headerlink" title="服务富规则"></a>服务富规则</h2><p>问题：在某个区域中，添加一个服务或端口等规则时，就会导致：来自对应接口的“所有远程主机”都使用这个规则.</p>
<p>解决方案：使用富规则。</p>
<p>实例：主机B上安装了http服务，不允许主机C访问主机Ｂ的网站。</p>
<p>实现1：</p>
<pre><code>root@B#  firewall-cmd  --add-service=http
root@B#  firewall-cmd  --add-rich-rule  &apos;rule 
family=&quot;ipv4&quot; 
source address=&quot;192.168.30.30&quot; 
service name=&quot;http&quot; 
reject&apos;
</code></pre><p>注意：不能把source address=”192.168.30.30” 写成  source address=”192.168.30.30/24”,</p>
<p>否则等同于source address=”192.168.0/24”</p>
<p>实例2：主机B上安装了http服务，仅允许主机C访问主机Ｂ的网站。</p>
<p>实现：</p>
<pre><code>root@B#  firewall-cmd  --remove-service=http
root@B#  firewall-cmd  --add-rich-rule &apos;rule
family=ipv4
service name=http
source address=192.168.30.30
accept&apos;
</code></pre><h2 id="端口富规则"><a href="#端口富规则" class="headerlink" title="端口富规则"></a>端口富规则</h2><p>服务富规则的缺点：只能处理预定义服务！</p>
<p>比如 http服务(就是tcp/80)</p>
<p>当需要处理其他的非预定服务，比如 tcp/8000，就不能使用服务富规则！</p>
<p>实例：主机B上安装了http服务，不允许主机C访问主机Ｂ的网站。</p>
<p>实现1：</p>
<pre><code>root@B#  firewall-cmd  --add-service=http
root@B#  firewall-cmd  --add-rich-rule  &apos;rule 
family=&quot;ipv4&quot; 
source address=&quot;192.168.30.30&quot; 
port  port=80  protocol=tcp   
reject&apos;
</code></pre><h2 id="端口转发富规则"><a href="#端口转发富规则" class="headerlink" title="端口转发富规则"></a>端口转发富规则</h2><p>实例：仅主机A，使用ssh登录到B, 实际却登录主机C</p>
<p>实现：</p>
<pre><code>root@B firewall-cmd  --add-rich-rule &apos;rule
family=ipv4
source address=192.168.168.2
forward-port  port=22  protocol=tcp  to-port=22  to-addr=192.168.30.30
accept&apos;
</code></pre><h2 id="伪装富规则"><a href="#伪装富规则" class="headerlink" title="伪装富规则"></a>伪装富规则</h2><p>实例：本地局域网内仅主机A可以访问外网的主机C</p>
<p>实现：</p>
<pre><code>root@B firewall-cmd  --add-rich-rule &apos;rule
family=ipv4
source address=192.168.168.2
masquerade&apos;
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;防火墙原理&quot;&gt;&lt;a href=&quot;#防火墙原理&quot; class=&quot;headerlink&quot; title=&quot;防火墙原理&quot;&gt;&lt;/a&gt;防火墙原理&lt;/h1&gt;&lt;p&gt;&lt;img src=&quot;http://oxysobnip.bkt.clouddn.com/2.8.png&quot; alt=&quot;2
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Linux学习笔记" scheme="http://yjscloud.com/tags/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Linux学习笔记（七）-守护进程</title>
    <link href="http://yjscloud.com/2017/05/07/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89-%E5%AE%88%E6%8A%A4%E8%BF%9B%E7%A8%8B/"/>
    <id>http://yjscloud.com/2017/05/07/Linux学习笔记（七）-守护进程/</id>
    <published>2017-05-07T08:14:16.000Z</published>
    <updated>2017-12-02T08:38:52.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="systemd简介"><a href="#systemd简介" class="headerlink" title="systemd简介"></a>systemd简介</h1><p>在RHEL6中，系统的第一个进程(PID=1) 是init进程</p>
<p>在RHEL7中，系统的第一个进程是systemd, 是一个特殊的守护进程。</p>
<p>systemd比原来的init进程更强大：</p>
<p>1）并行化功能，提供系统的启动速度</p>
<p>2）能够按需要来启动守护进程</p>
<p>3）自动服务依赖管理，例如可在网路不可用时，不启动网路服务</p>
<h1 id="systemd的单元类型"><a href="#systemd的单元类型" class="headerlink" title="systemd的单元类型"></a>systemd的单元类型</h1><p>systemd是第一个进程，可处理多个system单元。</p>
<p>可以理解为：systemd包含多个“组件”，每个组件，就是一个“单元”。</p>
<p>在shell中，使用systemctl命令来管理system单元。</p>
<p>system单元，分多种类型：</p>
<pre><code># systemctl  -t  help
</code></pre><p>查看所有可用的systemd单元的类型。</p>
<p>常用的systemd单元类型：</p>
<p>1）服务单元  </p>
<p>   扩展名为 .service</p>
<p>   服务单元，用来启动对应的“守护进程”。</p>
<p>2）套接字单元</p>
<p>   扩展名为.socket</p>
<p>   表示进程间通信的套接字，可用于延时启动的服务、按需启动的服务。</p>
<p>3）目标单元</p>
<p>   扩展名为.target</p>
<p>   target单元，相当于RHEL6中的运行级别。</p>
<p>   启动开机时，必须选择一种targe单元进行启动</p>
<h1 id="管理目标单元"><a href="#管理目标单元" class="headerlink" title="管理目标单元"></a>管理目标单元</h1><h2 id="常用的目标单元"><a href="#常用的目标单元" class="headerlink" title="常用的目标单元"></a>常用的目标单元</h2><p>graphical.target：支持多用户，支持图像登陆和文本登陆。</p>
<p>multi-user.target：支持多用户，支持文本登陆</p>
<p>rescue.target：完成基本系统的初始化，rescue模式（救援模式）</p>
<p>emergency.target：系统根文件系统以只读形式挂载在/目录，emergency模式（紧急模式）</p>
<p>target单元相当于RHEL6中的运行级别。</p>
<p>即：每个target单元（运行级别），是一种模式。</p>
<p>在各个模式下，分别了不同的多个服务。</p>
<p>例如：graphical.target支持图形化界面</p>
<p>类比：马云这辈子，大脑开启了商业服务，下辈子投胎后，还是一样的大脑，但是大脑就可能就开启了表演服务，成为演员。</p>
<h2 id="使用systemctl管理目标单元"><a href="#使用systemctl管理目标单元" class="headerlink" title="使用systemctl管理目标单元"></a>使用systemctl管理目标单元</h2><p>（1）手动切换tareget目标</p>
<pre><code># systemctl  isolate  multi-user.target
</code></pre><p> 马上生效</p>
<p>(2)获取默认target目标</p>
<pre><code># systemctl  get-default 
</code></pre><p> 系统重启才生效</p>
<p>(3)设置默认target目标</p>
<pre><code># systemctl  set-default  multi-user.target
</code></pre><p>(4)开机时设置target目标。<br>   仅该次有效,重启系统，然后编辑启动项，在启动命名行中指定启动目标</p>
<p>  即： 重启系统。</p>
<p>  按任意键中断倒计时，选择启动项，按e</p>
<p>  在linux16开头的行的末尾，添加：systemd.unit=recure.target</p>
<p>  按ctrl+x使用修改，并启动系统。</p>
<h1 id="管理service单元"><a href="#管理service单元" class="headerlink" title="管理service单元"></a>管理service单元</h1><p>service单元，对应一个特定的服务。<br>一个服务，就是一个后台进程。</p>
<p>使用systemctl管理service单元：</p>
<p>(1)查询所有单元的状态</p>
<pre><code># systemctl  
</code></pre><p>(2)查询指定单元的状态</p>
<pre><code># systemctl  status  graphical.target
# systemctl  status  rsyslog.service
</code></pre><p>(3)查询所有服务单元的状态</p>
<pre><code># systemctl  --type=service
</code></pre><p>(4)查询处于失败或维护状态的所有单元</p>
<pre><code># systemctl  status  rngd.service  -l
</code></pre><p>  注： -l 可以显示完整的输出。</p>
<p>(5)查询指定的单元当前是否处于活动状态</p>
<pre><code>#  systemctl  is-active  sshd
</code></pre><p>因为sshd只有service类型的单元，没有同名的其他类型单元，可以省略 .service</p>
<p>(6)查询指定的单元是否开机自动启动</p>
<pre><code># systemctl  is-enabled  sshd
</code></pre><p>(7)查询已加载单元的状态</p>
<pre><code>#  systemctl  list-units
</code></pre><p> 列出所有已加载单元的状态。</p>
<pre><code>#  systemctl  list-units  --type=service
</code></pre><p>列出所有已加载服务单元的状态。</p>
<pre><code>#  systemctl  list-unit-files 
</code></pre><p> 列出所有单元的启用、禁用（开机不自动启动）状态。</p>
<pre><code>#  systemctl  list-unit-files  --type=service
</code></pre><p>  列出所有服务单元的启用、禁用（开机不自动启动）状态。</p>
<p>(8)查看所有失败的服务</p>
<pre><code>#  systemctl  --failed  --type=service
</code></pre><p>(9)控制服务单元</p>
<pre><code># systemctl  status  sshd.service 
# systemctl  stop   sshd.service
# systemctl  start   sshd.service
# systemctl   restart  sshd.service
# systemctl   enable  sshd.service
# systemctl   is-enabled  sshd.service
# systemctl   is-active  sshd.service
</code></pre><p>(10)重新加载服务的配置文件（不会停止和启动服务）</p>
<pre><code># systemctl  reload   sshd.service
</code></pre><p>(11)屏蔽服务</p>
<p>有些服务之间是有冲突的，比如iptables和firewalld，此时就需要把某个服务屏蔽。</p>
<p>服务屏蔽后，该服务就不会被启动！</p>
<p>屏蔽后，不能开机启动该服务，也不能手动启动该服务！</p>
<pre><code># systemctl   mask  iptables
</code></pre><p>取消屏蔽服务</p>
<pre><code># systemctl  unmask  iptables
</code></pre><p>(12)单元依赖</p>
<p>某些服务单元，需要依赖其他服务单元，才能启动。</p>
<p>列出指定单元所依赖的单元。</p>
<pre><code># systemctl  list-dependencies  sshd
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;systemd简介&quot;&gt;&lt;a href=&quot;#systemd简介&quot; class=&quot;headerlink&quot; title=&quot;systemd简介&quot;&gt;&lt;/a&gt;systemd简介&lt;/h1&gt;&lt;p&gt;在RHEL6中，系统的第一个进程(PID=1) 是init进程&lt;/p&gt;
&lt;p&gt;在RH
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Linux学习笔记" scheme="http://yjscloud.com/tags/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Linux学习笔记（六）-SELinux</title>
    <link href="http://yjscloud.com/2017/05/06/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89-SELinux/"/>
    <id>http://yjscloud.com/2017/05/06/Linux学习笔记（六）-SELinux/</id>
    <published>2017-05-06T09:46:38.000Z</published>
    <updated>2017-12-02T08:08:57.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="为什么要使用SELinux"><a href="#为什么要使用SELinux" class="headerlink" title="为什么要使用SELinux"></a>为什么要使用SELinux</h1><p>问题：</p>
<p>在生产环境中，某些管理员，为了简单，或者是因为无知，常常把一些目录或文件的权限，设置为777, 会导致一些非预期的后果（用户可以执行原本不应该执行的代码、误删重要资料）</p>
<p>目前的安全机制：</p>
<p>是基于用户的UID,GID的rwx权限设置。</p>
<p>即进程的UID和GID, 和程序的UID与GID进行匹配。</p>
<p>进程的UID和GID就是启动这个进程的用户的UID和GID。</p>
<p>最终导致黑客或者管理本身，可能对系统的资源进行窃取或者误操作。</p>
<p>解决方案：使用SELinux</p>
<h1 id="SELinux是什么"><a href="#SELinux是什么" class="headerlink" title="SELinux是什么"></a>SELinux是什么</h1><p>SELinux是美国国家安全局和Linux社区，一起研发的。</p>
<p>是一种安全机制。</p>
<p>成为“强制访问控制”（MAC）</p>
<h1 id="SELinux的原理"><a href="#SELinux的原理" class="headerlink" title="SELinux的原理"></a>SELinux的原理</h1><p><img src="http://oxysobnip.bkt.clouddn.com/2.4.png" alt="2.4"></p>
<h1 id="SELinux的模式"><a href="#SELinux的模式" class="headerlink" title="SELinux的模式"></a>SELinux的模式</h1><h2 id="SELinux的工作模式"><a href="#SELinux的工作模式" class="headerlink" title="SELinux的工作模式"></a>SELinux的工作模式</h2><p>1）强制模式</p>
<p>   使用SELinux的强制访问控制。</p>
<p>2）permissive模式</p>
<p>   访问违背SELinux规则的，就记录告警，但是不阻止访问。</p>
<p>3）disabled模式</p>
<p>   不记录，不阻止。</p>
<h2 id="查看当前的模式"><a href="#查看当前的模式" class="headerlink" title="查看当前的模式"></a>查看当前的模式</h2><pre><code># getenforce
</code></pre><p>输出为：</p>
<p>Enforcing  (强制模式)</p>
<p>Permissive  （Permissive模式）</p>
<p>Disabled    (Disabled模式)</p>
<h2 id="改变SELinux的模式"><a href="#改变SELinux的模式" class="headerlink" title="改变SELinux的模式"></a>改变SELinux的模式</h2><p><img src="http://oxysobnip.bkt.clouddn.com/2.5.png" alt="2.5"></p>
<p>SELiniux的配置文件</p>
<pre><code>/etc/selinux/config
</code></pre><pre><code>SELINUX=enforcing      #还可以取 permissive,  enabled 
SELINUXTYPE=targeted  #SELinux的策略，为“目标”策略
</code></pre><p>SELINUXTYPE是指SELinux的策略，默认为目标策略targeted, 不要修改<br>并启动系统。</p>
<h1 id="查看SELinux"><a href="#查看SELinux" class="headerlink" title="查看SELinux"></a>查看SELinux</h1><h2 id="查看文件的SELinux"><a href="#查看文件的SELinux" class="headerlink" title="查看文件的SELinux"></a>查看文件的SELinux</h2><p>ls –l 命令的第一列：</p>
<pre><code>-rw-r--r--.   
</code></pre><p>如果文件权限的最后一位是小数点，就表示该文件使用了SELinux<br>如果是+,表示使用了ACL.</p>
<p>在ls命令中使用Z选项</p>
<pre><code>#  ls  -Z  file.txt
unconfined_u:object_r:admin_home_t:s0
</code></pre><p>对于targeted策略，值需要关注第3列值（以冒号分割）该列，称为“SELinux上下文”，就是一个“标签”,SELinux机制中，已经定义好很多SELinux上下文。</p>
<h2 id="查看进程的SELinux"><a href="#查看进程的SELinux" class="headerlink" title="查看进程的SELinux"></a>查看进程的SELinux</h2><p>查看httpd进程的SELinux</p>
<pre><code># ps  auxZ  |  grep  httpd
或
# ps  -efZ  |  grep  httpd
</code></pre><p>Z选项，就是显示进程的SELinux上下文</p>
<p><img src="http://oxysobnip.bkt.clouddn.com/2.5-1.png" alt="2.5-1"></p>
<h1 id="SELinux保护示例"><a href="#SELinux保护示例" class="headerlink" title="SELinux保护示例"></a>SELinux保护示例</h1><p>（1）在Server0主机上安装apache</p>
<pre><code># yum  install  -y  httpd
# systemctl  enable httpd
# systemctl  start  httpd
# firewall-cmd  --add-service=httpd
</code></pre><p>（2)在Desktop0主机访问服务器的网站</p>
<pre><code># curl  192.168.0.11
</code></pre><p>  就能访问服务器网站的首页(/var/www/html/index.html)</p>
<p>（3）在服务器端编辑一个新的页面secure.html</p>
<pre><code># cd 
# echo  “This is a secure page”  &gt;  secure.html
# mv   secure.html   /var/www/html/
</code></pre><p>（4）在客户端Desktop0上访问</p>
<pre><code># curl   192.168.0.11/secure.html
</code></pre><p>   发现没有权限访问secure.html</p>
<p>   因为：secure.html的SELinux上下文和httpd进程的SELinux上文不一致！</p>
<p>  httpd的SELinux上下文是：httpd_sys_content_t</p>
<p>  secure.html的SELinux上下文是：admin_home_t</p>
<h1 id="修改SELinux上下文"><a href="#修改SELinux上下文" class="headerlink" title="修改SELinux上下文"></a>修改SELinux上下文</h1><p>(1)改变文件的SELinux上下文</p>
<pre><code># chcon  -t   httpd_sys_content_t   secure.html
</code></pre><p>把secure.html文件的SELinux上下文，设置为 httpd_sys_content_t</p>
<p>(2)改变目录以及目录内的所有文件的SELinux上下文</p>
<pre><code>#chcon  -R  -t  httpd_sys_content_t  secure.html
</code></pre><p>(3)根据指定的文件来修改文件的SELinux上下文</p>
<p>相当于复制SELinux上下文。</p>
<pre><code># chcon   --reference=index.html    secure.html
</code></pre><p>把文件secure.html的SELinux上下文和index.html的相同</p>
<p>(4)根据指定的目录来修改目录的SELinux上下文</p>
<p>相当于复制SELinux上下文。</p>
<pre><code># chcon   -R  --reference=/var/www/html    /var/www/html/work
</code></pre><p>把/var/www/html/work目录的SELinux上下文设置成和/var/www/html的相同    </p>
<h1 id="默认SELinux上下文"><a href="#默认SELinux上下文" class="headerlink" title="默认SELinux上下文"></a>默认SELinux上下文</h1><h2 id="设置默认SELinux上下文"><a href="#设置默认SELinux上下文" class="headerlink" title="设置默认SELinux上下文"></a>设置默认SELinux上下文</h2><p>1）设置文件的默认SELinux上下文</p>
<pre><code># semanage   fcontext   -a   -t   httpd_sys_content_t  ‘/root/file.txt’
</code></pre><p>  （1）一定要使用单引号’’</p>
<p>  （2）单引号里面，必须写绝对路径。</p>
<p>2）设置目录的默认SELinux上下文</p>
<pre><code># semanage   fcontext   -a   -t   httpd_sys_content_t  ‘/root/work(/.*)?’
</code></pre><p>把/root/work目录以及该目录下的所有文件的默认SELinux上下文都修改为httpd_sys_content_t</p>
<p>说明：（/.*）? 表示匹配任意长度的字符串，可以用来处理目录。</p>
<p>改变默认SELinux上下文后，并不会改变当前的SELinux上下文。</p>
<h2 id="恢复默认SELinux上下文"><a href="#恢复默认SELinux上下文" class="headerlink" title="恢复默认SELinux上下文"></a>恢复默认SELinux上下文</h2><p>1)恢复目录以及目录内所有文件的默认SELinux上下文</p>
<pre><code># restorecon   -R   /root/work
</code></pre><p>2）恢复文件的默认SELinux上下文</p>
<pre><code># restorecon  /root/file.txt
</code></pre><h1 id="SELinux布尔值"><a href="#SELinux布尔值" class="headerlink" title="SELinux布尔值"></a>SELinux布尔值</h1><h2 id="SELinux布尔值的作用"><a href="#SELinux布尔值的作用" class="headerlink" title="SELinux布尔值的作用"></a>SELinux布尔值的作用</h2><p><img src="http://oxysobnip.bkt.clouddn.com/2.7.png" alt="2.7"></p>
<p>系统定义了很多不同类型的SELinux布尔值。</p>
<p>只有对应的SELinux布尔值为真，而且SELinux上下文匹配时，才能访问对应的文件。</p>
<h2 id="查看SELinux布尔值"><a href="#查看SELinux布尔值" class="headerlink" title="查看SELinux布尔值"></a>查看SELinux布尔值</h2><p>查看系统的所有SELinux布尔值</p>
<pre><code># getsebool   -a 
</code></pre><p>查看指定的SELinux布尔值</p>
<pre><code># getsebool   ftpd_anon_write
</code></pre><p>查询httpd相关的SELinux布尔值</p>
<pre><code># getsebool  -a  |  grep  httpd
</code></pre><h2 id="设置SELinux布尔值"><a href="#设置SELinux布尔值" class="headerlink" title="设置SELinux布尔值"></a>设置SELinux布尔值</h2><p>临时设置，重启无效</p>
<pre><code># setsebool   ftpd_anon_write   on   
# setsebool   ftpd_anon_write   off
</code></pre><p>永久有效</p>
<pre><code># setsebool   -P  ftpd_anon_write   on   
# setsebool   -P  ftpd_anon_write   off
</code></pre><h1 id="SELinux端口标记"><a href="#SELinux端口标记" class="headerlink" title="SELinux端口标记"></a>SELinux端口标记</h1><p>问题：在主机B中，安装httpd服务。同时监听80端口和8889端口。（在Apache的主配置文件中添加 Listen 8888即可）</p>
<p>导致：启动httpd失败！</p>
<p>原因：SELinux强制模式下，进程访问某个端口时，需要他们的SELinux上下文匹配！<br>而8889端口的SELinux上下文和httpd进程的SELinux上下文不匹配。</p>
<p>解决：</p>
<pre><code># semanage   port   -a   -t   http_port_t   -p  tcp    8889
</code></pre><p>表示，把本机的8889端口添加一个SELinux上下文：http_port_t</p>
<p>其他命令：</p>
<pre><code># semanage   port   -d   -t   http_port_t   -p  tcp    8889
</code></pre><p>把本机的8889端口删除一个SELinux上下文：http_port_t</p>
<pre><code># semanage   port   -m   -t   http_port_t   -p  tcp    8889 
</code></pre><p>把本机的8889端口的上下文修改为http_port_t</p>
<p>查看端口的SELinux上下文：</p>
<pre><code># semanage  port  -l
# semanage  port  -l  |  grep  80
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;为什么要使用SELinux&quot;&gt;&lt;a href=&quot;#为什么要使用SELinux&quot; class=&quot;headerlink&quot; title=&quot;为什么要使用SELinux&quot;&gt;&lt;/a&gt;为什么要使用SELinux&lt;/h1&gt;&lt;p&gt;问题：&lt;/p&gt;
&lt;p&gt;在生产环境中，某些管理员，为了
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Linux学习笔记" scheme="http://yjscloud.com/tags/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Linux学习笔记（五）-vim入门教程</title>
    <link href="http://yjscloud.com/2017/05/05/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89-vim%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B/"/>
    <id>http://yjscloud.com/2017/05/05/Linux学习笔记（五）-vim入门教程/</id>
    <published>2017-05-05T13:09:05.000Z</published>
    <updated>2017-12-02T09:44:20.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Vim（Vi[Improved]）编辑器是功能强大的跨平台文本文件编辑工具，继承自Unix系统的Vi编辑器，支持Linux/Mac OS X/Windows系统，利用它可以建立、修改文本文件。进入Vim编辑程序，可以在终端输入下面的命令：</p>
<figure class="highlight gams"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta"><span class="meta-keyword">$vim</span> [filename]</span></div></pre></td></tr></table></figure>
<p>其中filename是要编辑器的文件的路径名。如果文件不存在，它将为你建立一个新文件。</p>
<h2 id="Vim使用"><a href="#Vim使用" class="headerlink" title="Vim使用"></a>Vim使用</h2><h3 id="vim-模式化编辑器"><a href="#vim-模式化编辑器" class="headerlink" title="vim:模式化编辑器"></a>vim:模式化编辑器</h3><pre><code>基本模式：编辑模式,命令模式,输入模式,末行模式(内置的命令行模式)
     打开文件：
             # vim [OPTION]...FILE...
             +#:打开文件后，直接让处于第#行的行首

     模式转换：
         ESC键：
    编辑模式--&gt;输入模式：
            i: 在光标所在处的前方转换为输入模式
            a: 在光标所在的后方转换为输入模式
            o: 在光标所在行的下方新建一个空行并转换为输入模式
            I: 跳转至行首 
            A：跳转至行尾
            O: 光标所在行的上方新建一个空白行

     输入模式--&gt;编辑模式
            ESC
    编辑模式--&gt;末行模式
            :
    末行模式--&gt;编辑模式
            ESC
</code></pre><h3 id="关闭文件："><a href="#关闭文件：" class="headerlink" title="关闭文件："></a>关闭文件：</h3><pre><code> :q：退出
 :q! 强制退出，丢弃做出的修改
:wq 保存退出
:x 保存退出
:wq! 强制保存退出
:w :/PATH/TO/SOMEWHERE
ZZ:保存退出
</code></pre><h3 id="光标移动："><a href="#光标移动：" class="headerlink" title="光标移动："></a>光标移动：</h3><h4 id="字符间移动：h-j-k-l"><a href="#字符间移动：h-j-k-l" class="headerlink" title="字符间移动：h,j,k,l"></a>字符间移动：h,j,k,l</h4><pre><code>h:左

l:右

j:下

k：上

#{h|j|k|l}: 跳#个字符
</code></pre><h4 id="单词间移动"><a href="#单词间移动" class="headerlink" title="单词间移动"></a>单词间移动</h4><pre><code>w: 下一个单词词首

e: 当前单词或下一个单词词尾

b: 当前单词或前一个单词词首

 #{w|e|b}:跳#个单词
</code></pre><h4 id="行内移动"><a href="#行内移动" class="headerlink" title="行内移动"></a>行内移动</h4><pre><code>^: 跳转至行首第一个非空白字符

0：跳转至绝对行首

$: 跳转至绝对行尾
</code></pre><h4 id="行间移动："><a href="#行间移动：" class="headerlink" title="行间移动："></a>行间移动：</h4><pre><code>#G: 直接跳转至第#行；

G：最后一行

1g,gg:回至第一行

 句子间移动：
    ) 
    (

段落间移动：
    }
    {
</code></pre><h3 id="vim编辑命令"><a href="#vim编辑命令" class="headerlink" title="vim编辑命令"></a>vim编辑命令</h3><h4 id="字符编辑："><a href="#字符编辑：" class="headerlink" title="字符编辑："></a>字符编辑：</h4><pre><code>x: 删除光标所在处的字符

 #x:删除光标起始的#字符
</code></pre><h4 id="替换命令"><a href="#替换命令" class="headerlink" title="替换命令"></a>替换命令</h4><pre><code>r:替换光标所在处的字符
</code></pre><h4 id="删除命令"><a href="#删除命令" class="headerlink" title="删除命令"></a>删除命令</h4><pre><code> d:结合光标跳转字符使用，删除跳转范围内的字符
d$:删除光标所在行
d^:删除空格
dw:删除一个字符
de:向后删除一个单词    
db:向前删除一个单词
dd: 删除光标所在行
#dd:多行删除
</code></pre><h4 id="粘贴命令"><a href="#粘贴命令" class="headerlink" title="粘贴命令"></a>粘贴命令</h4><pre><code>p:缓冲区存的如果为整行，则粘贴当前光标所在行的下方；否则，则粘贴至当前光标所在的后面；
P:缓冲区存的如果为整行，则粘贴当前光标所在行的上方；否则，则粘贴至当前光标所在的前面；
</code></pre><h4 id="复制命令"><a href="#复制命令" class="headerlink" title="复制命令"></a>复制命令</h4><pre><code>y:复制，工作行为与d相似
yy:复制行
#yy:复制多行
</code></pre><h4 id="改变命令"><a href="#改变命令" class="headerlink" title="改变命令"></a>改变命令</h4><pre><code>c：修改，工作行为与d相似
     编辑模式--&gt;末行模式
cc:删除并输入新内容
 #cc:
</code></pre><h4 id="可视化模式"><a href="#可视化模式" class="headerlink" title="可视化模式"></a>可视化模式</h4><pre><code>v:按字符选定
V:按行选定
</code></pre><h4 id="撤销操作"><a href="#撤销操作" class="headerlink" title="撤销操作"></a>撤销操作</h4><pre><code>u(undo):撤销此前的操作    
#u:撤销指定撤销次数                
撤销此前的撤销：
    ctrl+r                     
重复前一个编辑操作：.
</code></pre><h4 id="翻屏操作"><a href="#翻屏操作" class="headerlink" title="翻屏操作"></a>翻屏操作</h4><pre><code> Ctrl+f: 向文件尾部翻一屏
Ctrl+b: 向文件首部翻一屏
Ctrl+d: 向文件尾部翻半屏
Ctrl+u: 向文件首部翻半屏
</code></pre><h3 id="vim中的末行模式"><a href="#vim中的末行模式" class="headerlink" title="vim中的末行模式"></a>vim中的末行模式</h3><p>地址定界</p>
<pre><code>：start_pos,end_pos
   #:具体第#行，例如2表示第2行
    #，#：从左侧#表示行起始，到右侧#表示行结尾
    #，+#：从左侧#表示的行起始，加上右侧#表示的行数
    .：当前行
    $:最后一行
    %：全文，相当于1，$

    /pat1/,/pat2/:
    从第一次被pat1模式匹配到的行开始，一直到第一次被pat2匹配到的行结束

    使用方式：
        后面跟一个编辑模式
            d
            y
            w /PATH/TO/SOMEWHERE:将范围内的行另存至指定文件中
            r /PATH/FROM/SOMEFILE:在指定位置插入指定文件中的所有内容
</code></pre><h3 id="查找"><a href="#查找" class="headerlink" title="查找"></a>查找</h3><pre><code> /PATTERN:从当前光标所在处向文件尾部查找
?PATTERN：从当前光标所在处向文件首部查找                     
n:与命令同方向
N：与命令反方向
</code></pre><p>###查找并替换</p>
<pre><code>s:在末行模式下完整查找替换操作
s/要查找的内容/替换为的内容/修饰符
        要查找的内容：可使用模式
        替换为的内容：不能使用模式，但可以使用\1,\2...等后向引用符号；还可以使用“&amp;”引用前面查找到的整个内容
修饰符：
    i：忽略大小写
    g:全局替换；默认情况下，每一行只替换第一次出现
</code></pre><h3 id="练习："><a href="#练习：" class="headerlink" title="练习："></a>练习：</h3><pre><code>1、复制/etc/grub2.cfg至/tmp/目录，用查找替换命令删除/tmp/grub.cfg文件中的行首的空白字符
        %s/^[[:space:]]\+//g

2、复制/etc/rc.d/init.d/functions文件至/tmp目录，用查的替换命令为/tmp/functions的每行开头为空白字符的行行首添加一个#号；
         %s/^[[:space:]]/#&amp;/
</code></pre><h3 id="多文件模式："><a href="#多文件模式：" class="headerlink" title="多文件模式："></a>多文件模式：</h3><pre><code>vim FILE1 FILE2 FILE3....
     :next 下一个
    :prev 前一个
    :last 最后一个
    :first 第一个
    :wall 保存退出
    :qall 退出所有
</code></pre><h3 id="多窗口模式"><a href="#多窗口模式" class="headerlink" title="多窗口模式"></a>多窗口模式</h3><pre><code>多文件：
    vim 
        -o: 水平分割
        -O: 垂直分割

        Ctrl+w, Arrow
单文件：
        Ctrl+w, s: 水平分割
        Ctrl+w, v: 垂直分割
</code></pre><h3 id="定制vim的工作特性"><a href="#定制vim的工作特性" class="headerlink" title="定制vim的工作特性"></a>定制vim的工作特性</h3><pre><code>配置文件：永久有效

全局：/etc/vimrc

个人：~/.vimrc

 末行：当前vim进程有效

(1）行号
显示：set number,简写为set nu
取消显示：set nonumber ,简写set nonu

(2)括号匹配
 匹配：set showmatch 简写 set sm
 取消：set nosm

(3)自动缩进
 启用：set ai
禁用：set noai

(4)高亮搜索
启用：set hlsearch
 禁用：set nohlsearch

(5)语法高亮
启用：syntax on
禁用：syntax off

(6)忽略字符大小写
启用：set ic
不忽略：set noic         
</code></pre><p>获取帮助：help subject</p>
]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h2&gt;&lt;p&gt;Vim（Vi[Improved]）编辑器是功能强大的跨平台文本文件编辑工具，继承自Unix系统的Vi编辑器，支持Linux/Mac OS X
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Linux学习笔记" scheme="http://yjscloud.com/tags/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Linux学习笔记（四）-bash基础特性</title>
    <link href="http://yjscloud.com/2017/05/04/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89-bash%E5%9F%BA%E7%A1%80%E7%89%B9%E6%80%A7/"/>
    <id>http://yjscloud.com/2017/05/04/Linux学习笔记（四）-bash基础特性/</id>
    <published>2017-05-04T03:16:28.000Z</published>
    <updated>2017-12-02T09:44:07.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="bash中的变量类型："><a href="#bash中的变量类型：" class="headerlink" title="bash中的变量类型："></a>bash中的变量类型：</h2><p> 根据变量的生效范围等标准：</p>
<pre><code>本地变量：生效范围为当前shell进程；对当前shell之外的其他shell进场，包括当前shell的子shell进场无效
环境变量：生效范围当前shell进程和子进程
局部变量：生效范围为当前shell进程中某代码片段（通常指函数）
位置变量：$1,$2,...来表示，用于让脚本在脚本代码中调用通过命令行传递给它的参数
特殊变量：$?,$0,$*,$#,$@
</code></pre><h3 id="本地变量"><a href="#本地变量" class="headerlink" title="本地变量"></a>本地变量</h3><p>  变量赋值：name=’value’</p>
<pre><code>可以使用引用：
    value:
         (1）可以是直接字符;name=&quot;username&quot;
        （2）变量引用：name=&quot;$username&quot;
         (3)命令引用：name=`COMMAND` ,name=$(COMMAND)
        变量引用：${name},$name
            &quot;&quot;:弱引用，其中的变量引用会被替换为变量值；
            &apos;&apos;:强引用，其中的变量引用不会被替换为变量值，而保持原字符串；
        显示已定义的所有变量
            set
        销毁变量
            unset name
</code></pre><h3 id="环境变量："><a href="#环境变量：" class="headerlink" title="环境变量："></a>环境变量：</h3><pre><code> 变量声明、赋值：
     export name=VALUE
     declare -x name=VALUE
     变量引用：$name,${name}
     显示所有环境变量：
         export
         env
         printenv
     销毁：
         unset name

     bash有许多内建的环境变量：PATH,SHELL,UID,HISISZE,HOME,PWD,OLD

变量命名法则：
     1、不能使程序中的保留字，例如if ，for；
     2、只能使用数字、字母及下划线，且不能一以数字开头
     3、见名知义：驼峰命名法（尽量不要用大写字母）

 只读变量：
     readonly name
     declare -r name
</code></pre><h3 id="位置变量："><a href="#位置变量：" class="headerlink" title="位置变量："></a>位置变量：</h3><pre><code>在脚本代码中调用通过命令行传递给脚本参数
    $1,$2,...:对应调用第1、第2等参数
    $0:命令本身
    $*：传递给脚本的所有参数
    $@:传递给脚本的所有参数
  $#:传递给脚本的参数的个数

实例：判段给出的文件的行数
    #!/bin/bash
    linecount=&quot;$(wc -1 $1| cut -d&apos;&apos; -f1)&quot;
    echo &quot;$1 has $linecount line.&quot;
</code></pre><h2 id="bash的配置文件："><a href="#bash的配置文件：" class="headerlink" title="bash的配置文件："></a>bash的配置文件：</h2><pre><code>按生效范围划分，存在两类：
    全局配置：
        /etc/profile
            /etc/profile.d/*.sh
        /etc/bashrc
    个人配置：        
        ~/.bash_profile
        ~./bashrc

按功能划分，存在两类：
    profile类：为交互式登陆的shell提供配置
        全局：/etc/profile,/ect/profile.d/*.sh
        个人：~/.bash_profile
        功用：
            （1）用于定义环境变量
            （2）运行命令或脚本
    bashrc类：为非交互式登陆的shell提供配置
      全局： /etc/bashrc
      个人：~/.bashrc

      功用：
          （1）定义命令别名
           (2）定义本地变量
</code></pre><h2 id="shell登录："><a href="#shell登录：" class="headerlink" title="shell登录："></a>shell登录：</h2><h3 id="交互式登录："><a href="#交互式登录：" class="headerlink" title="交互式登录："></a>交互式登录：</h3><pre><code>直接通过终端输入账号密码登录；
    使用“su - UserName&quot;或”su -l UserName&quot;切换的用户

    /etc/profile --&gt; /etc/profile.d/*.sh --&gt; ~/.bash_profile --&gt;~/.bashrc --&gt; /etc/bashrc
</code></pre><h3 id="非交互式登陆"><a href="#非交互式登陆" class="headerlink" title="非交互式登陆:"></a>非交互式登陆:</h3><pre><code> su UserName
     图型界面下打开的终端
     执行脚本

     ~/.bashrc --&gt; /etc/basgrc --&gt; /etc/profile.d/*.sh

编辑配置文件定义的新配置的生效方式：
    （1）重新启动shell进程
    （2）使用source或.命令进程
</code></pre><h2 id="bash中的算术运算"><a href="#bash中的算术运算" class="headerlink" title="bash中的算术运算"></a>bash中的算术运算</h2><pre><code>+，-，*，/，%，**，

实现算术运算：
    （1）let var=算术表达式
    （2）var=$[算术表达式]
    （3）var=$((算术表达式))
    （4）var=$(expr arg1 arg2 arg3 ...)
        乘法符号有时候需要转义
        bash有内建的随机数生成器：$RANDOM

        增强型赋值：
            +=，-=，*=，/=，%=

            let varOPERvalue
                例如：let count+=1

        自增，自减：
            let var+=1
                let var++
            let var-=1
                let var--
</code></pre><h3 id="练习-1）：写一个脚本"><a href="#练习-1）：写一个脚本" class="headerlink" title="练习(1）：写一个脚本"></a>练习(1）：写一个脚本</h3><p>  计算/etc/passwd文件中的第10个用户和第20用户的ID之和</p>
<figure class="highlight makefile"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">	<span class="comment">#!/bin/bash</span></div><div class="line">userid1=<span class="variable">$(head -n 10 /etc/passwd | tail -n 1 | cut -d: -f3)</span></div><div class="line">userid2=<span class="variable">$(head -n 20 /etc/passwd | tail -n 1 | cut -d: -f3)</span></div><div class="line">useridsum=$[$userid1+userid2]</div><div class="line">echo <span class="string">"uid sum:$useridsum"</span></div></pre></td></tr></table></figure>
<h3 id="练习-2-：写一个脚本"><a href="#练习-2-：写一个脚本" class="headerlink" title="练习(2)：写一个脚本"></a>练习(2)：写一个脚本</h3><p> 传递两个文件路径作为参数给脚本，计算着两个文件中所有空白行之和</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line">spaceline1=$(grep <span class="string">"^[[:space:]]*$"</span> <span class="variable">$1</span> | wc <span class="_">-l</span>)</div><div class="line">spaceline2=$(grep <span class="string">"^[[:space:]]*$"</span> <span class="variable">$2</span> | wc <span class="_">-l</span>)</div><div class="line"><span class="built_in">echo</span> <span class="string">"the sum of space line:$[<span class="variable">$spaceline1</span>+<span class="variable">$spaceline2</span>]"</span></div></pre></td></tr></table></figure>
<h2 id="bash测试"><a href="#bash测试" class="headerlink" title="bash测试"></a>bash测试</h2><p> 条件测试：<br>     判断某需求是否满足，需要由测试机制来实现</p>
<pre><code>Note：专用的测试表达式需要由测试命令辅助完成测试过程

测试命令：
    test EXPRESSION
    [ EXPRESSION ]
    [[ EXPRESSION ]]
    Note:EXPRESSION前后必须有空白字符：

    bash的测试类型：
        数值测试：
            -gt:是否大于
            -ge：是否大于等于
            -eq:是否等于
            -ne:是否不等于
            -lt：是否小于
            -le：是否小于等于
    字符串测试：
            ==/=：是否等于
            &gt;:是否等于
            &lt;:是否小于
            ！=：是否等于
            =~：左侧字符是否能够被右侧的PATTERN所匹配
                Note:此表达式一般用于[[ ]]中
            -z：”SIRING&quot;：测试字符串是否为空，空则为真，不空为假
            -n:”SIRING&quot;：测试字符串是否不空，不空则为真，空则为假

            Note：用于字符串比较式时的用到的操作数都应该使用引号；

    文件测试
</code></pre><h2 id="bash自定义退出码"><a href="#bash自定义退出码" class="headerlink" title="bash自定义退出码"></a>bash自定义退出码</h2><pre><code>exit [n]:自定义退出状态码
    注意：脚本中一旦遇到exit命令，脚本会立即终止，终止退出状态取决于exit命令后面的数字，如果未给脚本指定退出状态码，整个脚本的退出状态码取决于脚本中执行的最后一条命令的状态码；
</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;bash中的变量类型：&quot;&gt;&lt;a href=&quot;#bash中的变量类型：&quot; class=&quot;headerlink&quot; title=&quot;bash中的变量类型：&quot;&gt;&lt;/a&gt;bash中的变量类型：&lt;/h2&gt;&lt;p&gt; 根据变量的生效范围等标准：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;本地变量
    
    </summary>
    
      <category term="学习笔记" scheme="http://yjscloud.com/categories/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="Linux学习笔记" scheme="http://yjscloud.com/tags/Linux%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
</feed>
